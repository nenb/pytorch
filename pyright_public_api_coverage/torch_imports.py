from torch import AVG
from torch import AcceleratorError
from torch import AggregationType
from torch import AliasDb
from torch import AnyType
from torch import Argument
from torch import ArgumentSpec
from torch import AwaitType
from torch import BFloat16Storage
from torch import BFloat16Tensor
from torch import BenchmarkConfig
from torch import BenchmarkExecutionStats
from torch import Block
from torch import BoolStorage
from torch import BoolTensor
from torch import BoolType
from torch import BufferDict
from torch import ByteStorage
from torch import ByteTensor
from torch import CallStack
from torch import Capsule
from torch import CharStorage
from torch import CharTensor
from torch import ClassType
from torch import Code
from torch import CompleteArgumentSpec
from torch import ComplexDoubleStorage
from torch import ComplexFloatStorage
from torch import ComplexType
from torch import ConcreteModuleType
from torch import ConcreteModuleTypeBuilder
from torch import DeepCopyMemoTable
from torch import DeserializationStorageContext
from torch import DeviceObjType
from torch import DictType
from torch import DisableTorchFunction
from torch import DisableTorchFunctionSubclass
from torch import DispatchKey
from torch import DispatchKeySet
from torch import DoubleStorage
from torch import DoubleTensor
from torch import EnumType
from torch import ErrorReport
from torch import Event
from torch import ExcludeDispatchKeyGuard
from torch import ExecutionPlan
from torch import FatalError
from torch import FileCheck
from torch import FloatStorage
from torch import FloatTensor
from torch import FloatType
from torch import FunctionSchema
from torch import Future
from torch import FutureType
from torch import Generator
from torch import Gradient
from torch import Graph
from torch import GraphExecutorState
from torch import HalfStorage
from torch import HalfTensor
from torch import IODescriptor
from torch import InferredType
from torch import IntStorage
from torch import IntTensor
from torch import IntType
from torch import InterfaceType
from torch import ListType
from torch import LiteScriptModule
from torch import LockingLogger
from torch import LoggerBase
from torch import LongStorage
from torch import LongTensor
from torch import ModuleDict
from torch import Node
from torch import NoneType
from torch import NoopLogger
from torch import NumberType
from torch import OperatorInfo
from torch import OptionalType
from torch import OutOfMemoryError
from torch import PRIVATE_OPS
from torch import ParameterDict
from torch import PyObjectType
from torch import PyTorchFileReader
from torch import PyTorchFileWriter
from torch import QInt32Storage
from torch import QInt8Storage
from torch import QUInt2x4Storage
from torch import QUInt4x2Storage
from torch import QUInt8Storage
from torch import RRefType
from torch import SUM
from torch import ScriptClass
from torch import ScriptClassFunction
from torch import ScriptDict
from torch import ScriptDictIterator
from torch import ScriptDictKeyIterator
from torch import ScriptList
from torch import ScriptListIterator
from torch import ScriptMethod
from torch import ScriptModule
from torch import ScriptModuleSerializer
from torch import ScriptObject
from torch import ScriptObjectProperty
from torch import SerializationStorageContext
from torch import ShortStorage
from torch import ShortTensor
from torch import Size
from torch import StaticModule
from torch import StorageBase
from torch import Stream
from torch import StreamObjType
from torch import StringType
from torch import SymBool
from torch import SymBoolType
from torch import SymFloat
from torch import SymInt
from torch import SymIntType
from torch import Tag
from torch import Tensor
from torch import TensorType
from torch import ThroughputBenchmark
from torch import TracingState
from torch import TupleType
from torch import Type
from torch import UnionType
from torch import Use
from torch import Value
from torch import abs
from torch import abs_
from torch import absolute
from torch import acos
from torch import acos_
from torch import acosh
from torch import acosh_
from torch import adaptive_avg_pool1d
from torch import adaptive_max_pool1d
from torch import add
from torch import addbmm
from torch import addcdiv
from torch import addcmul
from torch import addmm
from torch import addmv
from torch import addmv_
from torch import addr
from torch import adjoint
from torch import affine_grid_generator
from torch import alias_copy
from torch import all
from torch import allclose
from torch import alpha_dropout
from torch import alpha_dropout_
from torch import amax
from torch import amin
from torch import aminmax
from torch import angle
from torch import any
from torch import arange
from torch import arccos
from torch import arccos_
from torch import arccosh
from torch import arccosh_
from torch import arcsin
from torch import arcsin_
from torch import arcsinh
from torch import arcsinh_
from torch import arctan
from torch import arctan2
from torch import arctan_
from torch import arctanh
from torch import arctanh_
from torch import are_deterministic_algorithms_enabled
from torch import argmax
from torch import argmin
from torch import argsort
from torch import argwhere
from torch import as_strided
from torch import as_strided_
from torch import as_strided_copy
from torch import as_strided_scatter
from torch import as_tensor
from torch import asarray
from torch import asin
from torch import asin_
from torch import asinh
from torch import asinh_
from torch import atan
from torch import atan2
from torch import atan_
from torch import atanh
from torch import atanh_
from torch import autocast_decrement_nesting
from torch import autocast_increment_nesting
from torch import avg_pool1d
from torch import baddbmm
from torch import bartlett_window
from torch import batch_norm
from torch import batch_norm_backward_elemt
from torch import batch_norm_backward_reduce
from torch import batch_norm_elemt
from torch import batch_norm_gather_stats
from torch import batch_norm_gather_stats_with_counts
from torch import batch_norm_stats
from torch import batch_norm_update_stats
from torch import bernoulli
from torch import bfloat16
from torch import bilinear
from torch import binary_cross_entropy_with_logits
from torch import bincount
from torch import binomial
from torch import bit
from torch import bits16
from torch import bits1x8
from torch import bits2x4
from torch import bits4x2
from torch import bits8
from torch import bitwise_and
from torch import bitwise_left_shift
from torch import bitwise_not
from torch import bitwise_or
from torch import bitwise_right_shift
from torch import bitwise_xor
from torch import blackman_window
from torch import bmm
from torch import bool
from torch import broadcast_to
from torch import bucketize
from torch import can_cast
from torch import cat
from torch import ccol_indices_copy
from torch import cdouble
from torch import ceil
from torch import ceil_
from torch import celu
from torch import celu_
from torch import cfloat
from torch import chalf
from torch import channel_shuffle
from torch import channels_last
from torch import channels_last_3d
from torch import cholesky
from torch import cholesky_inverse
from torch import cholesky_solve
from torch import choose_qparams_optimized
from torch import chunk
from torch import clamp
from torch import clamp_
from torch import clamp_max
from torch import clamp_max_
from torch import clamp_min
from torch import clamp_min_
from torch import classproperty
from torch import clear_autocast_cache
from torch import clip
from torch import clip_
from torch import clone
from torch import col_indices_copy
from torch import column_stack
from torch import combinations
from torch import compile
from torch import compiled_with_cxx11_abi
from torch import complex
from torch import complex128
from torch import complex32
from torch import complex64
from torch import concat
from torch import concatenate
from torch import cond
from torch import conj
from torch import conj_physical
from torch import conj_physical_
from torch import constant_pad_nd
from torch import contiguous_format
from torch import conv1d
from torch import conv2d
from torch import conv3d
from torch import conv_tbc
from torch import conv_transpose1d
from torch import conv_transpose2d
from torch import conv_transpose3d
from torch import convolution
from torch import copysign
from torch import corrcoef
from torch import cos
from torch import cos_
from torch import cosh
from torch import cosh_
from torch import cosine_embedding_loss
from torch import cosine_similarity
from torch import count_nonzero
from torch import cov
from torch import cross
from torch import crow_indices_copy
from torch import ctc_loss
from torch import cudnn_affine_grid_generator
from torch import cudnn_batch_norm
from torch import cudnn_convolution
from torch import cudnn_convolution_add_relu
from torch import cudnn_convolution_relu
from torch import cudnn_convolution_transpose
from torch import cudnn_grid_sampler
from torch import cudnn_is_acceptable
from torch import cummax
from torch import cummin
from torch import cumprod
from torch import cumsum
from torch import cumulative_trapezoid
from torch import default_generator
from torch import deg2rad
from torch import deg2rad_
from torch import dequantize
from torch import det
from torch import detach
from torch import detach_
from torch import detach_copy
from torch import device
from torch import diag
from torch import diag_embed
from torch import diagflat
from torch import diagonal
from torch import diagonal_copy
from torch import diagonal_scatter
from torch import diff
from torch import digamma
from torch import dist
from torch import div
from torch import divide
from torch import dot
from torch import double
from torch import dropout
from torch import dropout_
from torch import dsmm
from torch import dsplit
from torch import dstack
from torch import dtype
from torch import eig
from torch import embedding
from torch import embedding_bag
from torch import embedding_renorm_
from torch import empty
from torch import empty_like
from torch import empty_permuted
from torch import empty_quantized
from torch import empty_strided
from torch import eq
from torch import equal
from torch import erf
from torch import erf_
from torch import erfc
from torch import erfc_
from torch import erfinv
from torch import exp
from torch import exp2
from torch import exp2_
from torch import exp_
from torch import expand_copy
from torch import expm1
from torch import expm1_
from torch import eye
from torch import fake_quantize_per_channel_affine
from torch import fake_quantize_per_tensor_affine
from torch import fbgemm_linear_fp16_weight
from torch import fbgemm_linear_fp16_weight_fp32_activation
from torch import fbgemm_linear_int8_weight
from torch import fbgemm_linear_int8_weight_fp32_activation
from torch import fbgemm_linear_quantize_weight
from torch import fbgemm_pack_gemm_matrix_fp16
from torch import fbgemm_pack_quantized_matrix
from torch import feature_alpha_dropout
from torch import feature_alpha_dropout_
from torch import feature_dropout
from torch import feature_dropout_
from torch import fill
from torch import fill_
from torch import finfo
from torch import fix
from torch import fix_
from torch import flatten
from torch import flip
from torch import fliplr
from torch import flipud
from torch import float
from torch import float16
from torch import float32
from torch import float4_e2m1fn_x2
from torch import float64
from torch import float8_e4m3fn
from torch import float8_e4m3fnuz
from torch import float8_e5m2
from torch import float8_e5m2fnuz
from torch import float8_e8m0fnu
from torch import float_power
from torch import floor
from torch import floor_
from torch import floor_divide
from torch import fmax
from torch import fmin
from torch import fmod
from torch import fork
from torch import frac
from torch import frac_
from torch import frexp
from torch import frobenius_norm
from torch import from_file
from torch import from_numpy
from torch import frombuffer
from torch import full
from torch import full_like
from torch import fused_moving_avg_obs_fake_quant
from torch import gather
from torch import gcd
from torch import gcd_
from torch import ge
from torch import geqrf
from torch import ger
from torch import get_autocast_cpu_dtype
from torch import get_autocast_dtype
from torch import get_autocast_gpu_dtype
from torch import get_autocast_ipu_dtype
from torch import get_autocast_xla_dtype
from torch import get_default_device
from torch import get_default_dtype
from torch import get_deterministic_debug_mode
from torch import get_device
from torch import get_device_module
from torch import get_file_path
from torch import get_float32_matmul_precision
from torch import get_num_interop_threads
from torch import get_num_threads
from torch import gradient
from torch import greater
from torch import greater_equal
from torch import grid_sampler
from torch import grid_sampler_2d
from torch import grid_sampler_3d
from torch import group_norm
from torch import gru
from torch import gru_cell
from torch import gt
from torch import half
from torch import hamming_window
from torch import hann_window
from torch import hardshrink
from torch import has_lapack
from torch import has_mkl
from torch import has_openmp
from torch import has_spectral
from torch import heaviside
from torch import hinge_embedding_loss
from torch import histc
from torch import histogram
from torch import histogramdd
from torch import hsmm
from torch import hsplit
from torch import hspmm
from torch import hstack
from torch import hypot
from torch import i0
from torch import i0_
from torch import igamma
from torch import igammac
from torch import iinfo
from torch import imag
from torch import import_ir_module
from torch import import_ir_module_from_buffer
from torch import index_add
from torch import index_copy
from torch import index_fill
from torch import index_put
from torch import index_put_
from torch import index_reduce
from torch import index_select
from torch import indices_copy
from torch import init_num_threads
from torch import inner
from torch import instance_norm
from torch import int
from torch import int1
from torch import int16
from torch import int2
from torch import int3
from torch import int32
from torch import int4
from torch import int5
from torch import int6
from torch import int64
from torch import int7
from torch import int8
from torch import int_repr
from torch import inverse
from torch import is_anomaly_check_nan_enabled
from torch import is_anomaly_enabled
from torch import is_autocast_cache_enabled
from torch import is_autocast_cpu_enabled
from torch import is_autocast_enabled
from torch import is_autocast_ipu_enabled
from torch import is_autocast_xla_enabled
from torch import is_complex
from torch import is_conj
from torch import is_deterministic_algorithms_warn_only_enabled
from torch import is_distributed
from torch import is_floating_point
from torch import is_grad_enabled
from torch import is_inference
from torch import is_inference_mode_enabled
from torch import is_neg
from torch import is_nonzero
from torch import is_same_size
from torch import is_signed
from torch import is_storage
from torch import is_tensor
from torch import is_vulkan_available
from torch import is_warn_always_enabled
from torch import isclose
from torch import isfinite
from torch import isin
from torch import isinf
from torch import isnan
from torch import isneginf
from torch import isposinf
from torch import isreal
from torch import istft
from torch import jagged
from torch import kaiser_window
from torch import kl_div
from torch import kron
from torch import kthvalue
from torch import layer_norm
from torch import layout
from torch import lcm
from torch import lcm_
from torch import ldexp
from torch import ldexp_
from torch import le
from torch import legacy_contiguous_format
from torch import lerp
from torch import less
from torch import less_equal
from torch import lgamma
from torch import linspace
from torch import lobpcg
from torch import log
from torch import log10
from torch import log10_
from torch import log1p
from torch import log1p_
from torch import log2
from torch import log2_
from torch import log_
from torch import log_softmax
from torch import logaddexp
from torch import logaddexp2
from torch import logcumsumexp
from torch import logdet
from torch import logical_and
from torch import logical_not
from torch import logical_or
from torch import logical_xor
from torch import logit
from torch import logit_
from torch import logspace
from torch import logsumexp
from torch import long
from torch import lstm
from torch import lstm_cell
from torch import lstsq
from torch import lt
from torch import lu_solve
from torch import lu_unpack
from torch import margin_ranking_loss
from torch import masked_fill
from torch import masked_scatter
from torch import masked_select
from torch import matmul
from torch import matrix_exp
from torch import matrix_power
from torch import matrix_rank
from torch import max
from torch import max_pool1d
from torch import max_pool1d_with_indices
from torch import max_pool2d
from torch import max_pool3d
from torch import maximum
from torch import mean
from torch import median
from torch import memory_format
from torch import merge_type_from_type_comment
from torch import min
from torch import minimum
from torch import miopen_batch_norm
from torch import miopen_convolution
from torch import miopen_convolution_add_relu
from torch import miopen_convolution_relu
from torch import miopen_convolution_transpose
from torch import miopen_depthwise_convolution
from torch import miopen_rnn
from torch import mkldnn_adaptive_avg_pool2d
from torch import mkldnn_convolution
from torch import mkldnn_linear_backward_weights
from torch import mkldnn_max_pool2d
from torch import mkldnn_max_pool3d
from torch import mkldnn_rnn_layer
from torch import mm
from torch import mode
from torch import moveaxis
from torch import movedim
from torch import msort
from torch import mul
from torch import multinomial
from torch import multiply
from torch import mv
from torch import mvlgamma
from torch import nan_to_num
from torch import nan_to_num_
from torch import nanmean
from torch import nanmedian
from torch import nanquantile
from torch import nansum
from torch import narrow
from torch import narrow_copy
from torch import native_batch_norm
from torch import native_channel_shuffle
from torch import native_dropout
from torch import native_group_norm
from torch import native_layer_norm
from torch import native_norm
from torch import ne
from torch import neg
from torch import neg_
from torch import negative
from torch import negative_
from torch import nextafter
from torch import nonzero
from torch import nonzero_static
from torch import norm_except_dim
from torch import normal
from torch import not_equal
from torch import nuclear_norm
from torch import numel
from torch import ones
from torch import ones_like
from torch import orgqr
from torch import ormqr
from torch import outer
from torch import pairwise_distance
from torch import parse_ir
from torch import parse_schema
from torch import parse_type_comment
from torch import pca_lowrank
from torch import pdist
from torch import per_channel_affine
from torch import per_channel_affine_float_qparams
from torch import per_channel_symmetric
from torch import per_tensor_affine
from torch import per_tensor_symmetric
from torch import permute
from torch import permute_copy
from torch import pinverse
from torch import pixel_shuffle
from torch import pixel_unshuffle
from torch import poisson
from torch import poisson_nll_loss
from torch import polar
from torch import polygamma
from torch import positive
from torch import pow
from torch import prelu
from torch import prepare_multiprocessing_environment
from torch import preserve_format
from torch import prod
from torch import profiler_allow_cudagraph_cupti_lazy_reinit_cuda12
from torch import promote_types
from torch import put
from torch import q_per_channel_axis
from torch import q_per_channel_scales
from torch import q_per_channel_zero_points
from torch import q_scale
from torch import q_zero_point
from torch import qint32
from torch import qint8
from torch import qr
from torch import qscheme
from torch import quantile
from torch import quantize_per_channel
from torch import quantize_per_tensor
from torch import quantize_per_tensor_dynamic
from torch import quantized_batch_norm
from torch import quantized_gru
from torch import quantized_gru_cell
from torch import quantized_lstm
from torch import quantized_lstm_cell
from torch import quantized_max_pool1d
from torch import quantized_max_pool2d
from torch import quantized_max_pool3d
from torch import quantized_rnn_relu_cell
from torch import quantized_rnn_tanh_cell
from torch import quint2x4
from torch import quint4x2
from torch import quint8
from torch import rad2deg
from torch import rad2deg_
from torch import rand
from torch import rand_like
from torch import randint
from torch import randint_like
from torch import randn
from torch import randn_like
from torch import randperm
from torch import range
from torch import ravel
from torch import read_vitals
from torch import real
from torch import reciprocal
from torch import reciprocal_
from torch import relu
from torch import relu_
from torch import remainder
from torch import renorm
from torch import repeat_interleave
from torch import reshape
from torch import resize_as_
from torch import resize_as_sparse_
from torch import resolve_conj
from torch import resolve_neg
from torch import result_type
from torch import rms_norm
from torch import rnn_relu
from torch import rnn_relu_cell
from torch import rnn_tanh
from torch import rnn_tanh_cell
from torch import roll
from torch import rot90
from torch import round
from torch import round_
from torch import row_indices_copy
from torch import row_stack
from torch import rrelu
from torch import rrelu_
from torch import rsqrt
from torch import rsqrt_
from torch import rsub
from torch import saddmm
from torch import scalar_tensor
from torch import scatter
from torch import scatter_add
from torch import scatter_reduce
from torch import searchsorted
from torch import segment_reduce
from torch import select
from torch import select_copy
from torch import select_scatter
from torch import selu
from torch import selu_
from torch import set_anomaly_enabled
from torch import set_autocast_cache_enabled
from torch import set_autocast_cpu_dtype
from torch import set_autocast_cpu_enabled
from torch import set_autocast_dtype
from torch import set_autocast_enabled
from torch import set_autocast_gpu_dtype
from torch import set_autocast_ipu_dtype
from torch import set_autocast_ipu_enabled
from torch import set_autocast_xla_dtype
from torch import set_autocast_xla_enabled
from torch import set_default_device
from torch import set_default_dtype
from torch import set_default_tensor_type
from torch import set_deterministic_debug_mode
from torch import set_float32_matmul_precision
from torch import set_flush_denormal
from torch import set_num_interop_threads
from torch import set_num_threads
from torch import set_printoptions
from torch import set_vital
from torch import set_warn_always
from torch import sgn
from torch import short
from torch import sigmoid
from torch import sigmoid_
from torch import sign
from torch import signbit
from torch import sin
from torch import sin_
from torch import sinc
from torch import sinc_
from torch import sinh
from torch import sinh_
from torch import slice_copy
from torch import slice_inverse
from torch import slice_scatter
from torch import slogdet
from torch import smm
from torch import softmax
from torch import solve
from torch import sort
from torch import sparse_bsc
from torch import sparse_bsc_tensor
from torch import sparse_bsr
from torch import sparse_bsr_tensor
from torch import sparse_compressed_tensor
from torch import sparse_coo
from torch import sparse_coo_tensor
from torch import sparse_csc
from torch import sparse_csc_tensor
from torch import sparse_csr
from torch import sparse_csr_tensor
from torch import split_copy
from torch import split_with_sizes
from torch import split_with_sizes_copy
from torch import spmm
from torch import sqrt
from torch import sqrt_
from torch import square
from torch import square_
from torch import squeeze
from torch import squeeze_copy
from torch import sspaddmm
from torch import stack
from torch import std
from torch import std_mean
from torch import strided
from torch import sub
from torch import subtract
from torch import sum
from torch import svd
from torch import svd_lowrank
from torch import swapaxes
from torch import swapdims
from torch import sym_constrain_range
from torch import sym_constrain_range_for_size
from torch import sym_float
from torch import sym_fresh_size
from torch import sym_int
from torch import sym_ite
from torch import sym_max
from torch import sym_min
from torch import sym_not
from torch import sym_sum
from torch import t
from torch import t_copy
from torch import take
from torch import take_along_dim
from torch import tan
from torch import tan_
from torch import tanh
from torch import tanh_
from torch import tensor
from torch import tensor_split
from torch import threshold
from torch import threshold_
from torch import tile
from torch import topk
from torch import trace
from torch import transpose
from torch import transpose_copy
from torch import trapezoid
from torch import trapz
from torch import triangular_solve
from torch import tril
from torch import tril_indices
from torch import triplet_margin_loss
from torch import triu
from torch import triu_indices
from torch import true_divide
from torch import trunc
from torch import trunc_
from torch import typename
from torch import uint1
from torch import uint16
from torch import uint2
from torch import uint3
from torch import uint32
from torch import uint4
from torch import uint5
from torch import uint6
from torch import uint64
from torch import uint7
from torch import uint8
from torch import unbind
from torch import unbind_copy
from torch import unflatten
from torch import unfold_copy
from torch import unify_type_list
from torch import unsafe_chunk
from torch import unsafe_split
from torch import unsafe_split_with_sizes
from torch import unsqueeze
from torch import unsqueeze_copy
from torch import use_deterministic_algorithms
from torch import values_copy
from torch import vander
from torch import var
from torch import var_mean
from torch import vdot
from torch import view_as_complex
from torch import view_as_complex_copy
from torch import view_as_real
from torch import view_as_real_copy
from torch import view_copy
from torch import vitals_enabled
from torch import vsplit
from torch import vstack
from torch import wait
from torch import where
from torch import while_loop
from torch import xlogy
from torch import xlogy_
from torch import zero_
from torch import zeros
from torch import zeros_like
from torch.accelerator import current_accelerator
from torch.accelerator import current_device_idx
from torch.accelerator import current_stream
from torch.accelerator import device_count
from torch.accelerator import device_index
from torch.accelerator import is_available
from torch.accelerator import set_device_idx
from torch.accelerator import set_stream
from torch.accelerator import synchronize
from torch.amp.autocast_mode import autocast
from torch.amp.autocast_mode import autocast_decorator
from torch.amp.autocast_mode import custom_bwd
from torch.amp.autocast_mode import custom_fwd
from torch.amp.autocast_mode import is_autocast_available
from torch.amp.grad_scaler import GradScaler
from torch.amp.grad_scaler import OptState
from torch.ao.nn.intrinsic.modules.fused import BNReLU2d
from torch.ao.nn.intrinsic.modules.fused import BNReLU3d
from torch.ao.nn.intrinsic.modules.fused import ConvAdd2d
from torch.ao.nn.intrinsic.modules.fused import ConvAddReLU2d
from torch.ao.nn.intrinsic.modules.fused import ConvBn1d
from torch.ao.nn.intrinsic.modules.fused import ConvBn2d
from torch.ao.nn.intrinsic.modules.fused import ConvBn3d
from torch.ao.nn.intrinsic.modules.fused import ConvBnReLU1d
from torch.ao.nn.intrinsic.modules.fused import ConvBnReLU2d
from torch.ao.nn.intrinsic.modules.fused import ConvBnReLU3d
from torch.ao.nn.intrinsic.modules.fused import ConvReLU1d
from torch.ao.nn.intrinsic.modules.fused import ConvReLU2d
from torch.ao.nn.intrinsic.modules.fused import ConvReLU3d
from torch.ao.nn.intrinsic.modules.fused import LinearBn1d
from torch.ao.nn.intrinsic.modules.fused import LinearLeakyReLU
from torch.ao.nn.intrinsic.modules.fused import LinearReLU
from torch.ao.nn.intrinsic.modules.fused import LinearTanh
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBn1d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBn2d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBn3d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBnReLU1d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBnReLU2d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvBnReLU3d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvReLU1d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvReLU2d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import ConvReLU3d
from torch.ao.nn.intrinsic.qat.modules.conv_fused import freeze_bn_stats
from torch.ao.nn.intrinsic.qat.modules.conv_fused import update_bn_stats
from torch.ao.nn.intrinsic.qat.modules.linear_fused import LinearBn1d
from torch.ao.nn.intrinsic.qat.modules.linear_relu import LinearReLU
from torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu import LinearReLU
from torch.ao.nn.intrinsic.quantized.modules.bn_relu import BNReLU2d
from torch.ao.nn.intrinsic.quantized.modules.bn_relu import BNReLU3d
from torch.ao.nn.intrinsic.quantized.modules.conv_add import ConvAdd2d
from torch.ao.nn.intrinsic.quantized.modules.conv_add import ConvAddReLU2d
from torch.ao.nn.intrinsic.quantized.modules.conv_relu import ConvReLU1d
from torch.ao.nn.intrinsic.quantized.modules.conv_relu import ConvReLU2d
from torch.ao.nn.intrinsic.quantized.modules.conv_relu import ConvReLU3d
from torch.ao.nn.intrinsic.quantized.modules.linear_relu import LinearLeakyReLU
from torch.ao.nn.intrinsic.quantized.modules.linear_relu import LinearReLU
from torch.ao.nn.intrinsic.quantized.modules.linear_relu import LinearTanh
from torch.ao.nn.qat.dynamic.modules.linear import Linear
from torch.ao.nn.qat.modules.conv import Conv1d
from torch.ao.nn.qat.modules.conv import Conv2d
from torch.ao.nn.qat.modules.conv import Conv3d
from torch.ao.nn.qat.modules.embedding_ops import Embedding
from torch.ao.nn.qat.modules.embedding_ops import EmbeddingBag
from torch.ao.nn.qat.modules.linear import Linear
from torch.ao.nn.quantizable.modules.activation import MultiheadAttention
from torch.ao.nn.quantizable.modules.rnn import LSTM
from torch.ao.nn.quantizable.modules.rnn import LSTMCell
from torch.ao.nn.quantized.dynamic.modules.conv import Conv1d
from torch.ao.nn.quantized.dynamic.modules.conv import Conv2d
from torch.ao.nn.quantized.dynamic.modules.conv import Conv3d
from torch.ao.nn.quantized.dynamic.modules.conv import ConvTranspose1d
from torch.ao.nn.quantized.dynamic.modules.conv import ConvTranspose2d
from torch.ao.nn.quantized.dynamic.modules.conv import ConvTranspose3d
from torch.ao.nn.quantized.dynamic.modules.linear import Linear
from torch.ao.nn.quantized.dynamic.modules.rnn import GRU
from torch.ao.nn.quantized.dynamic.modules.rnn import GRUCell
from torch.ao.nn.quantized.dynamic.modules.rnn import LSTM
from torch.ao.nn.quantized.dynamic.modules.rnn import LSTMCell
from torch.ao.nn.quantized.dynamic.modules.rnn import PackedParameter
from torch.ao.nn.quantized.dynamic.modules.rnn import RNNBase
from torch.ao.nn.quantized.dynamic.modules.rnn import RNNCell
from torch.ao.nn.quantized.dynamic.modules.rnn import RNNCellBase
from torch.ao.nn.quantized.dynamic.modules.rnn import apply_permutation
from torch.ao.nn.quantized.dynamic.modules.rnn import pack_weight_bias
from torch.ao.nn.quantized.functional import BroadcastingList2
from torch.ao.nn.quantized.functional import adaptive_avg_pool2d
from torch.ao.nn.quantized.functional import adaptive_avg_pool3d
from torch.ao.nn.quantized.functional import avg_pool2d
from torch.ao.nn.quantized.functional import avg_pool3d
from torch.ao.nn.quantized.functional import celu
from torch.ao.nn.quantized.functional import clamp
from torch.ao.nn.quantized.functional import conv1d
from torch.ao.nn.quantized.functional import conv2d
from torch.ao.nn.quantized.functional import conv3d
from torch.ao.nn.quantized.functional import elu
from torch.ao.nn.quantized.functional import hardsigmoid
from torch.ao.nn.quantized.functional import hardswish
from torch.ao.nn.quantized.functional import hardtanh
from torch.ao.nn.quantized.functional import interpolate
from torch.ao.nn.quantized.functional import leaky_relu
from torch.ao.nn.quantized.functional import linear
from torch.ao.nn.quantized.functional import max_pool1d
from torch.ao.nn.quantized.functional import max_pool2d
from torch.ao.nn.quantized.functional import threshold
from torch.ao.nn.quantized.functional import upsample
from torch.ao.nn.quantized.functional import upsample_bilinear
from torch.ao.nn.quantized.functional import upsample_nearest
from torch.ao.nn.quantized.modules import DeQuantize
from torch.ao.nn.quantized.modules import Quantize
from torch.ao.nn.quantized.modules.activation import ELU
from torch.ao.nn.quantized.modules.activation import Hardswish
from torch.ao.nn.quantized.modules.activation import LeakyReLU
from torch.ao.nn.quantized.modules.activation import MultiheadAttention
from torch.ao.nn.quantized.modules.activation import PReLU
from torch.ao.nn.quantized.modules.activation import ReLU6
from torch.ao.nn.quantized.modules.activation import Sigmoid
from torch.ao.nn.quantized.modules.activation import Softmax
from torch.ao.nn.quantized.modules.batchnorm import BatchNorm2d
from torch.ao.nn.quantized.modules.batchnorm import BatchNorm3d
from torch.ao.nn.quantized.modules.conv import Conv1d
from torch.ao.nn.quantized.modules.conv import Conv2d
from torch.ao.nn.quantized.modules.conv import Conv3d
from torch.ao.nn.quantized.modules.conv import ConvTranspose1d
from torch.ao.nn.quantized.modules.conv import ConvTranspose2d
from torch.ao.nn.quantized.modules.conv import ConvTranspose3d
from torch.ao.nn.quantized.modules.dropout import Dropout
from torch.ao.nn.quantized.modules.embedding_ops import Embedding
from torch.ao.nn.quantized.modules.embedding_ops import EmbeddingBag
from torch.ao.nn.quantized.modules.embedding_ops import EmbeddingPackedParams
from torch.ao.nn.quantized.modules.functional_modules import FXFloatFunctional
from torch.ao.nn.quantized.modules.functional_modules import FloatFunctional
from torch.ao.nn.quantized.modules.functional_modules import QFunctional
from torch.ao.nn.quantized.modules.linear import Linear
from torch.ao.nn.quantized.modules.linear import LinearPackedParams
from torch.ao.nn.quantized.modules.normalization import GroupNorm
from torch.ao.nn.quantized.modules.normalization import InstanceNorm1d
from torch.ao.nn.quantized.modules.normalization import InstanceNorm2d
from torch.ao.nn.quantized.modules.normalization import InstanceNorm3d
from torch.ao.nn.quantized.modules.normalization import LayerNorm
from torch.ao.nn.quantized.modules.rnn import LSTM
from torch.ao.nn.quantized.modules.utils import WeightedQuantizedModule
from torch.ao.nn.quantized.reference.modules.conv import Conv1d
from torch.ao.nn.quantized.reference.modules.conv import Conv2d
from torch.ao.nn.quantized.reference.modules.conv import Conv3d
from torch.ao.nn.quantized.reference.modules.conv import ConvTranspose1d
from torch.ao.nn.quantized.reference.modules.conv import ConvTranspose2d
from torch.ao.nn.quantized.reference.modules.conv import ConvTranspose3d
from torch.ao.nn.quantized.reference.modules.linear import Linear
from torch.ao.nn.quantized.reference.modules.rnn import GRU
from torch.ao.nn.quantized.reference.modules.rnn import GRUCell
from torch.ao.nn.quantized.reference.modules.rnn import LSTM
from torch.ao.nn.quantized.reference.modules.rnn import LSTMCell
from torch.ao.nn.quantized.reference.modules.rnn import RNNBase
from torch.ao.nn.quantized.reference.modules.rnn import RNNCell
from torch.ao.nn.quantized.reference.modules.rnn import RNNCellBase
from torch.ao.nn.quantized.reference.modules.rnn import get_quantized_weight
from torch.ao.nn.quantized.reference.modules.sparse import Embedding
from torch.ao.nn.quantized.reference.modules.sparse import EmbeddingBag
from torch.ao.nn.quantized.reference.modules.utils import ReferenceQuantizedModule
from torch.ao.nn.sparse.quantized.dynamic.linear import Linear
from torch.ao.nn.sparse.quantized.linear import Linear
from torch.ao.nn.sparse.quantized.linear import LinearPackedParams
from torch.ao.nn.sparse.quantized.utils import LinearBlockSparsePattern
from torch.ao.ns.fx.graph_matcher import GraphMatchingException
from torch.ao.ns.fx.graph_matcher import SubgraphTypeRelationship
from torch.ao.ns.fx.graph_matcher import get_matching_subgraph_pairs
from torch.ao.ns.fx.graph_passes import add_loggers_to_model
from torch.ao.ns.fx.graph_passes import create_a_shadows_b
from torch.ao.ns.fx.mappings import add_op_to_sets_of_related_ops
from torch.ao.ns.fx.mappings import get_base_name_for_op
from torch.ao.ns.fx.mappings import get_base_name_to_sets_of_related_ops
from torch.ao.ns.fx.mappings import get_node_type_to_io_type_map
from torch.ao.ns.fx.mappings import get_unmatchable_types_map
from torch.ao.ns.fx.n_shadows_utils import BINARY_FUNCTIONS
from torch.ao.ns.fx.n_shadows_utils import OutputProp
from torch.ao.ns.fx.n_shadows_utils import create_add_loggers_graph
from torch.ao.ns.fx.n_shadows_utils import create_n_transformed_and_logged_copies_of_subgraph
from torch.ao.ns.fx.n_shadows_utils import create_one_transformed_and_logged_copy_of_subgraph
from torch.ao.ns.fx.n_shadows_utils import create_results_comparison
from torch.ao.ns.fx.n_shadows_utils import create_submodule_from_subgraph
from torch.ao.ns.fx.n_shadows_utils import extract_weight_comparison
from torch.ao.ns.fx.n_shadows_utils import group_results_by_subgraph
from torch.ao.ns.fx.n_shadows_utils import print_n_shadows_summary
from torch.ao.ns.fx.ns_types import NSSingleResultValuesType
from torch.ao.ns.fx.ns_types import NSSubgraph
from torch.ao.ns.fx.pattern_utils import end_node_matches_reversed_fusion
from torch.ao.ns.fx.pattern_utils import get_reversed_fusions
from torch.ao.ns.fx.pattern_utils import get_type_a_related_to_b
from torch.ao.ns.fx.qconfig_multi_mapping import QConfigMultiMapping
from torch.ao.ns.fx.utils import NodeInputOrOutputType
from torch.ao.ns.fx.utils import compute_cosine_similarity
from torch.ao.ns.fx.utils import get_arg_indices_of_inputs_to_log
from torch.ao.ns.fx.utils import get_node_first_input_and_output_type
from torch.ao.ns.fx.utils import get_node_input_qparams
from torch.ao.ns.fx.utils import get_normalized_nth_input
from torch.ao.ns.fx.utils import get_number_of_non_param_args
from torch.ao.ns.fx.utils import get_target_type_str
from torch.ao.ns.fx.utils import maybe_add_missing_fqns
from torch.ao.ns.fx.utils import maybe_dequantize_first_two_tensor_args_and_handle_tuples
from torch.ao.ns.fx.utils import op_type_supports_shadowing
from torch.ao.ns.fx.utils import rekey_logger_info_on_node_name_of_model
from torch.ao.ns.fx.utils import return_first_non_observer_node
from torch.ao.ns.fx.weight_utils import extract_weight_from_node
from torch.ao.ns.fx.weight_utils import get_conv_fun_weight
from torch.ao.ns.fx.weight_utils import get_conv_mod_weight
from torch.ao.ns.fx.weight_utils import get_linear_fun_weight
from torch.ao.ns.fx.weight_utils import get_linear_mod_weight
from torch.ao.ns.fx.weight_utils import get_lstm_mod_weights
from torch.ao.ns.fx.weight_utils import get_lstm_weight
from torch.ao.ns.fx.weight_utils import get_op_to_type_to_weight_extraction_fn
from torch.ao.ns.fx.weight_utils import get_qconv_fun_weight
from torch.ao.ns.fx.weight_utils import get_qlinear_fun_weight
from torch.ao.ns.fx.weight_utils import get_qlstm_weight
from torch.ao.ns.fx.weight_utils import mod_0_weight_detach
from torch.ao.ns.fx.weight_utils import mod_weight_bias_0
from torch.ao.ns.fx.weight_utils import mod_weight_detach
from torch.ao.pruning import get_dynamic_sparse_quantized_mapping
from torch.ao.pruning import get_static_sparse_quantized_mapping
from torch.ao.pruning.scheduler.base_scheduler import BaseScheduler
from torch.ao.pruning.scheduler.cubic_scheduler import CubicSL
from torch.ao.pruning.scheduler.lambda_scheduler import LambdaSL
from torch.ao.pruning.sparsifier.base_sparsifier import BaseSparsifier
from torch.ao.pruning.sparsifier.base_sparsifier import KEYS_NOT_IN_STATE_DICT
from torch.ao.pruning.sparsifier.base_sparsifier import SUPPORTED_MODULES
from torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier import NearlyDiagonalSparsifier
from torch.ao.pruning.sparsifier.utils import FakeSparsity
from torch.ao.pruning.sparsifier.utils import fqn_to_module
from torch.ao.pruning.sparsifier.utils import get_arg_info_from_tensor_fqn
from torch.ao.pruning.sparsifier.utils import module_contains_param
from torch.ao.pruning.sparsifier.utils import module_to_fqn
from torch.ao.pruning.sparsifier.utils import swap_module
from torch.ao.pruning.sparsifier.weight_norm_sparsifier import WeightNormSparsifier
from torch.ao.quantization import DEFAULT_DYNAMIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization import DEFAULT_DYNAMIC_SPARSE_QUANT_MODULE_MAPPINGS
from torch.ao.quantization import DEFAULT_FLOAT_TO_QUANTIZED_OPERATOR_MAPPINGS
from torch.ao.quantization import DEFAULT_MODULE_TO_ACT_POST_PROCESS
from torch.ao.quantization import DEFAULT_QAT_MODULE_MAPPINGS
from torch.ao.quantization import DEFAULT_REFERENCE_STATIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization import DEFAULT_STATIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization import DEFAULT_STATIC_SPARSE_QUANT_MODULE_MAPPINGS
from torch.ao.quantization import ObserverOrFakeQuantize
from torch.ao.quantization import compare_results
from torch.ao.quantization import default_activation_only_qconfig
from torch.ao.quantization import default_affine_fixed_qparams_fake_quant
from torch.ao.quantization import default_affine_fixed_qparams_observer
from torch.ao.quantization import default_debug_qconfig
from torch.ao.quantization import default_dynamic_fake_quant
from torch.ao.quantization import default_dynamic_qat_qconfig
from torch.ao.quantization import default_dynamic_qconfig
from torch.ao.quantization import default_dynamic_quant_observer
from torch.ao.quantization import default_embedding_fake_quant
from torch.ao.quantization import default_embedding_fake_quant_4bit
from torch.ao.quantization import default_embedding_qat_qconfig
from torch.ao.quantization import default_embedding_qat_qconfig_4bit
from torch.ao.quantization import default_eval_fn
from torch.ao.quantization import default_fake_quant
from torch.ao.quantization import default_fixed_qparams_range_0to1_fake_quant
from torch.ao.quantization import default_fixed_qparams_range_0to1_observer
from torch.ao.quantization import default_fixed_qparams_range_neg1to1_fake_quant
from torch.ao.quantization import default_fixed_qparams_range_neg1to1_observer
from torch.ao.quantization import default_float_qparams_observer
from torch.ao.quantization import default_float_qparams_observer_4bit
from torch.ao.quantization import default_fused_act_fake_quant
from torch.ao.quantization import default_fused_per_channel_wt_fake_quant
from torch.ao.quantization import default_fused_wt_fake_quant
from torch.ao.quantization import default_histogram_fake_quant
from torch.ao.quantization import default_histogram_observer
from torch.ao.quantization import default_observer
from torch.ao.quantization import default_per_channel_qconfig
from torch.ao.quantization import default_per_channel_symmetric_qnnpack_qat_qconfig
from torch.ao.quantization import default_per_channel_symmetric_qnnpack_qconfig
from torch.ao.quantization import default_per_channel_weight_fake_quant
from torch.ao.quantization import default_per_channel_weight_observer
from torch.ao.quantization import default_qat_qconfig
from torch.ao.quantization import default_qat_qconfig_v2
from torch.ao.quantization import default_qconfig
from torch.ao.quantization import default_quint8_weight_qconfig
from torch.ao.quantization import default_reuse_input_qconfig
from torch.ao.quantization import default_symmetric_fixed_qparams_fake_quant
from torch.ao.quantization import default_symmetric_fixed_qparams_observer
from torch.ao.quantization import default_symmetric_qnnpack_qat_qconfig
from torch.ao.quantization import default_symmetric_qnnpack_qconfig
from torch.ao.quantization import default_weight_fake_quant
from torch.ao.quantization import default_weight_observer
from torch.ao.quantization import default_weight_only_qconfig
from torch.ao.quantization import extract_results_from_loggers
from torch.ao.quantization import float16_dynamic_qconfig
from torch.ao.quantization import float16_static_qconfig
from torch.ao.quantization import float_qparams_weight_only_qconfig
from torch.ao.quantization import float_qparams_weight_only_qconfig_4bit
from torch.ao.quantization import fused_per_channel_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization import fused_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization import generate_numeric_debug_handle
from torch.ao.quantization import per_channel_dynamic_qconfig
from torch.ao.quantization import per_channel_weight_observer_range_neg_127_to_127
from torch.ao.quantization import prepare_for_propagation_comparison
from torch.ao.quantization import weight_observer_range_neg_127_to_127
from torch.ao.quantization.backend_config.backend_config import BackendConfig
from torch.ao.quantization.backend_config.backend_config import BackendPatternConfig
from torch.ao.quantization.backend_config.backend_config import DTypeConfig
from torch.ao.quantization.backend_config.backend_config import DTypeWithConstraints
from torch.ao.quantization.backend_config.backend_config import ObservationType
from torch.ao.quantization.backend_config.executorch import executorch_act_qint8_scale_min_2_neg_12
from torch.ao.quantization.backend_config.executorch import executorch_default_dynamic_float16_dtype_config
from torch.ao.quantization.backend_config.executorch import executorch_default_dynamic_qint8_dtype_config
from torch.ao.quantization.backend_config.executorch import executorch_default_dynamic_quint8_dtype_config
from torch.ao.quantization.backend_config.executorch import executorch_default_op_quint8_dtype_config
from torch.ao.quantization.backend_config.executorch import executorch_weight_only_quint8_dtype_config
from torch.ao.quantization.backend_config.executorch import executorch_weight_qint8_neg_127_to_127_scale_min_2_neg_12
from torch.ao.quantization.backend_config.executorch import executorch_weighted_op_int8_dtype_config
from torch.ao.quantization.backend_config.executorch import get_executorch_backend_config
from torch.ao.quantization.backend_config.executorch import qnnpack_default_op_qint8_symmetric_dtype_config
from torch.ao.quantization.backend_config.executorch import qnnpack_weighted_op_qint8_symmetric_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_default_dynamic_float16_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_default_dynamic_int8_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_default_op_fp16_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_default_op_quint8_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_weight_only_quint4x2_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_weight_only_quint8_dtype_config
from torch.ao.quantization.backend_config.fbgemm import fbgemm_weighted_op_quint8_dtype_config
from torch.ao.quantization.backend_config.fbgemm import get_fbgemm_backend_config
from torch.ao.quantization.backend_config.native import default_dynamic_float16_dtype_config
from torch.ao.quantization.backend_config.native import default_dynamic_int8_dtype_config
from torch.ao.quantization.backend_config.native import default_op_fp16_dtype_config
from torch.ao.quantization.backend_config.native import default_op_quint8_dtype_config
from torch.ao.quantization.backend_config.native import get_native_backend_config
from torch.ao.quantization.backend_config.native import get_native_backend_config_dict
from torch.ao.quantization.backend_config.native import get_test_only_legacy_native_backend_config
from torch.ao.quantization.backend_config.native import get_test_only_legacy_native_backend_config_dict
from torch.ao.quantization.backend_config.native import input_output_only_quint8_dtype_config
from torch.ao.quantization.backend_config.native import weight_only_quint4x2_dtype_config
from torch.ao.quantization.backend_config.native import weight_only_quint8_dtype_config
from torch.ao.quantization.backend_config.native import weighted_op_quint8_dtype_config
from torch.ao.quantization.backend_config.onednn import binary_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import conv_add_left_optioins
from torch.ao.quantization.backend_config.onednn import conv_add_optioins
from torch.ao.quantization.backend_config.onednn import conv_add_relu_left_optioins
from torch.ao.quantization.backend_config.onednn import conv_configs
from torch.ao.quantization.backend_config.onednn import conv_dtype_configs
from torch.ao.quantization.backend_config.onednn import default_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import embedding_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import fixed_qparams_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import get_onednn_backend_config
from torch.ao.quantization.backend_config.onednn import layer_norm_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import linear_configs
from torch.ao.quantization.backend_config.onednn import linear_dtype_configs
from torch.ao.quantization.backend_config.onednn import observation_type
from torch.ao.quantization.backend_config.onednn import onednn_dynamic_int8_dtype_config
from torch.ao.quantization.backend_config.onednn import onednn_input_output_only_quint8_dtype_config
from torch.ao.quantization.backend_config.onednn import onednn_op_quint8_dtype_config
from torch.ao.quantization.backend_config.onednn import onednn_weight_only_qint8_dtype_config
from torch.ao.quantization.backend_config.onednn import onednn_weighted_op_int8_dtype_config
from torch.ao.quantization.backend_config.onednn import rnn_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import share_qparams_op_dtype_configs
from torch.ao.quantization.backend_config.onednn import with_bn
from torch.ao.quantization.backend_config.qnnpack import get_qnnpack_backend_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_act_qint8_scale_min_2_neg_12
from torch.ao.quantization.backend_config.qnnpack import qnnpack_default_dynamic_float16_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_default_dynamic_int8_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_default_op_fp16_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_default_op_qint8_symmetric_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_default_op_quint8_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_weight_only_quint4x2_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_weight_only_quint8_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_weight_qint8_neg_127_to_127_scale_min_2_neg_12
from torch.ao.quantization.backend_config.qnnpack import qnnpack_weighted_op_qint8_symmetric_dtype_config
from torch.ao.quantization.backend_config.qnnpack import qnnpack_weighted_op_quint8_dtype_config
from torch.ao.quantization.backend_config.tensorrt import get_tensorrt_backend_config
from torch.ao.quantization.backend_config.tensorrt import get_tensorrt_backend_config_dict
from torch.ao.quantization.backend_config.utils import entry_to_pretty_str
from torch.ao.quantization.backend_config.utils import get_fused_module_classes
from torch.ao.quantization.backend_config.utils import get_fuser_method_mapping
from torch.ao.quantization.backend_config.utils import get_fusion_pattern_to_extra_inputs_getter
from torch.ao.quantization.backend_config.utils import get_fusion_pattern_to_root_node_getter
from torch.ao.quantization.backend_config.utils import get_module_to_qat_module
from torch.ao.quantization.backend_config.utils import get_pattern_to_dtype_configs
from torch.ao.quantization.backend_config.utils import get_pattern_to_input_type_to_index
from torch.ao.quantization.backend_config.utils import get_qat_module_classes
from torch.ao.quantization.backend_config.utils import get_root_module_to_quantized_reference_module
from torch.ao.quantization.backend_config.utils import pattern_to_human_readable
from torch.ao.quantization.backend_config.utils import remove_boolean_dispatch_from_name
from torch.ao.quantization.backend_config.x86 import get_x86_backend_config
from torch.ao.quantization.backend_config.x86 import x86_default_dynamic_float16_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_default_dynamic_int8_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_default_op_fp16_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_default_op_quint8_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_weight_only_quint4x2_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_weight_only_quint8_dtype_config
from torch.ao.quantization.backend_config.x86 import x86_weighted_op_int8_dtype_config
from torch.ao.quantization.fake_quantize import FakeQuantize
from torch.ao.quantization.fake_quantize import FakeQuantizeBase
from torch.ao.quantization.fake_quantize import FixedQParamsFakeQuantize
from torch.ao.quantization.fake_quantize import FusedMovingAvgObsFakeQuantize
from torch.ao.quantization.fake_quantize import default_affine_fixed_qparams_fake_quant
from torch.ao.quantization.fake_quantize import default_dynamic_fake_quant
from torch.ao.quantization.fake_quantize import default_embedding_fake_quant
from torch.ao.quantization.fake_quantize import default_embedding_fake_quant_4bit
from torch.ao.quantization.fake_quantize import default_fake_quant
from torch.ao.quantization.fake_quantize import default_fixed_qparams_range_0to1_fake_quant
from torch.ao.quantization.fake_quantize import default_fixed_qparams_range_0to1_observer
from torch.ao.quantization.fake_quantize import default_fixed_qparams_range_neg1to1_fake_quant
from torch.ao.quantization.fake_quantize import default_fixed_qparams_range_neg1to1_observer
from torch.ao.quantization.fake_quantize import default_fused_act_fake_quant
from torch.ao.quantization.fake_quantize import default_fused_per_channel_wt_fake_quant
from torch.ao.quantization.fake_quantize import default_fused_wt_fake_quant
from torch.ao.quantization.fake_quantize import default_histogram_fake_quant
from torch.ao.quantization.fake_quantize import default_per_channel_weight_fake_quant
from torch.ao.quantization.fake_quantize import default_symmetric_fixed_qparams_fake_quant
from torch.ao.quantization.fake_quantize import default_weight_fake_quant
from torch.ao.quantization.fake_quantize import disable_fake_quant
from torch.ao.quantization.fake_quantize import disable_observer
from torch.ao.quantization.fake_quantize import enable_fake_quant
from torch.ao.quantization.fake_quantize import enable_observer
from torch.ao.quantization.fake_quantize import fused_per_channel_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization.fake_quantize import fused_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization.fuse_modules import fuse_known_modules
from torch.ao.quantization.fuse_modules import fuse_modules
from torch.ao.quantization.fuse_modules import fuse_modules_qat
from torch.ao.quantization.fuser_method_mappings import fuse_conv_bn
from torch.ao.quantization.fuser_method_mappings import fuse_conv_bn_relu
from torch.ao.quantization.fuser_method_mappings import fuse_convtranspose_bn
from torch.ao.quantization.fuser_method_mappings import fuse_linear_bn
from torch.ao.quantization.fuser_method_mappings import get_fuser_method
from torch.ao.quantization.fuser_method_mappings import get_fuser_method_new
from torch.ao.quantization.fx.convert import SUPPORTED_QDTYPES
from torch.ao.quantization.fx.convert import convert
from torch.ao.quantization.fx.convert import convert_custom_module
from torch.ao.quantization.fx.convert import convert_eq_obs
from torch.ao.quantization.fx.convert import convert_standalone_module
from torch.ao.quantization.fx.convert import convert_weighted_module
from torch.ao.quantization.fx.convert import quantized_decomposed_lib
from torch.ao.quantization.fx.convert import update_obs_for_equalization
from torch.ao.quantization.fx.custom_config import ConvertCustomConfig
from torch.ao.quantization.fx.custom_config import FuseCustomConfig
from torch.ao.quantization.fx.custom_config import PrepareCustomConfig
from torch.ao.quantization.fx.custom_config import StandaloneModuleConfigEntry
from torch.ao.quantization.fx.fuse import fuse
from torch.ao.quantization.fx.fuse_handler import DefaultFuseHandler
from torch.ao.quantization.fx.fuse_handler import FuseHandler
from torch.ao.quantization.fx.graph_module import FusedGraphModule
from torch.ao.quantization.fx.graph_module import ObservedGraphModule
from torch.ao.quantization.fx.graph_module import ObservedStandaloneGraphModule
from torch.ao.quantization.fx.graph_module import QuantizedGraphModule
from torch.ao.quantization.fx.lower_to_fbgemm import lower_to_fbgemm
from torch.ao.quantization.fx.lower_to_qnnpack import lower_to_qnnpack
from torch.ao.quantization.fx.lstm_utils import default_weight_fake_quant
from torch.ao.quantization.fx.lstm_utils import default_weight_observer
from torch.ao.quantization.fx.pattern_utils import get_default_fusion_patterns
from torch.ao.quantization.fx.pattern_utils import get_default_output_activation_post_process_map
from torch.ao.quantization.fx.pattern_utils import get_default_quant_patterns
from torch.ao.quantization.fx.prepare import NON_QUANTIZABLE_WEIGHT_OPS
from torch.ao.quantization.fx.prepare import insert_observers_for_model
from torch.ao.quantization.fx.prepare import is_equalization_observer
from torch.ao.quantization.fx.prepare import node_supports_equalization
from torch.ao.quantization.fx.prepare import prepare
from torch.ao.quantization.fx.prepare import propagate_dtypes_for_known_nodes
from torch.ao.quantization.fx.quantize_handler import BatchNormQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import BinaryOpQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import CatQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import ConvReluQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import CopyNodeQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import CustomModuleQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import DefaultNodeQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import EmbeddingQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import FixedQParamsOpQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import GeneralTensorShapeOpQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import LinearReLUQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import QuantizeHandler
from torch.ao.quantization.fx.quantize_handler import RNNDynamicQuantizeHandler
from torch.ao.quantization.fx.quantize_handler import StandaloneModuleQuantizeHandler
from torch.ao.quantization.fx.tracer import QuantizationTracer
from torch.ao.quantization.fx.tracer import ScopeContextManager
from torch.ao.quantization.fx.utils import EMPTY_ARG_DICT
from torch.ao.quantization.fx.utils import NON_OBSERVABLE_ARG_DICT
from torch.ao.quantization.fx.utils import NON_QUANTIZABLE_WEIGHT_OPS
from torch.ao.quantization.fx.utils import NodeInfo
from torch.ao.quantization.fx.utils import ObservedGraphModuleAttrs
from torch.ao.quantization.fx.utils import all_node_args_except_first
from torch.ao.quantization.fx.utils import all_node_args_have_no_tensors
from torch.ao.quantization.fx.utils import assert_and_get_unique_device
from torch.ao.quantization.fx.utils import collect_producer_nodes
from torch.ao.quantization.fx.utils import create_getattr_from_value
from torch.ao.quantization.fx.utils import create_node_from_old_node_preserve_meta
from torch.ao.quantization.fx.utils import float16_dynamic_qconfig
from torch.ao.quantization.fx.utils import float16_static_qconfig
from torch.ao.quantization.fx.utils import get_custom_module_class_keys
from torch.ao.quantization.fx.utils import get_linear_prepack_op_for_dtype
from torch.ao.quantization.fx.utils import get_new_attr_name_with_prefix
from torch.ao.quantization.fx.utils import get_non_observable_arg_indexes_and_types
from torch.ao.quantization.fx.utils import get_qconv_prepack_op
from torch.ao.quantization.fx.utils import get_skipped_module_name_and_classes
from torch.ao.quantization.fx.utils import graph_module_from_producer_nodes
from torch.ao.quantization.fx.utils import maybe_get_next_module
from torch.ao.quantization.fx.utils import node_arg_is_bias
from torch.ao.quantization.fx.utils import node_arg_is_weight
from torch.ao.quantization.fx.utils import quantized_decomposed_lib
from torch.ao.quantization.fx.utils import return_arg_list
from torch.ao.quantization.observer import AffineQuantizedObserverBase
from torch.ao.quantization.observer import FixedQParamsObserver
from torch.ao.quantization.observer import Granularity
from torch.ao.quantization.observer import HistogramObserver
from torch.ao.quantization.observer import MappingType
from torch.ao.quantization.observer import MinMaxObserver
from torch.ao.quantization.observer import MovingAverageMinMaxObserver
from torch.ao.quantization.observer import MovingAveragePerChannelMinMaxObserver
from torch.ao.quantization.observer import NoopObserver
from torch.ao.quantization.observer import ObserverBase
from torch.ao.quantization.observer import PerAxis
from torch.ao.quantization.observer import PerBlock
from torch.ao.quantization.observer import PerChannelMinMaxObserver
from torch.ao.quantization.observer import PerGroup
from torch.ao.quantization.observer import PerRow
from torch.ao.quantization.observer import PerTensor
from torch.ao.quantization.observer import PerToken
from torch.ao.quantization.observer import PlaceholderObserver
from torch.ao.quantization.observer import RecordingObserver
from torch.ao.quantization.observer import ReuseInputObserver
from torch.ao.quantization.observer import TorchAODType
from torch.ao.quantization.observer import UniformQuantizationObserverBase
from torch.ao.quantization.observer import ZeroPointDomain
from torch.ao.quantization.observer import default_affine_fixed_qparams_observer
from torch.ao.quantization.observer import default_dynamic_quant_observer
from torch.ao.quantization.observer import default_fixed_qparams_range_0to1_observer
from torch.ao.quantization.observer import default_fixed_qparams_range_neg1to1_observer
from torch.ao.quantization.observer import default_float_qparams_observer
from torch.ao.quantization.observer import default_float_qparams_observer_4bit
from torch.ao.quantization.observer import default_histogram_observer
from torch.ao.quantization.observer import default_observer
from torch.ao.quantization.observer import default_per_channel_weight_observer
from torch.ao.quantization.observer import default_symmetric_fixed_qparams_observer
from torch.ao.quantization.observer import default_weight_observer
from torch.ao.quantization.observer import get_block_size
from torch.ao.quantization.observer import get_observer_state_dict
from torch.ao.quantization.observer import load_observer_state_dict
from torch.ao.quantization.observer import per_channel_weight_observer_range_neg_127_to_127
from torch.ao.quantization.observer import weight_observer_range_neg_127_to_127
from torch.ao.quantization.pt2e.duplicate_dq_pass import DuplicateDQPass
from torch.ao.quantization.pt2e.export_utils import model_is_exported
from torch.ao.quantization.pt2e.graph_utils import bfs_trace_with_node_process
from torch.ao.quantization.pt2e.graph_utils import find_sequential_partitions
from torch.ao.quantization.pt2e.graph_utils import get_equivalent_types
from torch.ao.quantization.pt2e.graph_utils import update_equivalent_types_dict
from torch.ao.quantization.pt2e.lowering import constant_fold
from torch.ao.quantization.pt2e.lowering import freezing_passes
from torch.ao.quantization.pt2e.lowering import lower_pt2e_quantized_to_x86
from torch.ao.quantization.pt2e.port_metadata_pass import InternalError
from torch.ao.quantization.pt2e.port_metadata_pass import PortNodeMetaForQDQ
from torch.ao.quantization.pt2e.prepare import prepare
from torch.ao.quantization.pt2e.qat_utils import quantized_decomposed_lib
from torch.ao.quantization.pt2e.representation.rewrite import out_dtype
from torch.ao.quantization.pt2e.representation.rewrite import quantized_decomposed_lib
from torch.ao.quantization.pt2e.representation.rewrite import reference_representation_rewrite
from torch.ao.quantization.pt2e.utils import fold_bn_weights_into_conv_node
from torch.ao.quantization.pt2e.utils import quantized_decomposed_lib
from torch.ao.quantization.pt2e.utils import remove_tensor_overload_for_qdq_ops
from torch.ao.quantization.qconfig import QConfig
from torch.ao.quantization.qconfig import QConfigAny
from torch.ao.quantization.qconfig import QConfigDynamic
from torch.ao.quantization.qconfig import default_activation_only_qconfig
from torch.ao.quantization.qconfig import default_debug_qconfig
from torch.ao.quantization.qconfig import default_dynamic_fake_quant
from torch.ao.quantization.qconfig import default_dynamic_qat_qconfig
from torch.ao.quantization.qconfig import default_dynamic_qconfig
from torch.ao.quantization.qconfig import default_dynamic_quant_observer
from torch.ao.quantization.qconfig import default_embedding_fake_quant
from torch.ao.quantization.qconfig import default_embedding_fake_quant_4bit
from torch.ao.quantization.qconfig import default_embedding_qat_qconfig
from torch.ao.quantization.qconfig import default_embedding_qat_qconfig_4bit
from torch.ao.quantization.qconfig import default_fake_quant
from torch.ao.quantization.qconfig import default_float_qparams_observer
from torch.ao.quantization.qconfig import default_float_qparams_observer_4bit
from torch.ao.quantization.qconfig import default_fused_act_fake_quant
from torch.ao.quantization.qconfig import default_fused_per_channel_wt_fake_quant
from torch.ao.quantization.qconfig import default_fused_wt_fake_quant
from torch.ao.quantization.qconfig import default_observer
from torch.ao.quantization.qconfig import default_per_channel_qconfig
from torch.ao.quantization.qconfig import default_per_channel_symmetric_qnnpack_qat_qconfig
from torch.ao.quantization.qconfig import default_per_channel_symmetric_qnnpack_qconfig
from torch.ao.quantization.qconfig import default_per_channel_weight_fake_quant
from torch.ao.quantization.qconfig import default_per_channel_weight_observer
from torch.ao.quantization.qconfig import default_qat_qconfig
from torch.ao.quantization.qconfig import default_qat_qconfig_v2
from torch.ao.quantization.qconfig import default_qconfig
from torch.ao.quantization.qconfig import default_quint8_weight_qconfig
from torch.ao.quantization.qconfig import default_reuse_input_qconfig
from torch.ao.quantization.qconfig import default_symmetric_qnnpack_qat_qconfig
from torch.ao.quantization.qconfig import default_symmetric_qnnpack_qconfig
from torch.ao.quantization.qconfig import default_weight_fake_quant
from torch.ao.quantization.qconfig import default_weight_observer
from torch.ao.quantization.qconfig import default_weight_only_qconfig
from torch.ao.quantization.qconfig import float16_dynamic_qconfig
from torch.ao.quantization.qconfig import float16_static_qconfig
from torch.ao.quantization.qconfig import float_qparams_weight_only_qconfig
from torch.ao.quantization.qconfig import float_qparams_weight_only_qconfig_4bit
from torch.ao.quantization.qconfig import fused_per_channel_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization.qconfig import fused_wt_fake_quant_range_neg_127_to_127
from torch.ao.quantization.qconfig import get_default_qat_qconfig
from torch.ao.quantization.qconfig import get_default_qat_qconfig_dict
from torch.ao.quantization.qconfig import get_default_qconfig
from torch.ao.quantization.qconfig import get_default_qconfig_dict
from torch.ao.quantization.qconfig import per_channel_dynamic_qconfig
from torch.ao.quantization.qconfig import per_channel_weight_observer_range_neg_127_to_127
from torch.ao.quantization.qconfig import qconfig_equals
from torch.ao.quantization.qconfig import weight_observer_range_neg_127_to_127
from torch.ao.quantization.qconfig_mapping import QConfigMapping
from torch.ao.quantization.qconfig_mapping import default_fixed_qparams_range_0to1_observer
from torch.ao.quantization.qconfig_mapping import default_fixed_qparams_range_neg1to1_observer
from torch.ao.quantization.qconfig_mapping import default_quint8_weight_qconfig
from torch.ao.quantization.qconfig_mapping import default_reuse_input_qconfig
from torch.ao.quantization.qconfig_mapping import default_symmetric_qnnpack_qat_qconfig
from torch.ao.quantization.qconfig_mapping import default_symmetric_qnnpack_qconfig
from torch.ao.quantization.qconfig_mapping import default_weight_fake_quant
from torch.ao.quantization.qconfig_mapping import default_weight_observer
from torch.ao.quantization.qconfig_mapping import get_default_qat_qconfig_mapping
from torch.ao.quantization.qconfig_mapping import get_default_qconfig_mapping
from torch.ao.quantization.quant_type import QuantType
from torch.ao.quantization.quantization_mappings import DEFAULT_DYNAMIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_DYNAMIC_SPARSE_QUANT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_FLOAT_TO_QUANTIZED_OPERATOR_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_MODULE_TO_ACT_POST_PROCESS
from torch.ao.quantization.quantization_mappings import DEFAULT_QAT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_REFERENCE_STATIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_STATIC_QUANT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import DEFAULT_STATIC_SPARSE_QUANT_MODULE_MAPPINGS
from torch.ao.quantization.quantization_mappings import default_fixed_qparams_range_0to1_fake_quant
from torch.ao.quantization.quantization_mappings import default_fixed_qparams_range_neg1to1_fake_quant
from torch.ao.quantization.quantization_mappings import get_default_compare_output_module_list
from torch.ao.quantization.quantization_mappings import get_default_dynamic_quant_module_mappings
from torch.ao.quantization.quantization_mappings import get_default_dynamic_sparse_quant_module_mappings
from torch.ao.quantization.quantization_mappings import get_default_float_to_quantized_operator_mappings
from torch.ao.quantization.quantization_mappings import get_default_qat_module_mappings
from torch.ao.quantization.quantization_mappings import get_default_qconfig_propagation_list
from torch.ao.quantization.quantization_mappings import get_default_static_quant_module_mappings
from torch.ao.quantization.quantization_mappings import get_default_static_quant_reference_module_mappings
from torch.ao.quantization.quantization_mappings import get_default_static_sparse_quant_module_mappings
from torch.ao.quantization.quantization_mappings import get_dynamic_quant_module_class
from torch.ao.quantization.quantization_mappings import get_embedding_qat_module_mappings
from torch.ao.quantization.quantization_mappings import get_embedding_static_quant_module_mappings
from torch.ao.quantization.quantization_mappings import get_quantized_operator
from torch.ao.quantization.quantization_mappings import get_static_quant_module_class
from torch.ao.quantization.quantization_mappings import no_observer_set
from torch.ao.quantization.quantize import add_quant_dequant
from torch.ao.quantization.quantize import convert
from torch.ao.quantization.quantize import default_dynamic_qconfig
from torch.ao.quantization.quantize import float16_dynamic_qconfig
from torch.ao.quantization.quantize import float_qparams_weight_only_qconfig
from torch.ao.quantization.quantize import float_qparams_weight_only_qconfig_4bit
from torch.ao.quantization.quantize import get_default_custom_config_dict
from torch.ao.quantization.quantize import prepare
from torch.ao.quantization.quantize import prepare_qat
from torch.ao.quantization.quantize import propagate_qconfig_
from torch.ao.quantization.quantize import quantize
from torch.ao.quantization.quantize import quantize_dynamic
from torch.ao.quantization.quantize import quantize_qat
from torch.ao.quantization.quantize import swap_module
from torch.ao.quantization.quantize_fx import attach_preserved_attrs_to_model
from torch.ao.quantization.quantize_fx import convert_fx
from torch.ao.quantization.quantize_fx import convert_to_reference_fx
from torch.ao.quantization.quantize_fx import fuse_fx
from torch.ao.quantization.quantize_fx import prepare_fx
from torch.ao.quantization.quantize_fx import prepare_qat_fx
from torch.ao.quantization.quantize_jit import convert_dynamic_jit
from torch.ao.quantization.quantize_jit import convert_jit
from torch.ao.quantization.quantize_jit import fuse_conv_bn_jit
from torch.ao.quantization.quantize_jit import prepare_dynamic_jit
from torch.ao.quantization.quantize_jit import prepare_jit
from torch.ao.quantization.quantize_jit import quantize_dynamic_jit
from torch.ao.quantization.quantize_jit import quantize_jit
from torch.ao.quantization.quantize_jit import script_qconfig
from torch.ao.quantization.quantize_jit import script_qconfig_dict
from torch.ao.quantization.quantize_pt2e import constant_fold
from torch.ao.quantization.quantize_pt2e import convert_pt2e
from torch.ao.quantization.quantize_pt2e import prepare_pt2e
from torch.ao.quantization.quantize_pt2e import prepare_qat_pt2e
from torch.ao.quantization.quantizer.composable_quantizer import ComposableQuantizer
from torch.ao.quantization.quantizer.embedding_quantizer import EmbeddingQuantizer
from torch.ao.quantization.quantizer.embedding_quantizer import get_embedding_operators_config
from torch.ao.quantization.quantizer.quantizer import DerivedQuantizationSpec
from torch.ao.quantization.quantizer.quantizer import EdgeOrNode
from torch.ao.quantization.quantizer.quantizer import FixedQParamsQuantizationSpec
from torch.ao.quantization.quantizer.quantizer import QuantizationAnnotation
from torch.ao.quantization.quantizer.quantizer import QuantizationSpec
from torch.ao.quantization.quantizer.quantizer import QuantizationSpecBase
from torch.ao.quantization.quantizer.quantizer import Quantizer
from torch.ao.quantization.quantizer.quantizer import SharedQuantizationSpec
from torch.ao.quantization.quantizer.x86_inductor_quantizer import X86InductorQuantizer
from torch.ao.quantization.quantizer.x86_inductor_quantizer import default_quantizable_ops
from torch.ao.quantization.quantizer.x86_inductor_quantizer import get_default_x86_inductor_quantization_config
from torch.ao.quantization.quantizer.x86_inductor_quantizer import get_x86_inductor_linear_dynamic_fp16_config
from torch.ao.quantization.quantizer.x86_inductor_quantizer import int8_in_int8_out_ops
from torch.ao.quantization.quantizer.x86_inductor_quantizer import propagation_quantizable_ops
from torch.ao.quantization.quantizer.x86_inductor_quantizer import quantizable_ops
from torch.ao.quantization.quantizer.xnnpack_quantizer import OP_TO_ANNOTATOR
from torch.ao.quantization.quantizer.xnnpack_quantizer import XNNPACKQuantizer
from torch.ao.quantization.quantizer.xnnpack_quantizer import get_symmetric_quantization_config
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import OP_TO_ANNOTATOR
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import OperatorConfig
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import OperatorPatternType
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import QuantizationConfig
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import get_bias_qspec
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import get_input_act_qspec
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import get_output_act_qspec
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import get_weight_qspec
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import propagate_annotation
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import register_annotator
from torch.ao.quantization.quantizer.xpu_inductor_quantizer import XPUInductorQuantizer
from torch.ao.quantization.quantizer.xpu_inductor_quantizer import get_default_xpu_inductor_quantization_config
from torch.ao.quantization.quantizer.xpu_inductor_quantizer import int8_in_int8_out_ops
from torch.ao.quantization.stubs import DeQuantStub
from torch.ao.quantization.stubs import QuantStub
from torch.ao.quantization.stubs import QuantWrapper
from torch.ao.quantization.utils import MatchAllNode
from torch.ao.quantization.utils import NodePattern
from torch.ao.quantization.utils import activation_dtype
from torch.ao.quantization.utils import activation_is_dynamically_quantized
from torch.ao.quantization.utils import activation_is_int32_quantized
from torch.ao.quantization.utils import activation_is_int8_quantized
from torch.ao.quantization.utils import activation_is_statically_quantized
from torch.ao.quantization.utils import calculate_qmin_qmax
from torch.ao.quantization.utils import check_min_max_valid
from torch.ao.quantization.utils import check_node
from torch.ao.quantization.utils import determine_qparams
from torch.ao.quantization.utils import func_list
from torch.ao.quantization.utils import get_combined_dict
from torch.ao.quantization.utils import get_fqn_to_example_inputs
from torch.ao.quantization.utils import get_qconfig_dtypes
from torch.ao.quantization.utils import get_qparam_dict
from torch.ao.quantization.utils import get_quant_type
from torch.ao.quantization.utils import get_swapped_custom_module_class
from torch.ao.quantization.utils import getattr_from_fqn
from torch.ao.quantization.utils import has_no_children_ignoring_parametrizations
from torch.ao.quantization.utils import is_per_channel
from torch.ao.quantization.utils import is_per_tensor
from torch.ao.quantization.utils import method_list
from torch.ao.quantization.utils import module_type_list
from torch.ao.quantization.utils import op_is_int8_dynamically_quantized
from torch.ao.quantization.utils import to_underlying_dtype
from torch.ao.quantization.utils import validate_qmin_qmax
from torch.ao.quantization.utils import weight_dtype
from torch.ao.quantization.utils import weight_is_quantized
from torch.ao.quantization.utils import weight_is_statically_quantized
from torch.autograd import DeviceType
from torch.autograd import ProfilerActivity
from torch.autograd import ProfilerConfig
from torch.autograd import ProfilerEvent
from torch.autograd import ProfilerState
from torch.autograd import SavedTensor
from torch.autograd import backward
from torch.autograd import grad
from torch.autograd import kineto_available
from torch.autograd import variable
from torch.autograd.anomaly_mode import detect_anomaly
from torch.autograd.anomaly_mode import set_detect_anomaly
from torch.autograd.forward_ad import UnpackedDualTensor
from torch.autograd.forward_ad import dual_level
from torch.autograd.forward_ad import enter_dual_level
from torch.autograd.forward_ad import exit_dual_level
from torch.autograd.forward_ad import make_dual
from torch.autograd.forward_ad import unpack_dual
from torch.autograd.function import AUTOGRAD_FUNCTION_COUNTER
from torch.autograd.function import BackwardCFunction
from torch.autograd.function import Function
from torch.autograd.function import FunctionCtx
from torch.autograd.function import FunctionMeta
from torch.autograd.function import InplaceFunction
from torch.autograd.function import NestedIOFunction
from torch.autograd.function import custom_function_call
from torch.autograd.function import once_differentiable
from torch.autograd.functional import hessian
from torch.autograd.functional import hvp
from torch.autograd.functional import jacobian
from torch.autograd.functional import jvp
from torch.autograd.functional import vhp
from torch.autograd.functional import vjp
from torch.autograd.grad_mode import F
from torch.autograd.grad_mode import enable_grad
from torch.autograd.grad_mode import inference_mode
from torch.autograd.grad_mode import no_grad
from torch.autograd.grad_mode import set_grad_enabled
from torch.autograd.grad_mode import set_multithreading_enabled
from torch.autograd.gradcheck import GradcheckError
from torch.autograd.gradcheck import get_analytical_jacobian
from torch.autograd.gradcheck import get_numerical_jacobian
from torch.autograd.gradcheck import get_numerical_jacobian_wrt_specific_input
from torch.autograd.gradcheck import gradcheck
from torch.autograd.gradcheck import gradgradcheck
from torch.autograd.gradcheck import vmap
from torch.autograd.graph import GradientEdge
from torch.autograd.graph import Node
from torch.autograd.graph import TorchDispatchMode
from torch.autograd.graph import allow_mutation_on_saved_tensors
from torch.autograd.graph import disable_saved_tensors_hooks
from torch.autograd.graph import get_gradient_edge
from torch.autograd.graph import increment_version
from torch.autograd.graph import register_multi_grad_hook
from torch.autograd.graph import save_on_cpu
from torch.autograd.graph import saved_tensors_hooks
from torch.autograd.profiler import EnforceUnique
from torch.autograd.profiler import KinetoStepTracker
from torch.autograd.profiler import emit_itt
from torch.autograd.profiler import emit_nvtx
from torch.autograd.profiler import load_nvprof
from torch.autograd.profiler import parse_nvprof_trace
from torch.autograd.profiler import profile
from torch.autograd.profiler import record_function
from torch.autograd.profiler_legacy import profile
from torch.autograd.profiler_util import EventList
from torch.autograd.profiler_util import FormattedTimesMixin
from torch.autograd.profiler_util import FunctionEvent
from torch.autograd.profiler_util import FunctionEventAvg
from torch.autograd.profiler_util import Interval
from torch.autograd.profiler_util import Kernel
from torch.autograd.profiler_util import MemRecordsAcc
from torch.autograd.profiler_util import StringTable
from torch.autograd.variable import Variable
from torch.autograd.variable import VariableMeta
from torch.backends.cpu import get_cpu_capability
from torch.backends.cuda import SDPAParams
from torch.backends.cuda import allow_fp16_bf16_reduction_math_sdp
from torch.backends.cuda import can_use_cudnn_attention
from torch.backends.cuda import can_use_efficient_attention
from torch.backends.cuda import can_use_flash_attention
from torch.backends.cuda import cuBLASModule
from torch.backends.cuda import cuFFTPlanCache
from torch.backends.cuda import cuFFTPlanCacheAttrContextProp
from torch.backends.cuda import cuFFTPlanCacheManager
from torch.backends.cuda import cudnn_sdp_enabled
from torch.backends.cudnn.rnn import Unserializable
from torch.backends.cudnn.rnn import get_cudnn_mode
from torch.backends.cudnn.rnn import init_dropout_state
from torch.backends.cusparselt import get_max_alg_id
from torch.backends.cusparselt import is_available
from torch.backends.cusparselt import version
from torch.backends.kleidiai import is_available
from torch.backends.mha import get_fastpath_enabled
from torch.backends.mha import set_fastpath_enabled
from torch.backends.mkl import is_available
from torch.backends.mkl import verbose
from torch.backends.mps import is_available
from torch.backends.mps import is_built
from torch.backends.mps import is_macos13_or_newer
from torch.backends.mps import is_macos_or_newer
from torch.backends.nnpack import ContextProp
from torch.backends.nnpack import PropModule
from torch.backends.nnpack import flags
from torch.backends.nnpack import is_available
from torch.backends.nnpack import set_flags
from torch.backends.openmp import is_available
from torch.backends.xeon.run_cpu import create_args
from torch.backends.xeon.run_cpu import format_str
from torch.backends.xeon.run_cpu import main
from torch.compiler import allow_in_graph
from torch.compiler import assume_constant_result
from torch.compiler import compile
from torch.compiler import cudagraph_mark_step_begin
from torch.compiler import disable
from torch.compiler import is_compiling
from torch.compiler import is_dynamo_compiling
from torch.compiler import is_exporting
from torch.compiler import keep_tensor_guards_unsafe
from torch.compiler import list_backends
from torch.compiler import load_cache_artifacts
from torch.compiler import nested_compile_region
from torch.compiler import reset
from torch.compiler import save_cache_artifacts
from torch.compiler import set_enable_guard_collectives
from torch.compiler import set_stance
from torch.compiler import skip_guard_on_all_nn_modules_unsafe
from torch.compiler import skip_guard_on_globals_unsafe
from torch.compiler import skip_guard_on_inbuilt_nn_modules_unsafe
from torch.compiler import substitute_in_graph
from torch.compiler import wrap_numpy
from torch.compiler.config import Config
from torch.compiler.config import install_config_module
from torch.cpu import Event
from torch.cpu import Stream
from torch.cpu import StreamContext
from torch.cpu import current_device
from torch.cpu import current_stream
from torch.cpu import device_count
from torch.cpu import is_available
from torch.cpu import is_initialized
from torch.cpu import set_device
from torch.cpu import stream
from torch.cpu import synchronize
from torch.cpu.amp.autocast_mode import autocast
from torch.cpu.amp.grad_scaler import GradScaler
from torch.cuda import BFloat16Storage
from torch.cuda import BFloat16Tensor
from torch.cuda import BoolStorage
from torch.cuda import BoolTensor
from torch.cuda import ByteStorage
from torch.cuda import ByteTensor
from torch.cuda import CharStorage
from torch.cuda import CharTensor
from torch.cuda import ComplexDoubleStorage
from torch.cuda import ComplexFloatStorage
from torch.cuda import CudaError
from torch.cuda import DeferredCudaCallError
from torch.cuda import DoubleStorage
from torch.cuda import DoubleTensor
from torch.cuda import FloatStorage
from torch.cuda import FloatTensor
from torch.cuda import HalfStorage
from torch.cuda import HalfTensor
from torch.cuda import IntStorage
from torch.cuda import IntTensor
from torch.cuda import LongStorage
from torch.cuda import LongTensor
from torch.cuda import ShortStorage
from torch.cuda import ShortTensor
from torch.cuda import StreamContext
from torch.cuda import can_device_access_peer
from torch.cuda import check_error
from torch.cuda import clock_rate
from torch.cuda import cudaStatus
from torch.cuda import cudart
from torch.cuda import current_blas_handle
from torch.cuda import current_device
from torch.cuda import current_stream
from torch.cuda import default_generators
from torch.cuda import default_stream
from torch.cuda import device
from torch.cuda import device_count
from torch.cuda import device_memory_used
from torch.cuda import device_of
from torch.cuda import get_arch_list
from torch.cuda import get_device_capability
from torch.cuda import get_device_name
from torch.cuda import get_device_properties
from torch.cuda import get_gencode_flags
from torch.cuda import get_stream_from_external
from torch.cuda import get_sync_debug_mode
from torch.cuda import has_half
from torch.cuda import has_magma
from torch.cuda import init
from torch.cuda import ipc_collect
from torch.cuda import is_available
from torch.cuda import is_bf16_supported
from torch.cuda import is_initialized
from torch.cuda import is_tf32_supported
from torch.cuda import memory_usage
from torch.cuda import power_draw
from torch.cuda import set_device
from torch.cuda import set_stream
from torch.cuda import set_sync_debug_mode
from torch.cuda import stream
from torch.cuda import synchronize
from torch.cuda import temperature
from torch.cuda import utilization
from torch.cuda.amp.autocast_mode import autocast
from torch.cuda.amp.autocast_mode import custom_bwd
from torch.cuda.amp.autocast_mode import custom_fwd
from torch.cuda.amp.common import amp_definitely_not_available
from torch.cuda.amp.grad_scaler import GradScaler
from torch.cuda.gds import GdsFile
from torch.cuda.gds import gds_deregister_buffer
from torch.cuda.gds import gds_register_buffer
from torch.cuda.graphs import CUDAGraph
from torch.cuda.graphs import graph
from torch.cuda.graphs import graph_pool_handle
from torch.cuda.graphs import is_current_stream_capturing
from torch.cuda.graphs import make_graphed_callables
from torch.cuda.memory import CUDAPluggableAllocator
from torch.cuda.memory import MemPool
from torch.cuda.memory import caching_allocator_alloc
from torch.cuda.memory import caching_allocator_delete
from torch.cuda.memory import caching_allocator_enable
from torch.cuda.memory import change_current_allocator
from torch.cuda.memory import empty_cache
from torch.cuda.memory import get_allocator_backend
from torch.cuda.memory import get_per_process_memory_fraction
from torch.cuda.memory import host_memory_stats
from torch.cuda.memory import host_memory_stats_as_nested_dict
from torch.cuda.memory import list_gpu_processes
from torch.cuda.memory import max_memory_allocated
from torch.cuda.memory import max_memory_cached
from torch.cuda.memory import max_memory_reserved
from torch.cuda.memory import mem_get_info
from torch.cuda.memory import memory_allocated
from torch.cuda.memory import memory_cached
from torch.cuda.memory import memory_reserved
from torch.cuda.memory import memory_snapshot
from torch.cuda.memory import memory_stats
from torch.cuda.memory import memory_stats_as_nested_dict
from torch.cuda.memory import memory_summary
from torch.cuda.memory import reset_accumulated_host_memory_stats
from torch.cuda.memory import reset_accumulated_memory_stats
from torch.cuda.memory import reset_max_memory_allocated
from torch.cuda.memory import reset_max_memory_cached
from torch.cuda.memory import reset_peak_host_memory_stats
from torch.cuda.memory import reset_peak_memory_stats
from torch.cuda.memory import set_per_process_memory_fraction
from torch.cuda.memory import use_mem_pool
from torch.cuda.nccl import all_gather
from torch.cuda.nccl import all_reduce
from torch.cuda.nccl import broadcast
from torch.cuda.nccl import init_rank
from torch.cuda.nccl import is_available
from torch.cuda.nccl import reduce
from torch.cuda.nccl import reduce_scatter
from torch.cuda.nccl import unique_id
from torch.cuda.nccl import version
from torch.cuda.nvtx import mark
from torch.cuda.nvtx import range
from torch.cuda.nvtx import range_end
from torch.cuda.nvtx import range_pop
from torch.cuda.nvtx import range_push
from torch.cuda.nvtx import range_start
from torch.cuda.profiler import DEFAULT_FLAGS
from torch.cuda.profiler import init
from torch.cuda.profiler import profile
from torch.cuda.profiler import start
from torch.cuda.profiler import stop
from torch.cuda.random import get_rng_state
from torch.cuda.random import get_rng_state_all
from torch.cuda.random import initial_seed
from torch.cuda.random import manual_seed
from torch.cuda.random import manual_seed_all
from torch.cuda.random import seed
from torch.cuda.random import seed_all
from torch.cuda.random import set_rng_state
from torch.cuda.random import set_rng_state_all
from torch.cuda.sparse import BFloat16Tensor
from torch.cuda.sparse import ByteTensor
from torch.cuda.sparse import CharTensor
from torch.cuda.sparse import DoubleTensor
from torch.cuda.sparse import FloatTensor
from torch.cuda.sparse import HalfTensor
from torch.cuda.sparse import IntTensor
from torch.cuda.sparse import LongTensor
from torch.cuda.sparse import ShortTensor
from torch.cuda.streams import Event
from torch.cuda.streams import ExternalStream
from torch.cuda.streams import Stream
from torch.cuda.tunable import enable
from torch.cuda.tunable import get_filename
from torch.cuda.tunable import get_max_tuning_duration
from torch.cuda.tunable import get_max_tuning_iterations
from torch.cuda.tunable import get_results
from torch.cuda.tunable import get_rotating_buffer_size
from torch.cuda.tunable import get_validators
from torch.cuda.tunable import is_enabled
from torch.cuda.tunable import mgpu_tune_gemm_in_file
from torch.cuda.tunable import read_file
from torch.cuda.tunable import record_untuned_enable
from torch.cuda.tunable import record_untuned_is_enabled
from torch.cuda.tunable import set_filename
from torch.cuda.tunable import set_max_tuning_duration
from torch.cuda.tunable import set_max_tuning_iterations
from torch.cuda.tunable import set_rotating_buffer_size
from torch.cuda.tunable import tune_gemm_in_file
from torch.cuda.tunable import tuning_enable
from torch.cuda.tunable import tuning_is_enabled
from torch.cuda.tunable import write_file
from torch.cuda.tunable import write_file_on_exit
from torch.distributed import DistBackendError
from torch.distributed import DistError
from torch.distributed import DistNetworkError
from torch.distributed import DistStoreError
from torch.distributed import QueueEmptyError
from torch.distributed import is_available
from torch.distributed.algorithms.join import Join
from torch.distributed.algorithms.join import JoinHook
from torch.distributed.algorithms.join import Joinable
from torch.distributed.argparse_util import check_env
from torch.distributed.argparse_util import env
from torch.distributed.autograd import context
from torch.distributed.autograd import is_available
from torch.distributed.collective_utils import SyncPayload
from torch.distributed.collective_utils import T
from torch.distributed.collective_utils import all_gather
from torch.distributed.collective_utils import all_gather_object_enforce_type
from torch.distributed.collective_utils import broadcast
from torch.distributed.device_mesh import not_none
from torch.distributed.elastic.control_plane import worker_main
from torch.distributed.elastic.events import construct_and_record_rdzv_event
from torch.distributed.elastic.events import record
from torch.distributed.elastic.events import record_rdzv_event
from torch.distributed.elastic.events.api import Event
from torch.distributed.elastic.events.api import EventSource
from torch.distributed.elastic.events.api import NodeState
from torch.distributed.elastic.events.api import RdzvEvent
from torch.distributed.elastic.events.handlers import get_logging_handler
from torch.distributed.elastic.metrics import initialize_metrics
from torch.distributed.elastic.metrics.api import ConsoleMetricHandler
from torch.distributed.elastic.metrics.api import MetricData
from torch.distributed.elastic.metrics.api import MetricHandler
from torch.distributed.elastic.metrics.api import MetricStream
from torch.distributed.elastic.metrics.api import MetricsConfig
from torch.distributed.elastic.metrics.api import NullMetricHandler
from torch.distributed.elastic.metrics.api import configure
from torch.distributed.elastic.metrics.api import getStream
from torch.distributed.elastic.metrics.api import get_elapsed_time_ms
from torch.distributed.elastic.metrics.api import prof
from torch.distributed.elastic.metrics.api import profile
from torch.distributed.elastic.metrics.api import publish_metric
from torch.distributed.elastic.metrics.api import put_metric
from torch.distributed.elastic.multiprocessing import start_processes
from torch.distributed.elastic.multiprocessing.api import DefaultLogsSpecs
from torch.distributed.elastic.multiprocessing.api import LogsDest
from torch.distributed.elastic.multiprocessing.api import LogsSpecs
from torch.distributed.elastic.multiprocessing.api import MultiprocessContext
from torch.distributed.elastic.multiprocessing.api import PContext
from torch.distributed.elastic.multiprocessing.api import RunProcsResult
from torch.distributed.elastic.multiprocessing.api import SignalException
from torch.distributed.elastic.multiprocessing.api import Std
from torch.distributed.elastic.multiprocessing.api import SubprocessContext
from torch.distributed.elastic.multiprocessing.api import get_std_cm
from torch.distributed.elastic.multiprocessing.api import to_map
from torch.distributed.elastic.multiprocessing.errors import ChildFailedError
from torch.distributed.elastic.multiprocessing.errors import ProcessFailure
from torch.distributed.elastic.multiprocessing.errors import record
from torch.distributed.elastic.multiprocessing.errors.error_handler import ErrorHandler
from torch.distributed.elastic.multiprocessing.errors.handlers import get_error_handler
from torch.distributed.elastic.multiprocessing.redirects import get_libc
from torch.distributed.elastic.multiprocessing.redirects import libc
from torch.distributed.elastic.multiprocessing.redirects import redirect
from torch.distributed.elastic.multiprocessing.subprocess_handler.handlers import get_subprocess_handler
from torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler import SubprocessHandler
from torch.distributed.elastic.multiprocessing.tail_log import TailLog
from torch.distributed.elastic.multiprocessing.tail_log import tail_logfile
from torch.distributed.elastic.timer.api import RequestQueue
from torch.distributed.elastic.timer.api import TimerClient
from torch.distributed.elastic.timer.api import TimerRequest
from torch.distributed.elastic.timer.api import TimerServer
from torch.distributed.elastic.timer.api import configure
from torch.distributed.elastic.timer.api import expires
from torch.distributed.elastic.timer.debug_info_logging import log_debug_info_for_expired_timers
from torch.distributed.elastic.timer.file_based_local_timer import FileTimerClient
from torch.distributed.elastic.timer.file_based_local_timer import FileTimerRequest
from torch.distributed.elastic.timer.file_based_local_timer import FileTimerServer
from torch.distributed.elastic.timer.local_timer import LocalTimerClient
from torch.distributed.elastic.timer.local_timer import LocalTimerServer
from torch.distributed.elastic.timer.local_timer import MultiprocessingRequestQueue
from torch.distributed.elastic.utils.api import get_env_variable_or_raise
from torch.distributed.elastic.utils.api import get_socket_with_port
from torch.distributed.elastic.utils.api import macros
from torch.distributed.elastic.utils.data.cycling_iterator import CyclingIterator
from torch.distributed.elastic.utils.data.elastic_distributed_sampler import ElasticDistributedSampler
from torch.distributed.elastic.utils.data.elastic_distributed_sampler import T
from torch.distributed.elastic.utils.distributed import create_c10d_store
from torch.distributed.elastic.utils.distributed import get_free_port
from torch.distributed.elastic.utils.distributed import get_socket_with_port
from torch.distributed.elastic.utils.log_level import get_log_level
from torch.distributed.elastic.utils.logging import get_logger
from torch.distributed.elastic.utils.store import barrier
from torch.distributed.elastic.utils.store import get_all
from torch.distributed.elastic.utils.store import store_timeout
from torch.distributed.elastic.utils.store import synchronize
from torch.distributed.rpc import is_available
from torch.distributed.rpc.functions import async_execution
from torch.distributed.utils import Q
from torch.distributed.utils import R
from torch.distributed.utils import S
from torch.distributed.utils import T
from torch.distributions import biject_to
from torch.distributions import identity_transform
from torch.distributions import transform_to
from torch.distributions.bernoulli import Bernoulli
from torch.distributions.beta import Beta
from torch.distributions.binomial import Binomial
from torch.distributions.categorical import Categorical
from torch.distributions.cauchy import Cauchy
from torch.distributions.chi2 import Chi2
from torch.distributions.constraint_registry import ConstraintRegistry
from torch.distributions.constraint_registry import biject_to
from torch.distributions.constraint_registry import transform_to
from torch.distributions.constraints import Constraint
from torch.distributions.constraints import MixtureSameFamilyConstraint
from torch.distributions.constraints import boolean
from torch.distributions.constraints import corr_cholesky
from torch.distributions.constraints import dependent
from torch.distributions.constraints import is_dependent
from torch.distributions.constraints import lower_cholesky
from torch.distributions.constraints import lower_triangular
from torch.distributions.constraints import nonnegative
from torch.distributions.constraints import nonnegative_integer
from torch.distributions.constraints import one_hot
from torch.distributions.constraints import positive
from torch.distributions.constraints import positive_definite
from torch.distributions.constraints import positive_integer
from torch.distributions.constraints import positive_semidefinite
from torch.distributions.constraints import real
from torch.distributions.constraints import real_vector
from torch.distributions.constraints import simplex
from torch.distributions.constraints import square
from torch.distributions.constraints import symmetric
from torch.distributions.constraints import unit_interval
from torch.distributions.continuous_bernoulli import ContinuousBernoulli
from torch.distributions.dirichlet import Dirichlet
from torch.distributions.distribution import Distribution
from torch.distributions.exp_family import ExponentialFamily
from torch.distributions.exponential import Exponential
from torch.distributions.fishersnedecor import FisherSnedecor
from torch.distributions.gamma import Gamma
from torch.distributions.generalized_pareto import GeneralizedPareto
from torch.distributions.geometric import Geometric
from torch.distributions.gumbel import Gumbel
from torch.distributions.gumbel import euler_constant
from torch.distributions.half_cauchy import HalfCauchy
from torch.distributions.half_normal import HalfNormal
from torch.distributions.independent import D
from torch.distributions.independent import Independent
from torch.distributions.inverse_gamma import InverseGamma
from torch.distributions.kl import kl_divergence
from torch.distributions.kl import register_kl
from torch.distributions.kumaraswamy import Kumaraswamy
from torch.distributions.kumaraswamy import euler_constant
from torch.distributions.laplace import Laplace
from torch.distributions.lkj_cholesky import LKJCholesky
from torch.distributions.log_normal import LogNormal
from torch.distributions.logistic_normal import LogisticNormal
from torch.distributions.lowrank_multivariate_normal import LowRankMultivariateNormal
from torch.distributions.mixture_same_family import MixtureSameFamily
from torch.distributions.multinomial import Multinomial
from torch.distributions.multivariate_normal import MultivariateNormal
from torch.distributions.negative_binomial import NegativeBinomial
from torch.distributions.normal import Normal
from torch.distributions.one_hot_categorical import OneHotCategorical
from torch.distributions.one_hot_categorical import OneHotCategoricalStraightThrough
from torch.distributions.pareto import Pareto
from torch.distributions.poisson import Poisson
from torch.distributions.relaxed_bernoulli import LogitRelaxedBernoulli
from torch.distributions.relaxed_bernoulli import RelaxedBernoulli
from torch.distributions.relaxed_categorical import ExpRelaxedCategorical
from torch.distributions.relaxed_categorical import RelaxedOneHotCategorical
from torch.distributions.studentT import StudentT
from torch.distributions.transformed_distribution import TransformedDistribution
from torch.distributions.transforms import AbsTransform
from torch.distributions.transforms import AffineTransform
from torch.distributions.transforms import CatTransform
from torch.distributions.transforms import ComposeTransform
from torch.distributions.transforms import CorrCholeskyTransform
from torch.distributions.transforms import CumulativeDistributionTransform
from torch.distributions.transforms import ExpTransform
from torch.distributions.transforms import IndependentTransform
from torch.distributions.transforms import LowerCholeskyTransform
from torch.distributions.transforms import PositiveDefiniteTransform
from torch.distributions.transforms import PowerTransform
from torch.distributions.transforms import ReshapeTransform
from torch.distributions.transforms import SigmoidTransform
from torch.distributions.transforms import SoftmaxTransform
from torch.distributions.transforms import SoftplusTransform
from torch.distributions.transforms import StackTransform
from torch.distributions.transforms import StickBreakingTransform
from torch.distributions.transforms import TanhTransform
from torch.distributions.transforms import Transform
from torch.distributions.transforms import identity_transform
from torch.distributions.uniform import Uniform
from torch.distributions.utils import R
from torch.distributions.utils import T
from torch.distributions.utils import broadcast_all
from torch.distributions.utils import clamp_probs
from torch.distributions.utils import euler_constant
from torch.distributions.utils import lazy_property
from torch.distributions.utils import logits_to_probs
from torch.distributions.utils import probs_to_logits
from torch.distributions.utils import tril_matrix_to_vec
from torch.distributions.utils import vec_to_tril_matrix
from torch.distributions.von_mises import VonMises
from torch.distributions.weibull import Weibull
from torch.distributions.weibull import euler_constant
from torch.distributions.wishart import Wishart
from torch.export import compatibility
from torch.export import draft_export
from torch.export import export
from torch.export import export_for_training
from torch.export import load
from torch.export import register_dataclass
from torch.export import save
from torch.export.custom_obj import ScriptObjectMeta
from torch.export.custom_ops import lib
from torch.export.decomp_utils import CustomDecompTable
from torch.export.decomp_utils import PRESERVED_ATEN_CIA_OPS
from torch.export.dynamic_shapes import AdditionalInputs
from torch.export.dynamic_shapes import BUILTIN_TYPES
from torch.export.dynamic_shapes import Dim
from torch.export.dynamic_shapes import LeafSpec
from torch.export.dynamic_shapes import MappingKey
from torch.export.dynamic_shapes import SUPPORTED_NODES
from torch.export.dynamic_shapes import ShapesCollection
from torch.export.dynamic_shapes import dims
from torch.export.dynamic_shapes import keystr
from torch.export.dynamic_shapes import refine_dynamic_shapes_from_suggested_fixes
from torch.export.dynamic_shapes import tree_map_with_path
from torch.export.exported_program import ExportedProgram
from torch.export.exported_program import ModuleCallEntry
from torch.export.exported_program import ModuleCallSignature
from torch.export.exported_program import TracingContext
from torch.export.exported_program import Verifier
from torch.export.exported_program import autograd_not_implemented
from torch.export.exported_program import default_decompositions
from torch.export.exported_program import first_call_function_nn_module_stack
from torch.export.exported_program import is_equivalent
from torch.export.exported_program import placeholder_naming_pass
from torch.export.exported_program import register_op_impl
from torch.export.exported_program import tracing
from torch.export.exported_program import unset_fake_temporarily
from torch.export.graph_signature import ConstantArgument
from torch.export.graph_signature import CustomObjArgument
from torch.export.graph_signature import ExportBackwardSignature
from torch.export.graph_signature import ExportGraphSignature
from torch.export.graph_signature import InputKind
from torch.export.graph_signature import InputSpec
from torch.export.graph_signature import OutputKind
from torch.export.graph_signature import OutputSpec
from torch.export.graph_signature import SymBoolArgument
from torch.export.graph_signature import SymFloatArgument
from torch.export.graph_signature import SymIntArgument
from torch.export.graph_signature import TensorArgument
from torch.export.graph_signature import TokenArgument
from torch.export.graph_signature import is_fake
from torch.export.passes import move_to_device_pass
from torch.export.pt2_archive import PT2ArchiveReader
from torch.export.pt2_archive import PT2ArchiveWriter
from torch.export.pt2_archive import is_pt2_package
from torch.export.unflatten import FakeScriptObject
from torch.export.unflatten import FlatArgsAdapter
from torch.export.unflatten import GetAttrKey
from torch.export.unflatten import InterpreterModule
from torch.export.unflatten import InterpreterModuleDispatcher
from torch.export.unflatten import UnflattenedModule
from torch.export.unflatten import is_fx_tracing
from torch.export.unflatten import reorder_kwargs
from torch.export.unflatten import unflatten
from torch.fft import common_args
from torch.fft import factory_common_args
from torch.fft import fft
from torch.fft import fft2
from torch.fft import fftfreq
from torch.fft import fftn
from torch.fft import fftshift
from torch.fft import hfft
from torch.fft import hfft2
from torch.fft import hfftn
from torch.fft import ifft
from torch.fft import ifft2
from torch.fft import ifftn
from torch.fft import ifftshift
from torch.fft import ihfft
from torch.fft import ihfft2
from torch.fft import ihfftn
from torch.fft import irfft
from torch.fft import irfft2
from torch.fft import irfftn
from torch.fft import rfft
from torch.fft import rfft2
from torch.fft import rfftfreq
from torch.fft import rfftn
from torch.func import debug_unwrap
from torch.func import functional_call
from torch.func import functionalize
from torch.func import grad
from torch.func import grad_and_value
from torch.func import hessian
from torch.func import jacfwd
from torch.func import jacrev
from torch.func import jvp
from torch.func import linearize
from torch.func import replace_all_batch_norm_modules_
from torch.func import stack_module_state
from torch.func import vjp
from torch.func import vmap
from torch.functional import align_tensors
from torch.functional import atleast_1d
from torch.functional import atleast_2d
from torch.functional import atleast_3d
from torch.functional import block_diag
from torch.functional import boolean_dispatch
from torch.functional import broadcast_shapes
from torch.functional import broadcast_tensors
from torch.functional import cartesian_prod
from torch.functional import cdist
from torch.functional import chain_matmul
from torch.functional import einsum
from torch.functional import lu
from torch.functional import meshgrid
from torch.functional import norm
from torch.functional import split
from torch.functional import stft
from torch.functional import tensordot
from torch.functional import unique
from torch.functional import unique_consecutive
from torch.functional import unravel_index
from torch.futures import S
from torch.futures import T
from torch.futures import collect_all
from torch.futures import wait_all
from torch.fx import PH
from torch.fx import ProxyableClassMeta
from torch.fx import Tracer
from torch.fx import symbolic_trace
from torch.fx import wrap
from torch.fx.annotate import annotate
from torch.fx.config import disable_progress
from torch.fx.config import verbose_progress
from torch.fx.experimental.accelerator_partitioner import DAG
from torch.fx.experimental.accelerator_partitioner import DAGNode
from torch.fx.experimental.accelerator_partitioner import PartitionResult
from torch.fx.experimental.accelerator_partitioner import Partitioner
from torch.fx.experimental.accelerator_partitioner import check_dependency
from torch.fx.experimental.accelerator_partitioner import combine_two_partitions
from torch.fx.experimental.accelerator_partitioner import get_bfs_level_partition
from torch.fx.experimental.accelerator_partitioner import get_device_partition_stats
from torch.fx.experimental.accelerator_partitioner import get_device_to_partitions_mapping
from torch.fx.experimental.accelerator_partitioner import get_logical_id_to_device
from torch.fx.experimental.accelerator_partitioner import get_node_to_partition_mapping
from torch.fx.experimental.accelerator_partitioner import reorganize_partitions
from torch.fx.experimental.accelerator_partitioner import reset_partition_device
from torch.fx.experimental.accelerator_partitioner import set_parents_and_children
from torch.fx.experimental.const_fold import FoldedGraphModule
from torch.fx.experimental.const_fold import get_unique_attr_name_in_module
from torch.fx.experimental.const_fold import split_const_subgraphs
from torch.fx.experimental.debug import set_trace
from torch.fx.experimental.graph_gradual_typechecker import GraphTypeChecker
from torch.fx.experimental.graph_gradual_typechecker import Refine
from torch.fx.experimental.graph_gradual_typechecker import adaptiveavgpool2d_check
from torch.fx.experimental.graph_gradual_typechecker import adaptiveavgpool2d_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import add_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import all_eq
from torch.fx.experimental.graph_gradual_typechecker import bn2d_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import broadcast_types
from torch.fx.experimental.graph_gradual_typechecker import calculate_out_dimension
from torch.fx.experimental.graph_gradual_typechecker import conv2d_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import conv_refinement_rule
from torch.fx.experimental.graph_gradual_typechecker import conv_rule
from torch.fx.experimental.graph_gradual_typechecker import element_wise_eq
from torch.fx.experimental.graph_gradual_typechecker import expand_to_tensor_dim
from torch.fx.experimental.graph_gradual_typechecker import first_two_eq
from torch.fx.experimental.graph_gradual_typechecker import flatten_check
from torch.fx.experimental.graph_gradual_typechecker import flatten_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import flatten_refinement_rule
from torch.fx.experimental.graph_gradual_typechecker import get_attr_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import get_greatest_upper_bound
from torch.fx.experimental.graph_gradual_typechecker import get_parameter
from torch.fx.experimental.graph_gradual_typechecker import linear_check
from torch.fx.experimental.graph_gradual_typechecker import linear_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import linear_refinement_rule
from torch.fx.experimental.graph_gradual_typechecker import maxpool2d_check
from torch.fx.experimental.graph_gradual_typechecker import maxpool2d_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import register_algebraic_expressions_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import register_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import register_refinement_rule
from torch.fx.experimental.graph_gradual_typechecker import relu_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import reshape_inference_rule
from torch.fx.experimental.graph_gradual_typechecker import transpose_inference_rule
from torch.fx.experimental.merge_matmul import are_nodes_independent
from torch.fx.experimental.merge_matmul import may_depend_on
from torch.fx.experimental.merge_matmul import merge_matmul
from torch.fx.experimental.merge_matmul import split_result_tensors
from torch.fx.experimental.meta_tracer import MetaAttribute
from torch.fx.experimental.meta_tracer import MetaDeviceAttribute
from torch.fx.experimental.meta_tracer import MetaProxy
from torch.fx.experimental.meta_tracer import MetaTracer
from torch.fx.experimental.meta_tracer import embedding_override
from torch.fx.experimental.meta_tracer import functional_relu_override
from torch.fx.experimental.meta_tracer import gen_constructor_wrapper
from torch.fx.experimental.meta_tracer import manual_meta_overrides
from torch.fx.experimental.meta_tracer import nn_layernorm_override
from torch.fx.experimental.meta_tracer import proxys_to_metas
from torch.fx.experimental.meta_tracer import symbolic_trace
from torch.fx.experimental.meta_tracer import torch_abs_override
from torch.fx.experimental.meta_tracer import torch_nn_relu_override
from torch.fx.experimental.meta_tracer import torch_relu_override
from torch.fx.experimental.meta_tracer import torch_where_override
from torch.fx.experimental.migrate_gradual_types.constraint import ApplyBroadcasting
from torch.fx.experimental.migrate_gradual_types.constraint import BVar
from torch.fx.experimental.migrate_gradual_types.constraint import BinConstraintD
from torch.fx.experimental.migrate_gradual_types.constraint import BinConstraintT
from torch.fx.experimental.migrate_gradual_types.constraint import BinaryConstraint
from torch.fx.experimental.migrate_gradual_types.constraint import CalcConv
from torch.fx.experimental.migrate_gradual_types.constraint import CalcMaxPool
from torch.fx.experimental.migrate_gradual_types.constraint import CalcProduct
from torch.fx.experimental.migrate_gradual_types.constraint import CanReshape
from torch.fx.experimental.migrate_gradual_types.constraint import Conj
from torch.fx.experimental.migrate_gradual_types.constraint import Constraint
from torch.fx.experimental.migrate_gradual_types.constraint import DGreatestUpperBound
from torch.fx.experimental.migrate_gradual_types.constraint import DVar
from torch.fx.experimental.migrate_gradual_types.constraint import Disj
from torch.fx.experimental.migrate_gradual_types.constraint import F
from torch.fx.experimental.migrate_gradual_types.constraint import GetItem
from torch.fx.experimental.migrate_gradual_types.constraint import GetItemTensor
from torch.fx.experimental.migrate_gradual_types.constraint import IndexSelect
from torch.fx.experimental.migrate_gradual_types.constraint import Prod
from torch.fx.experimental.migrate_gradual_types.constraint import T
from torch.fx.experimental.migrate_gradual_types.constraint import TGreatestUpperBound
from torch.fx.experimental.migrate_gradual_types.constraint import TVar
from torch.fx.experimental.migrate_gradual_types.constraint import Transpose
from torch.fx.experimental.migrate_gradual_types.constraint import is_algebraic_expression
from torch.fx.experimental.migrate_gradual_types.constraint import is_bool_expr
from torch.fx.experimental.migrate_gradual_types.constraint import is_dim
from torch.fx.experimental.migrate_gradual_types.constraint import op_add
from torch.fx.experimental.migrate_gradual_types.constraint import op_div
from torch.fx.experimental.migrate_gradual_types.constraint import op_eq
from torch.fx.experimental.migrate_gradual_types.constraint import op_gt
from torch.fx.experimental.migrate_gradual_types.constraint import op_lt
from torch.fx.experimental.migrate_gradual_types.constraint import op_mod
from torch.fx.experimental.migrate_gradual_types.constraint import op_mul
from torch.fx.experimental.migrate_gradual_types.constraint import op_neq
from torch.fx.experimental.migrate_gradual_types.constraint import op_sub
from torch.fx.experimental.migrate_gradual_types.constraint_generator import ConstraintGenerator
from torch.fx.experimental.migrate_gradual_types.constraint_generator import adaptive_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import add_layer_norm_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import add_linear_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import arange_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import assert_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import batchnorm_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import bmm_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import broadcasting_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import conv2d_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import cumsum_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import embedding_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import embedding_inference_rule_functional
from torch.fx.experimental.migrate_gradual_types.constraint_generator import eq_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import equality_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import expand_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import flatten_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import full_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import gen_broadcasting_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import gen_embedding_rules
from torch.fx.experimental.migrate_gradual_types.constraint_generator import gen_layer_norm_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import generate_flatten_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import get_attr_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import getitem_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import gt_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import index_select_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import layer_norm_functional
from torch.fx.experimental.migrate_gradual_types.constraint_generator import layer_norm_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import linear_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_generator import linear_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import lt_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import masked_fill_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import maxpool_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import neq_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_add
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_consistency
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_div
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_eq
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_gt
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_leq
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_lt
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_matching
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_mul
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_neq
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_precision
from torch.fx.experimental.migrate_gradual_types.constraint_generator import op_sub
from torch.fx.experimental.migrate_gradual_types.constraint_generator import range_check
from torch.fx.experimental.migrate_gradual_types.constraint_generator import register_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import relu_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import reshape_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import size_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import tensor_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import torch_dim_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import torch_linear_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import transpose_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import type_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_generator import view_inference_rule
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import apply_padding
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import broadcast_dim
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import calc_last_two_dims
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import create_equality_constraints_for_broadcasting
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import gen_all_reshape_possibilities
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import gen_broadcasting_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import gen_consistency_constraints
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import gen_greatest_upper_bound
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import gen_lists_of_dims
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_all_broadcasting_possibilities_no_padding
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_all_int_dyn_dim_possibilities
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_binconstraint_d
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_binconstraint_t
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_broadcasting
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_calc_conv
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_calc_maxpool
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_calc_product
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_conj
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_d_gub
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_disj
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_gub
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import generate_reshape
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import is_dim_div_by_target
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import is_target_div_by_dim
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import no_broadcast_dim_with_index
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_add
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_consistency
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_div
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_eq
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_leq
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_matching
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_mod
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_mul
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_neq
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_precision
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import op_sub
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import register_transformation_rule
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import transform_constraint
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import transform_get_item
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import transform_get_item_tensor
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import transform_index_select
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import transform_transpose
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import valid_index
from torch.fx.experimental.migrate_gradual_types.constraint_transformation import valid_index_tensor
from torch.fx.experimental.migrate_gradual_types.operation import op_add
from torch.fx.experimental.migrate_gradual_types.operation import op_consistency
from torch.fx.experimental.migrate_gradual_types.operation import op_div
from torch.fx.experimental.migrate_gradual_types.operation import op_eq
from torch.fx.experimental.migrate_gradual_types.operation import op_gt
from torch.fx.experimental.migrate_gradual_types.operation import op_imp
from torch.fx.experimental.migrate_gradual_types.operation import op_leq
from torch.fx.experimental.migrate_gradual_types.operation import op_lt
from torch.fx.experimental.migrate_gradual_types.operation import op_matching
from torch.fx.experimental.migrate_gradual_types.operation import op_mod
from torch.fx.experimental.migrate_gradual_types.operation import op_mul
from torch.fx.experimental.migrate_gradual_types.operation import op_neq
from torch.fx.experimental.migrate_gradual_types.operation import op_precision
from torch.fx.experimental.migrate_gradual_types.operation import op_sub
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_add
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_div
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_eq
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_gt
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_leq
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_lt
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_mod
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_mul
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_neq
from torch.fx.experimental.migrate_gradual_types.transform_to_z3 import op_sub
from torch.fx.experimental.migrate_gradual_types.util import gen_bvar
from torch.fx.experimental.migrate_gradual_types.util import gen_dvar
from torch.fx.experimental.migrate_gradual_types.util import gen_nat_constraints
from torch.fx.experimental.migrate_gradual_types.util import gen_tensor_dims
from torch.fx.experimental.migrate_gradual_types.util import gen_tvar
from torch.fx.experimental.migrate_gradual_types.util import op_leq
from torch.fx.experimental.normalize import NormalizeArgs
from torch.fx.experimental.normalize import NormalizeOperators
from torch.fx.experimental.optimization import MklSubgraph
from torch.fx.experimental.optimization import UnionFind
from torch.fx.experimental.optimization import extract_subgraph
from torch.fx.experimental.optimization import fuse
from torch.fx.experimental.optimization import gen_mkl_autotuner
from torch.fx.experimental.optimization import matches_module_pattern
from torch.fx.experimental.optimization import mkldnn_map
from torch.fx.experimental.optimization import mkldnn_supported
from torch.fx.experimental.optimization import mkldnn_supported_unknown
from torch.fx.experimental.optimization import modules_to_mkldnn
from torch.fx.experimental.optimization import optimize_for_inference
from torch.fx.experimental.optimization import remove_dropout
from torch.fx.experimental.optimization import replace_node_module
from torch.fx.experimental.optimization import reset_modules
from torch.fx.experimental.optimization import use_mkl_length
from torch.fx.experimental.partitioner_utils import Device
from torch.fx.experimental.partitioner_utils import NodeLatency
from torch.fx.experimental.partitioner_utils import Partition
from torch.fx.experimental.partitioner_utils import PartitionLatency
from torch.fx.experimental.partitioner_utils import PartitionMode
from torch.fx.experimental.partitioner_utils import PartitionerConfig
from torch.fx.experimental.partitioner_utils import get_comm_latency_between
from torch.fx.experimental.partitioner_utils import get_extra_size_of
from torch.fx.experimental.partitioner_utils import get_latency_of_one_partition
from torch.fx.experimental.partitioner_utils import get_latency_of_partitioned_graph
from torch.fx.experimental.partitioner_utils import get_partition_to_latency_mapping
from torch.fx.experimental.proxy_tensor import BackwardState
from torch.fx.experimental.proxy_tensor import CURRENT_DECOMPOSITION_TABLE
from torch.fx.experimental.proxy_tensor import DecompositionInterpreter
from torch.fx.experimental.proxy_tensor import HANDLED_TYPES
from torch.fx.experimental.proxy_tensor import ORIGINAL_ATEN
from torch.fx.experimental.proxy_tensor import PreDispatchTorchFunctionMode
from torch.fx.experimental.proxy_tensor import ProxyTorchDispatchMode
from torch.fx.experimental.proxy_tensor import PythonKeyTracer
from torch.fx.experimental.proxy_tensor import R
from torch.fx.experimental.proxy_tensor import T
from torch.fx.experimental.proxy_tensor import Thunk
from torch.fx.experimental.proxy_tensor import TorchFunctionMetadataMode
from torch.fx.experimental.proxy_tensor import U
from torch.fx.experimental.proxy_tensor import count
from torch.fx.experimental.proxy_tensor import decompose
from torch.fx.experimental.proxy_tensor import disable_autocast_cache
from torch.fx.experimental.proxy_tensor import disable_proxy_modes_tracing
from torch.fx.experimental.proxy_tensor import dispatch_trace
from torch.fx.experimental.proxy_tensor import extract_val
from torch.fx.experimental.proxy_tensor import fake_signature
from torch.fx.experimental.proxy_tensor import fast_detach
from torch.fx.experimental.proxy_tensor import fetch_object_proxy
from torch.fx.experimental.proxy_tensor import fetch_sym_proxy
from torch.fx.experimental.proxy_tensor import get_innermost_proxy_mode
from torch.fx.experimental.proxy_tensor import get_isolated_graphmodule
from torch.fx.experimental.proxy_tensor import get_proxy_mode
from torch.fx.experimental.proxy_tensor import get_proxy_slot
from torch.fx.experimental.proxy_tensor import get_torch_dispatch_modes
from torch.fx.experimental.proxy_tensor import handle_sym_dispatch
from torch.fx.experimental.proxy_tensor import has_proxy_slot
from torch.fx.experimental.proxy_tensor import is_sym_node
from torch.fx.experimental.proxy_tensor import make_fx
from torch.fx.experimental.proxy_tensor import maybe_disable_thunkify
from torch.fx.experimental.proxy_tensor import maybe_enable_thunkify
from torch.fx.experimental.proxy_tensor import maybe_handle_decomp
from torch.fx.experimental.proxy_tensor import no_default
from torch.fx.experimental.proxy_tensor import proxy_call
from torch.fx.experimental.proxy_tensor import proxy_slot
from torch.fx.experimental.proxy_tensor import py_sym_types
from torch.fx.experimental.proxy_tensor import set_meta
from torch.fx.experimental.proxy_tensor import set_original_aten_op
from torch.fx.experimental.proxy_tensor import set_proxy_slot
from torch.fx.experimental.proxy_tensor import snapshot_fake
from torch.fx.experimental.proxy_tensor import thunkify
from torch.fx.experimental.proxy_tensor import trace_structured
from torch.fx.experimental.proxy_tensor import track_tensor
from torch.fx.experimental.proxy_tensor import track_tensor_tree
from torch.fx.experimental.proxy_tensor import wrap_key
from torch.fx.experimental.proxy_tensor import wrapper_and_args_for_make_fx
from torch.fx.experimental.recording import FakeTensorMeta
from torch.fx.experimental.recording import NotEqualError
from torch.fx.experimental.recording import ShapeEnvEvent
from torch.fx.experimental.recording import record_shapeenv_event
from torch.fx.experimental.recording import replay_shape_env_events
from torch.fx.experimental.recording import shape_env_check_state_equal
from torch.fx.experimental.refinement_types import Equality
from torch.fx.experimental.rewriter import AST_Rewriter
from torch.fx.experimental.rewriter import RewritingTracer
from torch.fx.experimental.rewriter import normalize_source_lines
from torch.fx.experimental.schema_type_annotation import AnnotateTypesWithSchema
from torch.fx.experimental.sym_node import METHOD_TO_OPERATOR
from torch.fx.experimental.sym_node import SymNode
from torch.fx.experimental.sym_node import SymTypes
from torch.fx.experimental.sym_node import also_bool_magic_methods
from torch.fx.experimental.sym_node import always_bool_magic_methods
from torch.fx.experimental.sym_node import always_float_magic_methods
from torch.fx.experimental.sym_node import always_int_magic_methods
from torch.fx.experimental.sym_node import bitwise_ops
from torch.fx.experimental.sym_node import bool_becomes_int_magic_methods
from torch.fx.experimental.sym_node import bool_magic_methods
from torch.fx.experimental.sym_node import dtrace_structured
from torch.fx.experimental.sym_node import is_channels_last_contiguous_2d
from torch.fx.experimental.sym_node import magic_methods
from torch.fx.experimental.sym_node import magic_methods_on_operator_with_trailing_underscore
from torch.fx.experimental.sym_node import method_to_operator
from torch.fx.experimental.sym_node import only_bool_magic_methods
from torch.fx.experimental.sym_node import only_float_magic_methods
from torch.fx.experimental.sym_node import priv_sym_name
from torch.fx.experimental.sym_node import reflectable_magic_methods
from torch.fx.experimental.sym_node import sizes_strides_methods
from torch.fx.experimental.sym_node import sympy_is_channels_last_contiguous_2d
from torch.fx.experimental.sym_node import sympy_is_channels_last_contiguous_3d
from torch.fx.experimental.sym_node import sympy_is_channels_last_strides_2d
from torch.fx.experimental.sym_node import sympy_is_channels_last_strides_3d
from torch.fx.experimental.sym_node import sympy_is_channels_last_strides_generic
from torch.fx.experimental.sym_node import sympy_is_contiguous
from torch.fx.experimental.sym_node import sympy_is_contiguous_generic
from torch.fx.experimental.sym_node import to_node
from torch.fx.experimental.sym_node import unary_magic_methods
from torch.fx.experimental.sym_node import unary_methods
from torch.fx.experimental.sym_node import unary_nonmagic_methods
from torch.fx.experimental.sym_node import wrap_node
from torch.fx.experimental.symbolic_shapes import BoolLike
from torch.fx.experimental.symbolic_shapes import CallMethodKey
from torch.fx.experimental.symbolic_shapes import CeilToInt
from torch.fx.experimental.symbolic_shapes import CleanDiv
from torch.fx.experimental.symbolic_shapes import Constraint
from torch.fx.experimental.symbolic_shapes import ConstraintViolationError
from torch.fx.experimental.symbolic_shapes import ConvertIntKey
from torch.fx.experimental.symbolic_shapes import CppPrinter
from torch.fx.experimental.symbolic_shapes import DimConstraints
from torch.fx.experimental.symbolic_shapes import DimDynamic
from torch.fx.experimental.symbolic_shapes import DivideByKey
from torch.fx.experimental.symbolic_shapes import DynamicDimConstraintPrinter
from torch.fx.experimental.symbolic_shapes import EqualityConstraint
from torch.fx.experimental.symbolic_shapes import FloatLike
from torch.fx.experimental.symbolic_shapes import FloorDiv
from torch.fx.experimental.symbolic_shapes import FloorToInt
from torch.fx.experimental.symbolic_shapes import GuardOnDataDependentSymNode
from torch.fx.experimental.symbolic_shapes import IndicatorTypes
from torch.fx.experimental.symbolic_shapes import InnerTensorKey
from torch.fx.experimental.symbolic_shapes import IntLike
from torch.fx.experimental.symbolic_shapes import IntTrueDiv
from torch.fx.experimental.symbolic_shapes import IsNonOverlappingAndDenseIndicator
from torch.fx.experimental.symbolic_shapes import LazyString
from torch.fx.experimental.symbolic_shapes import LoggingShapeGuardPrinter
from torch.fx.experimental.symbolic_shapes import Max
from torch.fx.experimental.symbolic_shapes import Min
from torch.fx.experimental.symbolic_shapes import Mod
from torch.fx.experimental.symbolic_shapes import PendingUnbackedSymbolNotFound
from torch.fx.experimental.symbolic_shapes import PropagateUnbackedSymInts
from torch.fx.experimental.symbolic_shapes import PythonMod
from torch.fx.experimental.symbolic_shapes import PythonPrinter
from torch.fx.experimental.symbolic_shapes import RelaxedUnspecConstraint
from torch.fx.experimental.symbolic_shapes import RuntimeAssert
from torch.fx.experimental.symbolic_shapes import SLoc
from torch.fx.experimental.symbolic_shapes import SYMPY_INTERP
from torch.fx.experimental.symbolic_shapes import ShapeEnv
from torch.fx.experimental.symbolic_shapes import ShapeEnvSettings
from torch.fx.experimental.symbolic_shapes import ShapeGuard
from torch.fx.experimental.symbolic_shapes import ShapeGuardPrinter
from torch.fx.experimental.symbolic_shapes import ShapeGuardPythonPrinter
from torch.fx.experimental.symbolic_shapes import SingletonInt
from torch.fx.experimental.symbolic_shapes import Source
from torch.fx.experimental.symbolic_shapes import Specialization
from torch.fx.experimental.symbolic_shapes import StatefulSymbolicContext
from torch.fx.experimental.symbolic_shapes import StatelessSymbolicContext
from torch.fx.experimental.symbolic_shapes import StrictMinMaxConstraint
from torch.fx.experimental.symbolic_shapes import SubclassSymbolicContext
from torch.fx.experimental.symbolic_shapes import SymExprPrinter
from torch.fx.experimental.symbolic_shapes import SymIntEqByExpr
from torch.fx.experimental.symbolic_shapes import SymIntSymbolicContext
from torch.fx.experimental.symbolic_shapes import SymPyValueRangeAnalysis
from torch.fx.experimental.symbolic_shapes import SymT
from torch.fx.experimental.symbolic_shapes import SymTypes
from torch.fx.experimental.symbolic_shapes import SymbolicContext
from torch.fx.experimental.symbolic_shapes import SympyBoolean
from torch.fx.experimental.symbolic_shapes import TrackedFake
from torch.fx.experimental.symbolic_shapes import TruncToInt
from torch.fx.experimental.symbolic_shapes import ValueRangeError
from torch.fx.experimental.symbolic_shapes import ValueRanges
from torch.fx.experimental.symbolic_shapes import ValueRangesSLoc
from torch.fx.experimental.symbolic_shapes import bind_symbols
from torch.fx.experimental.symbolic_shapes import bound_sympy
from torch.fx.experimental.symbolic_shapes import canonicalize_bool_expr
from torch.fx.experimental.symbolic_shapes import cast_symbool_to_symint_guardless
from torch.fx.experimental.symbolic_shapes import check_consistent
from torch.fx.experimental.symbolic_shapes import compute_unbacked_bindings
from torch.fx.experimental.symbolic_shapes import constrain_range
from torch.fx.experimental.symbolic_shapes import constrain_unify
from torch.fx.experimental.symbolic_shapes import create_contiguous
from torch.fx.experimental.symbolic_shapes import error
from torch.fx.experimental.symbolic_shapes import eval_guards
from torch.fx.experimental.symbolic_shapes import eval_is_non_overlapping_and_dense
from torch.fx.experimental.symbolic_shapes import expect_true
from torch.fx.experimental.symbolic_shapes import find_symbol_binding_fx_nodes
from torch.fx.experimental.symbolic_shapes import format_frame
from torch.fx.experimental.symbolic_shapes import free_symbols
from torch.fx.experimental.symbolic_shapes import free_unbacked_symbols
from torch.fx.experimental.symbolic_shapes import fx_placeholder_targets
from torch.fx.experimental.symbolic_shapes import fx_placeholder_vals
from torch.fx.experimental.symbolic_shapes import guard_bool
from torch.fx.experimental.symbolic_shapes import guard_float
from torch.fx.experimental.symbolic_shapes import guard_int
from torch.fx.experimental.symbolic_shapes import guard_or_false
from torch.fx.experimental.symbolic_shapes import guard_or_true
from torch.fx.experimental.symbolic_shapes import guard_scalar
from torch.fx.experimental.symbolic_shapes import guard_size_oblivious
from torch.fx.experimental.symbolic_shapes import has_free_symbols
from torch.fx.experimental.symbolic_shapes import has_free_unbacked_symbols
from torch.fx.experimental.symbolic_shapes import has_hint
from torch.fx.experimental.symbolic_shapes import has_static_value
from torch.fx.experimental.symbolic_shapes import has_symbolic_sizes_strides
from torch.fx.experimental.symbolic_shapes import hint_int
from torch.fx.experimental.symbolic_shapes import int_oo
from torch.fx.experimental.symbolic_shapes import is_accessor_node
from torch.fx.experimental.symbolic_shapes import is_concrete_bool
from torch.fx.experimental.symbolic_shapes import is_concrete_float
from torch.fx.experimental.symbolic_shapes import is_concrete_int
from torch.fx.experimental.symbolic_shapes import is_nested_int
from torch.fx.experimental.symbolic_shapes import is_symbol_binding_fx_node
from torch.fx.experimental.symbolic_shapes import is_symbolic
from torch.fx.experimental.symbolic_shapes import log_lru_cache_stats
from torch.fx.experimental.symbolic_shapes import lru_cache
from torch.fx.experimental.symbolic_shapes import make_symbol
from torch.fx.experimental.symbolic_shapes import py_sym_types
from torch.fx.experimental.symbolic_shapes import rebind_unbacked
from torch.fx.experimental.symbolic_shapes import resolve_unbacked_bindings
from torch.fx.experimental.symbolic_shapes import safe_expand
from torch.fx.experimental.symbolic_shapes import signpost_event
from torch.fx.experimental.symbolic_shapes import statically_known_false
from torch.fx.experimental.symbolic_shapes import statically_known_true
from torch.fx.experimental.symbolic_shapes import sym_and
from torch.fx.experimental.symbolic_shapes import sym_eq
from torch.fx.experimental.symbolic_shapes import sym_or
from torch.fx.experimental.symbolic_shapes import symbol_is_type
from torch.fx.experimental.symbolic_shapes import try_solve
from torch.fx.experimental.symbolic_shapes import uninteresting_files
from torch.fx.experimental.unification import isvar
from torch.fx.experimental.unification import unify
from torch.fx.experimental.unification.core import reify
from torch.fx.experimental.unification.core import seq
from torch.fx.experimental.unification.dispatch import namespace
from torch.fx.experimental.unification.match import Dispatcher
from torch.fx.experimental.unification.match import VarDispatcher
from torch.fx.experimental.unification.match import edge
from torch.fx.experimental.unification.match import global_namespace
from torch.fx.experimental.unification.match import match
from torch.fx.experimental.unification.match import ordering
from torch.fx.experimental.unification.match import supercedes
from torch.fx.experimental.unification.more import reify_object
from torch.fx.experimental.unification.more import unifiable
from torch.fx.experimental.unification.more import unify_object
from torch.fx.experimental.unification.multipledispatch.conflict import AmbiguityWarning
from torch.fx.experimental.unification.multipledispatch.conflict import ambiguities
from torch.fx.experimental.unification.multipledispatch.conflict import ambiguous
from torch.fx.experimental.unification.multipledispatch.conflict import consistent
from torch.fx.experimental.unification.multipledispatch.conflict import edge
from torch.fx.experimental.unification.multipledispatch.conflict import ordering
from torch.fx.experimental.unification.multipledispatch.conflict import super_signature
from torch.fx.experimental.unification.multipledispatch.conflict import supercedes
from torch.fx.experimental.unification.multipledispatch.core import dispatch
from torch.fx.experimental.unification.multipledispatch.core import global_namespace
from torch.fx.experimental.unification.multipledispatch.core import ismethod
from torch.fx.experimental.unification.multipledispatch.dispatcher import Dispatcher
from torch.fx.experimental.unification.multipledispatch.dispatcher import MDNotImplementedError
from torch.fx.experimental.unification.multipledispatch.dispatcher import MethodDispatcher
from torch.fx.experimental.unification.multipledispatch.dispatcher import ambiguity_warn
from torch.fx.experimental.unification.multipledispatch.dispatcher import halt_ordering
from torch.fx.experimental.unification.multipledispatch.dispatcher import restart_ordering
from torch.fx.experimental.unification.multipledispatch.dispatcher import source
from torch.fx.experimental.unification.multipledispatch.dispatcher import str_signature
from torch.fx.experimental.unification.multipledispatch.dispatcher import variadic_signature_matches
from torch.fx.experimental.unification.multipledispatch.dispatcher import variadic_signature_matches_iter
from torch.fx.experimental.unification.multipledispatch.dispatcher import warning_text
from torch.fx.experimental.unification.multipledispatch.utils import expand_tuples
from torch.fx.experimental.unification.multipledispatch.utils import groupby
from torch.fx.experimental.unification.multipledispatch.utils import raises
from torch.fx.experimental.unification.multipledispatch.utils import reverse_dict
from torch.fx.experimental.unification.multipledispatch.utils import typename
from torch.fx.experimental.unification.multipledispatch.variadic import Variadic
from torch.fx.experimental.unification.multipledispatch.variadic import VariadicSignatureMeta
from torch.fx.experimental.unification.multipledispatch.variadic import VariadicSignatureType
from torch.fx.experimental.unification.multipledispatch.variadic import isvariadic
from torch.fx.experimental.unification.unification_tools import assoc
from torch.fx.experimental.unification.unification_tools import assoc_in
from torch.fx.experimental.unification.unification_tools import dissoc
from torch.fx.experimental.unification.unification_tools import first
from torch.fx.experimental.unification.unification_tools import get_in
from torch.fx.experimental.unification.unification_tools import getter
from torch.fx.experimental.unification.unification_tools import groupby
from torch.fx.experimental.unification.unification_tools import itemfilter
from torch.fx.experimental.unification.unification_tools import itemmap
from torch.fx.experimental.unification.unification_tools import keyfilter
from torch.fx.experimental.unification.unification_tools import keymap
from torch.fx.experimental.unification.unification_tools import merge
from torch.fx.experimental.unification.unification_tools import merge_with
from torch.fx.experimental.unification.unification_tools import update_in
from torch.fx.experimental.unification.unification_tools import valfilter
from torch.fx.experimental.unification.unification_tools import valmap
from torch.fx.experimental.unification.utils import freeze
from torch.fx.experimental.unification.utils import hashable
from torch.fx.experimental.unification.utils import raises
from torch.fx.experimental.unification.utils import reverse_dict
from torch.fx.experimental.unification.utils import transitive_get
from torch.fx.experimental.unification.utils import xfail
from torch.fx.experimental.unification.variable import Var
from torch.fx.experimental.unification.variable import var
from torch.fx.experimental.unification.variable import variables
from torch.fx.experimental.unification.variable import vars
from torch.fx.experimental.unify_refinements import check_for_type_equality
from torch.fx.experimental.unify_refinements import convert_eq
from torch.fx.experimental.unify_refinements import infer_symbolic_types
from torch.fx.experimental.unify_refinements import infer_symbolic_types_single_pass
from torch.fx.experimental.unify_refinements import substitute_all_types
from torch.fx.experimental.unify_refinements import substitute_solution_one_type
from torch.fx.experimental.unify_refinements import unify_eq
from torch.fx.experimental.validator import BisectValidationException
from torch.fx.experimental.validator import TorchDynamoException
from torch.fx.experimental.validator import ValidationException
from torch.fx.experimental.validator import bisect
from torch.fx.experimental.validator import dynamo_timed
from torch.fx.experimental.validator import sympy_interp
from torch.fx.experimental.validator import translation_validation_enabled
from torch.fx.experimental.validator import translation_validation_timeout
from torch.fx.graph import CodeGen
from torch.fx.graph import Graph
from torch.fx.graph import PythonCode
from torch.fx.graph import dtype_abbrs
from torch.fx.graph import inplace_methods
from torch.fx.graph import magic_methods
from torch.fx.graph import reflectable_magic_methods
from torch.fx.graph_module import GraphModule
from torch.fx.graph_module import reduce_deploy_graph_module
from torch.fx.graph_module import reduce_graph_module
from torch.fx.graph_module import reduce_package_graph_module
from torch.fx.graph_module import sys_importer
from torch.fx.immutable_collections import immutable_dict
from torch.fx.immutable_collections import immutable_list
from torch.fx.interpreter import Interpreter
from torch.fx.interpreter import Transformer
from torch.fx.node import ArgumentT
from torch.fx.node import Node
from torch.fx.node import base_types
from torch.fx.node import has_side_effect
from torch.fx.node import map_aggregate
from torch.fx.node import map_arg
from torch.fx.operator_schemas import ArgsKwargsPair
from torch.fx.operator_schemas import check_for_mutable_operation
from torch.fx.operator_schemas import create_type_hint
from torch.fx.operator_schemas import get_signature_for_torch_op
from torch.fx.operator_schemas import k
from torch.fx.operator_schemas import normalize_function
from torch.fx.operator_schemas import normalize_module
from torch.fx.operator_schemas import type_matches
from torch.fx.passes.annotate_getitem_nodes import annotate_getitem_nodes
from torch.fx.passes.backends.cudagraphs import CALLABLE_NODE_OPS
from torch.fx.passes.backends.cudagraphs import CudaGraphsSupport
from torch.fx.passes.backends.cudagraphs import partition_cudagraphs
from torch.fx.passes.dialect.common.cse_pass import CSEPass
from torch.fx.passes.dialect.common.cse_pass import get_CSE_banned_ops
from torch.fx.passes.dialect.common.cse_pass import inplace_ops
from torch.fx.passes.dialect.common.cse_pass import rand_ops
from torch.fx.passes.fake_tensor_prop import FakeTensorProp
from torch.fx.passes.fake_tensor_prop import OrderedSet
from torch.fx.passes.fake_tensor_prop import py_sym_types
from torch.fx.passes.graph_drawer import FxGraphDrawer
from torch.fx.passes.graph_drawer import pydot
from torch.fx.passes.graph_manipulation import get_size_of_all_nodes
from torch.fx.passes.graph_manipulation import get_size_of_node
from torch.fx.passes.graph_manipulation import get_tensor_meta
from torch.fx.passes.graph_manipulation import replace_target_nodes_with
from torch.fx.passes.graph_manipulation import size_bytes
from torch.fx.passes.graph_transform_observer import GraphTransformObserver
from torch.fx.passes.graph_transform_observer import T
from torch.fx.passes.infra.partitioner import CapabilityBasedPartitioner
from torch.fx.passes.infra.partitioner import Partition
from torch.fx.passes.infra.pass_base import PassBase
from torch.fx.passes.infra.pass_base import PassResult
from torch.fx.passes.infra.pass_manager import PassManager
from torch.fx.passes.infra.pass_manager import pass_result_wrapper
from torch.fx.passes.infra.pass_manager import this_before_that_pass_constraint
from torch.fx.passes.net_min_base import CALLABLE_NODE_OPS
from torch.fx.passes.net_min_base import FxNetMinimizerBadModuleError
from torch.fx.passes.net_min_base import FxNetMinimizerResultMismatchError
from torch.fx.passes.net_min_base import FxNetMinimizerRunFuncError
from torch.fx.passes.operator_support import CALLABLE_NODE_OPS
from torch.fx.passes.operator_support import OpSupports
from torch.fx.passes.operator_support import OperatorSupport
from torch.fx.passes.operator_support import OperatorSupportBase
from torch.fx.passes.operator_support import any_chain
from torch.fx.passes.operator_support import chain
from torch.fx.passes.operator_support import create_op_support
from torch.fx.passes.param_fetch import default_matching
from torch.fx.passes.param_fetch import extract_attrs_for_lowering
from torch.fx.passes.param_fetch import lift_lowering_attrs_to_nodes
from torch.fx.passes.param_fetch import module_fetch_book
from torch.fx.passes.pass_manager import PassManager
from torch.fx.passes.pass_manager import inplace_wrapper
from torch.fx.passes.pass_manager import log_hook
from torch.fx.passes.pass_manager import loop_pass
from torch.fx.passes.pass_manager import these_before_those_pass_constraint
from torch.fx.passes.pass_manager import this_before_that_pass_constraint
from torch.fx.passes.reinplace import FakeTensor
from torch.fx.passes.reinplace import FakeTensorMode
from torch.fx.passes.reinplace import reinplace
from torch.fx.passes.reinplace import tree_map_only
from torch.fx.passes.runtime_assert import insert_deferred_runtime_asserts
from torch.fx.passes.runtime_assert import py_sym_types
from torch.fx.passes.shape_prop import ShapeProp
from torch.fx.passes.shape_prop import TensorMetadata
from torch.fx.passes.shape_prop import contiguous_for_memory_format_or_false
from torch.fx.passes.shape_prop import detect_fake_mode
from torch.fx.passes.shape_prop import is_sparse_any
from torch.fx.passes.split_module import Partition
from torch.fx.passes.split_module import lazy_format_graph_code
from torch.fx.passes.split_module import split_module
from torch.fx.passes.split_utils import Component
from torch.fx.passes.split_utils import getattr_recursive
from torch.fx.passes.split_utils import setattr_recursive
from torch.fx.passes.split_utils import split_by_tags
from torch.fx.passes.splitter_base import CALLABLE_NODE_OPS
from torch.fx.passes.splitter_base import FxNetAccNodesFinder
from torch.fx.passes.splitter_base import FxNetSplitterInternalError
from torch.fx.passes.splitter_base import SplitResult
from torch.fx.passes.splitter_base import Subgraph
from torch.fx.passes.splitter_base import generate_inputs_for_submodules
from torch.fx.passes.tests.test_pass_manager import TestPassManager
from torch.fx.passes.tools_common import CALLABLE_NODE_OPS
from torch.fx.passes.tools_common import FxNetAccFusionsFinder
from torch.fx.passes.tools_common import get_acc_ops_name
from torch.fx.passes.tools_common import get_node_target
from torch.fx.passes.tools_common import is_node_output_tensor
from torch.fx.passes.tools_common import legalize_graph
from torch.fx.passes.utils.common import HolderModule
from torch.fx.passes.utils.common import compare_graphs
from torch.fx.passes.utils.common import lift_subgraph_as_module
from torch.fx.passes.utils.fuser_utils import erase_nodes
from torch.fx.passes.utils.fuser_utils import fuse_as_graphmodule
from torch.fx.passes.utils.fuser_utils import fuse_by_partitions
from torch.fx.passes.utils.fuser_utils import insert_subgm
from torch.fx.passes.utils.fuser_utils import topo_sort
from torch.fx.passes.utils.fuser_utils import validate_partition
from torch.fx.passes.utils.matcher_utils import InternalMatch
from torch.fx.passes.utils.matcher_utils import SubgraphMatcher
from torch.fx.passes.utils.matcher_with_name_node_map_utils import SubgraphMatcherWithNameNodeMap
from torch.fx.passes.utils.source_matcher_utils import SourcePartition
from torch.fx.passes.utils.source_matcher_utils import check_subgraphs_connected
from torch.fx.passes.utils.source_matcher_utils import get_source_partitions
from torch.fx.proxy import Attribute
from torch.fx.proxy import CapturedTraceback
from torch.fx.proxy import GraphAppendingTracer
from torch.fx.proxy import MetaProxy
from torch.fx.proxy import ParameterProxy
from torch.fx.proxy import Proxy
from torch.fx.proxy import Scope
from torch.fx.proxy import ScopeContextManager
from torch.fx.proxy import TraceError
from torch.fx.proxy import TracerBase
from torch.fx.proxy import assert_fn
from torch.fx.proxy import base_types
from torch.fx.proxy import magic_methods
from torch.fx.proxy import method
from torch.fx.proxy import orig_method_name
from torch.fx.proxy import reflectable_magic_methods
from torch.fx.subgraph_rewriter import Match
from torch.fx.subgraph_rewriter import ReplacedPatterns
from torch.fx.subgraph_rewriter import replace_pattern
from torch.fx.subgraph_rewriter import replace_pattern_with_filters
from torch.fx.tensor_type import TensorType
from torch.fx.tensor_type import is_consistent
from torch.fx.tensor_type import is_more_precise
from torch.fx.traceback import NodeSource
from torch.fx.traceback import NodeSourceAction
from torch.fx.traceback import current_meta
from torch.fx.traceback import format_stack
from torch.fx.traceback import get_current_meta
from torch.fx.traceback import get_graph_provenance_json
from torch.fx.traceback import has_preserved_node_meta
from torch.fx.traceback import preserve_node_meta
from torch.fx.traceback import reset_grad_fn_seq_nr
from torch.fx.traceback import set_current_meta
from torch.fx.traceback import set_grad_fn_seq_nr
from torch.fx.traceback import set_stack_trace
from torch.fx.traceback import should_preserve_node_meta
from torch.hub import download_url_to_file
from torch.hub import get_dir
from torch.hub import help
from torch.hub import list
from torch.hub import load
from torch.hub import load_state_dict_from_url
from torch.hub import set_dir
from torch.jit import Attribute
from torch.jit import CompilationUnit
from torch.jit import Error
from torch.jit import Future
from torch.jit import ONNXTracedModule
from torch.jit import RecursiveScriptClass
from torch.jit import RecursiveScriptModule
from torch.jit import ScriptFunction
from torch.jit import ScriptModule
from torch.jit import ScriptWarning
from torch.jit import TopLevelTracedModule
from torch.jit import TracedModule
from torch.jit import TracerWarning
from torch.jit import TracingCheckError
from torch.jit import annotate
from torch.jit import enable_onednn_fusion
from torch.jit import export
from torch.jit import export_opnames
from torch.jit import fork
from torch.jit import freeze
from torch.jit import fuser
from torch.jit import ignore
from torch.jit import interface
from torch.jit import is_scripting
from torch.jit import is_tracing
from torch.jit import isinstance
from torch.jit import jit_module_from_flatbuffer
from torch.jit import load
from torch.jit import onednn_fusion_enabled
from torch.jit import optimize_for_inference
from torch.jit import optimized_execution
from torch.jit import run_frozen_optimizations
from torch.jit import save
from torch.jit import save_jit_module_to_flatbuffer
from torch.jit import script
from torch.jit import script_if_tracing
from torch.jit import script_method
from torch.jit import set_fusion_strategy
from torch.jit import strict_fusion
from torch.jit import trace
from torch.jit import trace_module
from torch.jit import unused
from torch.jit import wait
from torch.jit.annotations import BroadcastingList1
from torch.jit.annotations import BroadcastingList2
from torch.jit.annotations import BroadcastingList3
from torch.jit.annotations import EvalEnv
from torch.jit.annotations import Module
from torch.jit.annotations import OpOverloadPacket
from torch.jit.annotations import ann_to_type
from torch.jit.annotations import check_fn
from torch.jit.annotations import get_enum_value_type
from torch.jit.annotations import get_param_names
from torch.jit.annotations import get_signature
from torch.jit.annotations import get_type_line
from torch.jit.annotations import is_await
from torch.jit.annotations import is_dict
from torch.jit.annotations import is_function_or_method
from torch.jit.annotations import is_future
from torch.jit.annotations import is_ignored_fn
from torch.jit.annotations import is_list
from torch.jit.annotations import is_optional
from torch.jit.annotations import is_tensor
from torch.jit.annotations import is_tuple
from torch.jit.annotations import is_union
from torch.jit.annotations import is_vararg
from torch.jit.annotations import parse_type_line
from torch.jit.annotations import split_type_line
from torch.jit.annotations import try_ann_to_type
from torch.jit.annotations import try_real_annotations
from torch.jit.frontend import Apply
from torch.jit.frontend import Assert
from torch.jit.frontend import Assign
from torch.jit.frontend import Attribute
from torch.jit.frontend import AugAssign
from torch.jit.frontend import BinOp
from torch.jit.frontend import Break
from torch.jit.frontend import Builder
from torch.jit.frontend import ClassDef
from torch.jit.frontend import Const
from torch.jit.frontend import Continue
from torch.jit.frontend import DATACLASS_MAGIC_METHODS
from torch.jit.frontend import Decl
from torch.jit.frontend import Def
from torch.jit.frontend import Delete
from torch.jit.frontend import DictComp
from torch.jit.frontend import DictLiteral
from torch.jit.frontend import Dots
from torch.jit.frontend import EmptyTypeAnnotation
from torch.jit.frontend import ExprBuilder
from torch.jit.frontend import ExprStmt
from torch.jit.frontend import FalseLiteral
from torch.jit.frontend import For
from torch.jit.frontend import FrontendError
from torch.jit.frontend import FrontendTypeError
from torch.jit.frontend import FunctionModifiers
from torch.jit.frontend import Ident
from torch.jit.frontend import If
from torch.jit.frontend import ListComp
from torch.jit.frontend import ListLiteral
from torch.jit.frontend import NoneLiteral
from torch.jit.frontend import NotSupportedError
from torch.jit.frontend import Param
from torch.jit.frontend import Pass
from torch.jit.frontend import Property
from torch.jit.frontend import Raise
from torch.jit.frontend import Return
from torch.jit.frontend import Select
from torch.jit.frontend import SliceExpr
from torch.jit.frontend import Starred
from torch.jit.frontend import Stmt
from torch.jit.frontend import StmtBuilder
from torch.jit.frontend import StringLiteral
from torch.jit.frontend import Subscript
from torch.jit.frontend import TernaryIf
from torch.jit.frontend import TrueLiteral
from torch.jit.frontend import TupleLiteral
from torch.jit.frontend import UnaryOp
from torch.jit.frontend import UnsupportedNodeError
from torch.jit.frontend import Var
from torch.jit.frontend import While
from torch.jit.frontend import With
from torch.jit.frontend import WithItem
from torch.jit.frontend import WithItemBuilder
from torch.jit.frontend import build_class_def
from torch.jit.frontend import build_def
from torch.jit.frontend import build_expr
from torch.jit.frontend import build_ignore_context_manager
from torch.jit.frontend import build_param
from torch.jit.frontend import build_param_list
from torch.jit.frontend import build_stmt
from torch.jit.frontend import build_stmts
from torch.jit.frontend import build_withitem
from torch.jit.frontend import build_withitems
from torch.jit.frontend import find_before
from torch.jit.frontend import get_class_assigns
from torch.jit.frontend import get_class_properties
from torch.jit.frontend import get_default_args
from torch.jit.frontend import get_default_args_for_class
from torch.jit.frontend import get_jit_class_def
from torch.jit.frontend import get_jit_def
from torch.jit.frontend import get_qualified_name
from torch.jit.frontend import get_source_lines_and_file
from torch.jit.frontend import is_reserved_name
from torch.jit.frontend import is_static_fn
from torch.jit.frontend import is_torch_jit_ignore_context_manager
from torch.jit.frontend import make_source_context
from torch.jit.frontend import monkeytype_trace
from torch.jit.frontend import node_start_tokens
from torch.jit.frontend import parse_def
from torch.jit.frontend import pretty_node_names
from torch.jit.frontend import should_drop
from torch.jit.generate_bytecode import format_bytecode
from torch.jit.generate_bytecode import generate_upgraders_bytecode
from torch.jit.mobile import LiteScriptModule
from torch.jit.mobile import validate_map_location
from torch.jit.quantized import QuantizedGRU
from torch.jit.quantized import QuantizedGRUCell
from torch.jit.quantized import QuantizedLSTM
from torch.jit.quantized import QuantizedLSTMCell
from torch.jit.quantized import QuantizedLinear
from torch.jit.quantized import QuantizedLinearFP16
from torch.jit.quantized import QuantizedRNNBase
from torch.jit.quantized import QuantizedRNNCell
from torch.jit.quantized import QuantizedRNNCellBase
from torch.jit.quantized import quantize_linear_modules
from torch.jit.quantized import quantize_rnn_cell_modules
from torch.jit.quantized import quantize_rnn_modules
from torch.jit.unsupported_tensor_ops import execWrapper
from torch.library import CustomOpDef
from torch.library import Library
from torch.library import OpOverload
from torch.library import custom_op
from torch.library import define
from torch.library import fallthrough_kernel
from torch.library import get_ctx
from torch.library import impl
from torch.library import impl_abstract
from torch.library import infer_schema
from torch.library import opcheck
from torch.library import register_autocast
from torch.library import register_autograd
from torch.library import register_fake
from torch.library import register_kernel
from torch.library import register_torch_dispatch
from torch.library import register_vmap
from torch.library import triton_op
from torch.library import wrap_triton
from torch.linalg import cholesky
from torch.linalg import cholesky_ex
from torch.linalg import common_notes
from torch.linalg import cond
from torch.linalg import cross
from torch.linalg import det
from torch.linalg import diagonal
from torch.linalg import eig
from torch.linalg import eigh
from torch.linalg import eigvals
from torch.linalg import eigvalsh
from torch.linalg import householder_product
from torch.linalg import inv
from torch.linalg import inv_ex
from torch.linalg import ldl_factor
from torch.linalg import ldl_factor_ex
from torch.linalg import ldl_solve
from torch.linalg import lstsq
from torch.linalg import lu
from torch.linalg import lu_factor
from torch.linalg import lu_factor_ex
from torch.linalg import lu_solve
from torch.linalg import matmul
from torch.linalg import matrix_exp
from torch.linalg import matrix_norm
from torch.linalg import matrix_power
from torch.linalg import matrix_rank
from torch.linalg import multi_dot
from torch.linalg import norm
from torch.linalg import pinv
from torch.linalg import qr
from torch.linalg import slogdet
from torch.linalg import solve
from torch.linalg import solve_ex
from torch.linalg import solve_triangular
from torch.linalg import svd
from torch.linalg import svdvals
from torch.linalg import tensorinv
from torch.linalg import tensorsolve
from torch.linalg import vander
from torch.linalg import vecdot
from torch.linalg import vector_norm
from torch.masked import amax
from torch.masked import amin
from torch.masked import argmax
from torch.masked import argmin
from torch.masked import cumprod
from torch.masked import cumsum
from torch.masked import log_softmax
from torch.masked import logaddexp
from torch.masked import logsumexp
from torch.masked import mean
from torch.masked import median
from torch.masked import norm
from torch.masked import normalize
from torch.masked import prod
from torch.masked import softmax
from torch.masked import softmin
from torch.masked import std
from torch.masked import sum
from torch.masked import var
from torch.masked.maskedtensor.binary import BINARY_NAMES
from torch.masked.maskedtensor.binary import INPLACE_BINARY_NAMES
from torch.masked.maskedtensor.binary import NATIVE_BINARY_FNS
from torch.masked.maskedtensor.binary import NATIVE_BINARY_MAP
from torch.masked.maskedtensor.binary import NATIVE_INPLACE_BINARY_FNS
from torch.masked.maskedtensor.binary import NATIVE_INPLACE_BINARY_MAP
from torch.masked.maskedtensor.core import MaskedTensor
from torch.masked.maskedtensor.core import is_masked_tensor
from torch.masked.maskedtensor.creation import as_masked_tensor
from torch.masked.maskedtensor.creation import masked_tensor
from torch.masked.maskedtensor.passthrough import PASSTHROUGH_FNS
from torch.masked.maskedtensor.reductions import NATIVE_REDUCE_FNS
from torch.masked.maskedtensor.reductions import NATIVE_REDUCE_MAP
from torch.masked.maskedtensor.reductions import REDUCE_NAMES
from torch.masked.maskedtensor.reductions import TENSOR_REDUCE_FNS
from torch.masked.maskedtensor.reductions import TENSOR_REDUCE_MAP
from torch.masked.maskedtensor.reductions import TORCH_REDUCE_FNS
from torch.masked.maskedtensor.reductions import TORCH_REDUCE_MAP
from torch.masked.maskedtensor.unary import INPLACE_UNARY_NAMES
from torch.masked.maskedtensor.unary import NATIVE_INPLACE_UNARY_FNS
from torch.masked.maskedtensor.unary import NATIVE_INPLACE_UNARY_MAP
from torch.masked.maskedtensor.unary import NATIVE_UNARY_FNS
from torch.masked.maskedtensor.unary import NATIVE_UNARY_MAP
from torch.masked.maskedtensor.unary import UNARY_NAMES
from torch.masked.maskedtensor.unary import UNARY_NAMES_UNSUPPORTED
from torch.monitor import Aggregation
from torch.monitor import COUNT
from torch.monitor import Event
from torch.monitor import EventHandlerHandle
from torch.monitor import MAX
from torch.monitor import MEAN
from torch.monitor import MIN
from torch.monitor import SUM
from torch.monitor import Stat
from torch.monitor import TensorboardEventHandler
from torch.monitor import VALUE
from torch.monitor import data_value_t
from torch.monitor import log_event
from torch.monitor import register_event_handler
from torch.monitor import unregister_event_handler
from torch.mps import compile_shader
from torch.mps import current_allocated_memory
from torch.mps import device_count
from torch.mps import driver_allocated_memory
from torch.mps import empty_cache
from torch.mps import get_rng_state
from torch.mps import is_available
from torch.mps import manual_seed
from torch.mps import recommended_max_memory
from torch.mps import seed
from torch.mps import set_per_process_memory_fraction
from torch.mps import set_rng_state
from torch.mps import synchronize
from torch.mps.event import Event
from torch.mps.profiler import is_capturing_metal
from torch.mps.profiler import is_metal_capture_enabled
from torch.mps.profiler import metal_capture
from torch.mps.profiler import profile
from torch.mps.profiler import start
from torch.mps.profiler import stop
from torch.mtia import DeferredMtiaCallError
from torch.mtia import StreamContext
from torch.mtia import attach_out_of_memory_observer
from torch.mtia import current_device
from torch.mtia import current_stream
from torch.mtia import default_stream
from torch.mtia import device
from torch.mtia import device_count
from torch.mtia import empty_cache
from torch.mtia import get_device_capability
from torch.mtia import get_device_properties
from torch.mtia import get_rng_state
from torch.mtia import init
from torch.mtia import is_available
from torch.mtia import is_initialized
from torch.mtia import record_memory_history
from torch.mtia import set_device
from torch.mtia import set_rng_state
from torch.mtia import set_stream
from torch.mtia import snapshot
from torch.mtia import stream
from torch.mtia import synchronize
from torch.mtia.memory import max_memory_allocated
from torch.mtia.memory import memory_stats
from torch.mtia.memory import reset_peak_memory_stats
from torch.multiprocessing import get_all_sharing_strategies
from torch.multiprocessing import get_sharing_strategy
from torch.multiprocessing import set_sharing_strategy
from torch.multiprocessing.pool import Pool
from torch.multiprocessing.pool import clean_worker
from torch.multiprocessing.queue import ConnectionWrapper
from torch.multiprocessing.queue import Queue
from torch.multiprocessing.queue import SimpleQueue
from torch.multiprocessing.reductions import SharedCache
from torch.multiprocessing.reductions import StorageWeakRef
from torch.multiprocessing.reductions import check_serializing_named_tensor
from torch.multiprocessing.reductions import fd_id
from torch.multiprocessing.reductions import init_reductions
from torch.multiprocessing.reductions import rebuild_cuda_tensor
from torch.multiprocessing.reductions import rebuild_event
from torch.multiprocessing.reductions import rebuild_meta_tensor
from torch.multiprocessing.reductions import rebuild_nested_tensor
from torch.multiprocessing.reductions import rebuild_sparse_compressed_tensor
from torch.multiprocessing.reductions import rebuild_sparse_coo_tensor
from torch.multiprocessing.reductions import rebuild_storage_empty
from torch.multiprocessing.reductions import rebuild_storage_fd
from torch.multiprocessing.reductions import rebuild_storage_filename
from torch.multiprocessing.reductions import rebuild_tensor
from torch.multiprocessing.reductions import rebuild_typed_storage
from torch.multiprocessing.reductions import rebuild_typed_storage_child
from torch.multiprocessing.reductions import reduce_event
from torch.multiprocessing.reductions import reduce_nested_tensor
from torch.multiprocessing.reductions import reduce_sparse_tensor
from torch.multiprocessing.reductions import reduce_storage
from torch.multiprocessing.reductions import reduce_tensor
from torch.multiprocessing.reductions import reduce_typed_storage
from torch.multiprocessing.reductions import reduce_typed_storage_child
from torch.multiprocessing.reductions import shared_cache
from torch.multiprocessing.reductions import storage_from_cache
from torch.multiprocessing.spawn import ProcessContext
from torch.multiprocessing.spawn import ProcessException
from torch.multiprocessing.spawn import ProcessExitedException
from torch.multiprocessing.spawn import ProcessRaisedException
from torch.multiprocessing.spawn import SpawnContext
from torch.multiprocessing.spawn import spawn
from torch.multiprocessing.spawn import start_processes
from torch.nested import as_nested_tensor
from torch.nested import masked_select
from torch.nested import narrow
from torch.nested import nested_tensor
from torch.nested import nested_tensor_from_jagged
from torch.nested import to_padded_tensor
from torch.nn import factory_kwargs
from torch.nn.attention import SDPBackend
from torch.nn.attention import sdpa_kernel
from torch.nn.attention.bias import CausalBias
from torch.nn.attention.bias import CausalVariant
from torch.nn.attention.bias import causal_lower_right
from torch.nn.attention.bias import causal_upper_left
from torch.nn.attention.bias import is_flash_attention_available
from torch.nn.attention.flex_attention import BlockMask
from torch.nn.attention.flex_attention import and_masks
from torch.nn.attention.flex_attention import create_block_mask
from torch.nn.attention.flex_attention import create_mask
from torch.nn.attention.flex_attention import create_nested_block_mask
from torch.nn.attention.flex_attention import flex_attention
from torch.nn.attention.flex_attention import flex_attention_hop
from torch.nn.attention.flex_attention import noop_mask
from torch.nn.attention.flex_attention import or_masks
from torch.nn.common_types import T
from torch.nn.cpp import ModuleWrapper
from torch.nn.cpp import OrderedDictWrapper
from torch.nn.functional import BroadcastingList1
from torch.nn.functional import BroadcastingList2
from torch.nn.functional import BroadcastingList3
from torch.nn.functional import GRID_SAMPLE_INTERPOLATION_MODES
from torch.nn.functional import GRID_SAMPLE_PADDING_MODES
from torch.nn.functional import adaptive_avg_pool2d
from torch.nn.functional import adaptive_avg_pool3d
from torch.nn.functional import adaptive_max_pool1d
from torch.nn.functional import adaptive_max_pool1d_with_indices
from torch.nn.functional import adaptive_max_pool2d
from torch.nn.functional import adaptive_max_pool2d_with_indices
from torch.nn.functional import adaptive_max_pool3d
from torch.nn.functional import adaptive_max_pool3d_with_indices
from torch.nn.functional import affine_grid
from torch.nn.functional import alpha_dropout
from torch.nn.functional import assert_int_or_pair
from torch.nn.functional import avg_pool2d
from torch.nn.functional import avg_pool3d
from torch.nn.functional import batch_norm
from torch.nn.functional import binary_cross_entropy
from torch.nn.functional import binary_cross_entropy_with_logits
from torch.nn.functional import celu
from torch.nn.functional import cosine_embedding_loss
from torch.nn.functional import cross_entropy
from torch.nn.functional import ctc_loss
from torch.nn.functional import dropout
from torch.nn.functional import dropout1d
from torch.nn.functional import dropout2d
from torch.nn.functional import dropout3d
from torch.nn.functional import elu
from torch.nn.functional import elu_
from torch.nn.functional import embedding
from torch.nn.functional import embedding_bag
from torch.nn.functional import feature_alpha_dropout
from torch.nn.functional import fold
from torch.nn.functional import fractional_max_pool2d
from torch.nn.functional import fractional_max_pool2d_with_indices
from torch.nn.functional import fractional_max_pool3d
from torch.nn.functional import fractional_max_pool3d_with_indices
from torch.nn.functional import gaussian_nll_loss
from torch.nn.functional import gelu
from torch.nn.functional import glu
from torch.nn.functional import grid_sample
from torch.nn.functional import group_norm
from torch.nn.functional import gumbel_softmax
from torch.nn.functional import hardsigmoid
from torch.nn.functional import hardswish
from torch.nn.functional import hardtanh
from torch.nn.functional import hardtanh_
from torch.nn.functional import hinge_embedding_loss
from torch.nn.functional import huber_loss
from torch.nn.functional import instance_norm
from torch.nn.functional import interpolate
from torch.nn.functional import kl_div
from torch.nn.functional import l1_loss
from torch.nn.functional import layer_norm
from torch.nn.functional import leaky_relu
from torch.nn.functional import leaky_relu_
from torch.nn.functional import linear
from torch.nn.functional import local_response_norm
from torch.nn.functional import log_softmax
from torch.nn.functional import logsigmoid
from torch.nn.functional import lp_pool1d
from torch.nn.functional import lp_pool2d
from torch.nn.functional import lp_pool3d
from torch.nn.functional import margin_ranking_loss
from torch.nn.functional import max_pool1d
from torch.nn.functional import max_pool1d_with_indices
from torch.nn.functional import max_pool2d
from torch.nn.functional import max_pool2d_with_indices
from torch.nn.functional import max_pool3d
from torch.nn.functional import max_pool3d_with_indices
from torch.nn.functional import max_unpool1d
from torch.nn.functional import max_unpool2d
from torch.nn.functional import max_unpool3d
from torch.nn.functional import mish
from torch.nn.functional import mse_loss
from torch.nn.functional import multi_head_attention_forward
from torch.nn.functional import multi_margin_loss
from torch.nn.functional import multilabel_margin_loss
from torch.nn.functional import multilabel_soft_margin_loss
from torch.nn.functional import nll_loss
from torch.nn.functional import normalize
from torch.nn.functional import one_hot
from torch.nn.functional import pad
from torch.nn.functional import poisson_nll_loss
from torch.nn.functional import relu
from torch.nn.functional import relu6
from torch.nn.functional import reproducibility_notes
from torch.nn.functional import rms_norm
from torch.nn.functional import rrelu
from torch.nn.functional import scaled_dot_product_attention
from torch.nn.functional import selu
from torch.nn.functional import sigmoid
from torch.nn.functional import silu
from torch.nn.functional import smooth_l1_loss
from torch.nn.functional import soft_margin_loss
from torch.nn.functional import softmax
from torch.nn.functional import softmin
from torch.nn.functional import softplus
from torch.nn.functional import softshrink
from torch.nn.functional import softsign
from torch.nn.functional import sparse_support_notes
from torch.nn.functional import tanh
from torch.nn.functional import tanhshrink
from torch.nn.functional import tf32_notes
from torch.nn.functional import triplet_margin_loss
from torch.nn.functional import triplet_margin_with_distance_loss
from torch.nn.functional import unfold
from torch.nn.functional import upsample
from torch.nn.functional import upsample_bilinear
from torch.nn.functional import upsample_nearest
from torch.nn.grad import conv1d_input
from torch.nn.grad import conv1d_weight
from torch.nn.grad import conv2d_input
from torch.nn.grad import conv2d_weight
from torch.nn.grad import conv3d_input
from torch.nn.grad import conv3d_weight
from torch.nn.init import calculate_gain
from torch.nn.init import constant
from torch.nn.init import constant_
from torch.nn.init import dirac
from torch.nn.init import dirac_
from torch.nn.init import eye
from torch.nn.init import eye_
from torch.nn.init import kaiming_normal
from torch.nn.init import kaiming_normal_
from torch.nn.init import kaiming_uniform
from torch.nn.init import kaiming_uniform_
from torch.nn.init import normal
from torch.nn.init import normal_
from torch.nn.init import ones_
from torch.nn.init import orthogonal
from torch.nn.init import orthogonal_
from torch.nn.init import sparse
from torch.nn.init import sparse_
from torch.nn.init import trunc_normal_
from torch.nn.init import uniform
from torch.nn.init import uniform_
from torch.nn.init import xavier_normal
from torch.nn.init import xavier_normal_
from torch.nn.init import xavier_uniform
from torch.nn.init import xavier_uniform_
from torch.nn.init import zeros_
from torch.nn.modules.activation import CELU
from torch.nn.modules.activation import ELU
from torch.nn.modules.activation import GELU
from torch.nn.modules.activation import GLU
from torch.nn.modules.activation import Hardshrink
from torch.nn.modules.activation import Hardsigmoid
from torch.nn.modules.activation import Hardswish
from torch.nn.modules.activation import Hardtanh
from torch.nn.modules.activation import LeakyReLU
from torch.nn.modules.activation import LogSigmoid
from torch.nn.modules.activation import LogSoftmax
from torch.nn.modules.activation import Mish
from torch.nn.modules.activation import MultiheadAttention
from torch.nn.modules.activation import PReLU
from torch.nn.modules.activation import RReLU
from torch.nn.modules.activation import ReLU
from torch.nn.modules.activation import ReLU6
from torch.nn.modules.activation import SELU
from torch.nn.modules.activation import SiLU
from torch.nn.modules.activation import Sigmoid
from torch.nn.modules.activation import Softmax
from torch.nn.modules.activation import Softmax2d
from torch.nn.modules.activation import Softmin
from torch.nn.modules.activation import Softplus
from torch.nn.modules.activation import Softshrink
from torch.nn.modules.activation import Softsign
from torch.nn.modules.activation import Tanh
from torch.nn.modules.activation import Tanhshrink
from torch.nn.modules.activation import Threshold
from torch.nn.modules.adaptive import AdaptiveLogSoftmaxWithLoss
from torch.nn.modules.batchnorm import BatchNorm1d
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.nn.modules.batchnorm import BatchNorm3d
from torch.nn.modules.batchnorm import LazyBatchNorm1d
from torch.nn.modules.batchnorm import LazyBatchNorm2d
from torch.nn.modules.batchnorm import LazyBatchNorm3d
from torch.nn.modules.batchnorm import SyncBatchNorm
from torch.nn.modules.batchnorm import sync_batch_norm
from torch.nn.modules.channelshuffle import ChannelShuffle
from torch.nn.modules.container import Container
from torch.nn.modules.container import ModuleDict
from torch.nn.modules.container import ModuleList
from torch.nn.modules.container import ParameterDict
from torch.nn.modules.container import ParameterList
from torch.nn.modules.container import Sequential
from torch.nn.modules.container import T
from torch.nn.modules.conv import Conv1d
from torch.nn.modules.conv import Conv2d
from torch.nn.modules.conv import Conv3d
from torch.nn.modules.conv import ConvTranspose1d
from torch.nn.modules.conv import ConvTranspose2d
from torch.nn.modules.conv import ConvTranspose3d
from torch.nn.modules.conv import LazyConv1d
from torch.nn.modules.conv import LazyConv2d
from torch.nn.modules.conv import LazyConv3d
from torch.nn.modules.conv import LazyConvTranspose1d
from torch.nn.modules.conv import LazyConvTranspose2d
from torch.nn.modules.conv import LazyConvTranspose3d
from torch.nn.modules.conv import convolution_notes
from torch.nn.modules.conv import reproducibility_notes
from torch.nn.modules.distance import CosineSimilarity
from torch.nn.modules.distance import PairwiseDistance
from torch.nn.modules.dropout import AlphaDropout
from torch.nn.modules.dropout import Dropout
from torch.nn.modules.dropout import Dropout1d
from torch.nn.modules.dropout import Dropout2d
from torch.nn.modules.dropout import Dropout3d
from torch.nn.modules.dropout import FeatureAlphaDropout
from torch.nn.modules.flatten import Flatten
from torch.nn.modules.flatten import Unflatten
from torch.nn.modules.fold import Fold
from torch.nn.modules.fold import Unfold
from torch.nn.modules.instancenorm import InstanceNorm1d
from torch.nn.modules.instancenorm import InstanceNorm2d
from torch.nn.modules.instancenorm import InstanceNorm3d
from torch.nn.modules.instancenorm import LazyInstanceNorm1d
from torch.nn.modules.instancenorm import LazyInstanceNorm2d
from torch.nn.modules.instancenorm import LazyInstanceNorm3d
from torch.nn.modules.lazy import LazyModuleMixin
from torch.nn.modules.linear import Bilinear
from torch.nn.modules.linear import Identity
from torch.nn.modules.linear import LazyLinear
from torch.nn.modules.linear import Linear
from torch.nn.modules.linear import NonDynamicallyQuantizableLinear
from torch.nn.modules.loss import BCELoss
from torch.nn.modules.loss import BCEWithLogitsLoss
from torch.nn.modules.loss import CTCLoss
from torch.nn.modules.loss import CosineEmbeddingLoss
from torch.nn.modules.loss import CrossEntropyLoss
from torch.nn.modules.loss import GaussianNLLLoss
from torch.nn.modules.loss import HingeEmbeddingLoss
from torch.nn.modules.loss import HuberLoss
from torch.nn.modules.loss import KLDivLoss
from torch.nn.modules.loss import L1Loss
from torch.nn.modules.loss import MSELoss
from torch.nn.modules.loss import MarginRankingLoss
from torch.nn.modules.loss import MultiLabelMarginLoss
from torch.nn.modules.loss import MultiLabelSoftMarginLoss
from torch.nn.modules.loss import MultiMarginLoss
from torch.nn.modules.loss import NLLLoss
from torch.nn.modules.loss import NLLLoss2d
from torch.nn.modules.loss import PoissonNLLLoss
from torch.nn.modules.loss import SmoothL1Loss
from torch.nn.modules.loss import SoftMarginLoss
from torch.nn.modules.loss import TripletMarginLoss
from torch.nn.modules.loss import TripletMarginWithDistanceLoss
from torch.nn.modules.module import Module
from torch.nn.modules.module import T
from torch.nn.modules.module import is_traceable_wrapper_subclass
from torch.nn.modules.module import register_module_backward_hook
from torch.nn.modules.module import register_module_buffer_registration_hook
from torch.nn.modules.module import register_module_forward_hook
from torch.nn.modules.module import register_module_forward_pre_hook
from torch.nn.modules.module import register_module_full_backward_hook
from torch.nn.modules.module import register_module_full_backward_pre_hook
from torch.nn.modules.module import register_module_module_registration_hook
from torch.nn.modules.module import register_module_parameter_registration_hook
from torch.nn.modules.normalization import CrossMapLRN2d
from torch.nn.modules.normalization import GroupNorm
from torch.nn.modules.normalization import LayerNorm
from torch.nn.modules.normalization import LocalResponseNorm
from torch.nn.modules.normalization import RMSNorm
from torch.nn.modules.padding import CircularPad1d
from torch.nn.modules.padding import CircularPad2d
from torch.nn.modules.padding import CircularPad3d
from torch.nn.modules.padding import ConstantPad1d
from torch.nn.modules.padding import ConstantPad2d
from torch.nn.modules.padding import ConstantPad3d
from torch.nn.modules.padding import ReflectionPad1d
from torch.nn.modules.padding import ReflectionPad2d
from torch.nn.modules.padding import ReflectionPad3d
from torch.nn.modules.padding import ReplicationPad1d
from torch.nn.modules.padding import ReplicationPad2d
from torch.nn.modules.padding import ReplicationPad3d
from torch.nn.modules.padding import ZeroPad1d
from torch.nn.modules.padding import ZeroPad2d
from torch.nn.modules.padding import ZeroPad3d
from torch.nn.modules.pixelshuffle import PixelShuffle
from torch.nn.modules.pixelshuffle import PixelUnshuffle
from torch.nn.modules.pooling import AdaptiveAvgPool1d
from torch.nn.modules.pooling import AdaptiveAvgPool2d
from torch.nn.modules.pooling import AdaptiveAvgPool3d
from torch.nn.modules.pooling import AdaptiveMaxPool1d
from torch.nn.modules.pooling import AdaptiveMaxPool2d
from torch.nn.modules.pooling import AdaptiveMaxPool3d
from torch.nn.modules.pooling import AvgPool1d
from torch.nn.modules.pooling import AvgPool2d
from torch.nn.modules.pooling import AvgPool3d
from torch.nn.modules.pooling import FractionalMaxPool2d
from torch.nn.modules.pooling import FractionalMaxPool3d
from torch.nn.modules.pooling import LPPool1d
from torch.nn.modules.pooling import LPPool2d
from torch.nn.modules.pooling import LPPool3d
from torch.nn.modules.pooling import MaxPool1d
from torch.nn.modules.pooling import MaxPool2d
from torch.nn.modules.pooling import MaxPool3d
from torch.nn.modules.pooling import MaxUnpool1d
from torch.nn.modules.pooling import MaxUnpool2d
from torch.nn.modules.pooling import MaxUnpool3d
from torch.nn.modules.rnn import GRU
from torch.nn.modules.rnn import GRUCell
from torch.nn.modules.rnn import LSTM
from torch.nn.modules.rnn import LSTMCell
from torch.nn.modules.rnn import RNN
from torch.nn.modules.rnn import RNNBase
from torch.nn.modules.rnn import RNNCell
from torch.nn.modules.rnn import RNNCellBase
from torch.nn.modules.rnn import apply_permutation
from torch.nn.modules.sparse import Embedding
from torch.nn.modules.sparse import EmbeddingBag
from torch.nn.modules.transformer import Transformer
from torch.nn.modules.transformer import TransformerDecoder
from torch.nn.modules.transformer import TransformerDecoderLayer
from torch.nn.modules.transformer import TransformerEncoder
from torch.nn.modules.transformer import TransformerEncoderLayer
from torch.nn.modules.upsampling import Upsample
from torch.nn.modules.upsampling import UpsamplingBilinear2d
from torch.nn.modules.upsampling import UpsamplingNearest2d
from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present
from torch.nn.parallel import DistributedDataParallelCPU
from torch.nn.parallel.comm import broadcast
from torch.nn.parallel.comm import broadcast_coalesced
from torch.nn.parallel.comm import gather
from torch.nn.parallel.comm import reduce_add
from torch.nn.parallel.comm import reduce_add_coalesced
from torch.nn.parallel.comm import scatter
from torch.nn.parallel.data_parallel import DataParallel
from torch.nn.parallel.data_parallel import T
from torch.nn.parallel.data_parallel import data_parallel
from torch.nn.parallel.distributed import DistributedDataParallel
from torch.nn.parallel.parallel_apply import get_a_var
from torch.nn.parallel.parallel_apply import parallel_apply
from torch.nn.parallel.replicate import T
from torch.nn.parallel.replicate import replicate
from torch.nn.parallel.scatter_gather import Gather
from torch.nn.parallel.scatter_gather import Scatter
from torch.nn.parallel.scatter_gather import T
from torch.nn.parallel.scatter_gather import gather
from torch.nn.parallel.scatter_gather import is_namedtuple
from torch.nn.parallel.scatter_gather import scatter
from torch.nn.parallel.scatter_gather import scatter_kwargs
from torch.nn.parameter import Buffer
from torch.nn.parameter import Parameter
from torch.nn.parameter import UninitializedBuffer
from torch.nn.parameter import UninitializedParameter
from torch.nn.parameter import UninitializedTensorMixin
from torch.nn.parameter import is_lazy
from torch.nn.utils import clip_grad_norm
from torch.nn.utils import clip_grad_norm_
from torch.nn.utils import clip_grad_value_
from torch.nn.utils.convert_parameters import parameters_to_vector
from torch.nn.utils.convert_parameters import vector_to_parameters
from torch.nn.utils.fusion import ConvT
from torch.nn.utils.fusion import LinearT
from torch.nn.utils.fusion import fuse_conv_bn_eval
from torch.nn.utils.fusion import fuse_conv_bn_weights
from torch.nn.utils.fusion import fuse_linear_bn_eval
from torch.nn.utils.fusion import fuse_linear_bn_weights
from torch.nn.utils.init import skip_init
from torch.nn.utils.memory_format import convert_conv2d_weight_memory_format
from torch.nn.utils.memory_format import convert_conv3d_weight_memory_format
from torch.nn.utils.parametrizations import orthogonal
from torch.nn.utils.parametrizations import spectral_norm
from torch.nn.utils.parametrizations import weight_norm
from torch.nn.utils.parametrize import ParametrizationList
from torch.nn.utils.parametrize import cached
from torch.nn.utils.parametrize import get_swap_module_params_on_conversion
from torch.nn.utils.parametrize import is_parametrized
from torch.nn.utils.parametrize import register_parametrization
from torch.nn.utils.parametrize import remove_parametrizations
from torch.nn.utils.parametrize import transfer_parametrizations_and_params
from torch.nn.utils.parametrize import type_before_parametrizations
from torch.nn.utils.prune import BasePruningMethod
from torch.nn.utils.prune import CustomFromMask
from torch.nn.utils.prune import Identity
from torch.nn.utils.prune import L1Unstructured
from torch.nn.utils.prune import LnStructured
from torch.nn.utils.prune import PruningContainer
from torch.nn.utils.prune import RandomStructured
from torch.nn.utils.prune import RandomUnstructured
from torch.nn.utils.prune import custom_from_mask
from torch.nn.utils.prune import global_unstructured
from torch.nn.utils.prune import identity
from torch.nn.utils.prune import is_pruned
from torch.nn.utils.prune import l1_unstructured
from torch.nn.utils.prune import ln_structured
from torch.nn.utils.prune import random_structured
from torch.nn.utils.prune import random_unstructured
from torch.nn.utils.prune import remove
from torch.nn.utils.rnn import PackedSequence
from torch.nn.utils.rnn import PackedSequence_
from torch.nn.utils.rnn import bind
from torch.nn.utils.rnn import invert_permutation
from torch.nn.utils.rnn import pack_padded_sequence
from torch.nn.utils.rnn import pack_sequence
from torch.nn.utils.rnn import pad_packed_sequence
from torch.nn.utils.rnn import pad_sequence
from torch.nn.utils.rnn import unpack_sequence
from torch.nn.utils.rnn import unpad_sequence
from torch.nn.utils.spectral_norm import SpectralNorm
from torch.nn.utils.spectral_norm import SpectralNormLoadStateDictPreHook
from torch.nn.utils.spectral_norm import SpectralNormStateDictHook
from torch.nn.utils.spectral_norm import T_module
from torch.nn.utils.spectral_norm import remove_spectral_norm
from torch.nn.utils.spectral_norm import spectral_norm
from torch.nn.utils.stateless import NamedMemberAccessor
from torch.nn.utils.stateless import functional_call
from torch.nn.utils.weight_norm import T_module
from torch.nn.utils.weight_norm import WeightNorm
from torch.nn.utils.weight_norm import remove_weight_norm
from torch.nn.utils.weight_norm import weight_norm
from torch.onnx import JitScalarType
from torch.onnx import ONNXProgram
from torch.onnx import OnnxExporterError
from torch.onnx import OperatorExportTypes
from torch.onnx import TensorProtoDataType
from torch.onnx import TrainingMode
from torch.onnx import enable_fake_mode
from torch.onnx import export
from torch.onnx import is_in_onnx_export
from torch.onnx import is_onnxrt_backend_supported
from torch.onnx import producer_name
from torch.onnx import producer_version
from torch.onnx.errors import OnnxExporterWarning
from torch.onnx.errors import SymbolicValueError
from torch.onnx.errors import UnsupportedOperatorError
from torch.onnx.ops import aten_decompositions
from torch.onnx.ops import attention
from torch.onnx.ops import rotary_embedding
from torch.onnx.ops import symbolic
from torch.onnx.ops import symbolic_multi_out
from torch.onnx.symbolic_helper import GLOBALS
from torch.onnx.symbolic_helper import args_have_same_dtype
from torch.onnx.symbolic_helper import cast_pytorch_to_onnx
from torch.onnx.symbolic_helper import check_training_mode
from torch.onnx.symbolic_helper import dequantize_helper
from torch.onnx.symbolic_helper import is_complex_value
from torch.onnx.symbolic_helper import parse_args
from torch.onnx.symbolic_helper import pytorch_name_to_type
from torch.onnx.symbolic_helper import quantize_helper
from torch.onnx.symbolic_helper import quantized_args
from torch.onnx.symbolic_helper import requantize_bias_helper
from torch.onnx.symbolic_helper import scalar_name_to_pytorch
from torch.onnx.symbolic_helper import scalar_type_to_onnx
from torch.onnx.symbolic_helper import scalar_type_to_pytorch_type
from torch.onnx.symbolic_opset10 import GLOBALS
from torch.onnx.symbolic_opset10 import dequantize
from torch.onnx.symbolic_opset10 import div
from torch.onnx.symbolic_opset10 import embedding_bag
from torch.onnx.symbolic_opset10 import fake_quantize_per_tensor_affine
from torch.onnx.symbolic_opset10 import flip
from torch.onnx.symbolic_opset10 import fmod
from torch.onnx.symbolic_opset10 import isfinite
from torch.onnx.symbolic_opset10 import isinf
from torch.onnx.symbolic_opset10 import nan_to_num
from torch.onnx.symbolic_opset10 import quantize_per_tensor
from torch.onnx.symbolic_opset10 import quantized_add
from torch.onnx.symbolic_opset10 import quantized_add_relu
from torch.onnx.symbolic_opset10 import quantized_cat
from torch.onnx.symbolic_opset10 import quantized_conv1d
from torch.onnx.symbolic_opset10 import quantized_conv1d_relu
from torch.onnx.symbolic_opset10 import quantized_conv2d
from torch.onnx.symbolic_opset10 import quantized_conv2d_relu
from torch.onnx.symbolic_opset10 import quantized_conv3d
from torch.onnx.symbolic_opset10 import quantized_conv3d_relu
from torch.onnx.symbolic_opset10 import quantized_conv_transpose1d
from torch.onnx.symbolic_opset10 import quantized_conv_transpose2d
from torch.onnx.symbolic_opset10 import quantized_conv_transpose3d
from torch.onnx.symbolic_opset10 import quantized_group_norm
from torch.onnx.symbolic_opset10 import quantized_hardswish
from torch.onnx.symbolic_opset10 import quantized_instance_norm
from torch.onnx.symbolic_opset10 import quantized_layer_norm
from torch.onnx.symbolic_opset10 import quantized_leaky_relu
from torch.onnx.symbolic_opset10 import quantized_linear
from torch.onnx.symbolic_opset10 import quantized_linear_relu
from torch.onnx.symbolic_opset10 import quantized_mul
from torch.onnx.symbolic_opset10 import quantized_sigmoid
from torch.onnx.symbolic_opset10 import slice
from torch.onnx.symbolic_opset10 import sort
from torch.onnx.symbolic_opset10 import topk
from torch.onnx.symbolic_opset11 import Delete
from torch.onnx.symbolic_opset11 import add
from torch.onnx.symbolic_opset11 import append
from torch.onnx.symbolic_opset11 import arange
from torch.onnx.symbolic_opset11 import argsort
from torch.onnx.symbolic_opset11 import atleast_1d
from torch.onnx.symbolic_opset11 import atleast_2d
from torch.onnx.symbolic_opset11 import atleast_3d
from torch.onnx.symbolic_opset11 import cat
from torch.onnx.symbolic_opset11 import chunk
from torch.onnx.symbolic_opset11 import clamp
from torch.onnx.symbolic_opset11 import clamp_max
from torch.onnx.symbolic_opset11 import clamp_min
from torch.onnx.symbolic_opset11 import constant_pad_nd
from torch.onnx.symbolic_opset11 import cumsum
from torch.onnx.symbolic_opset11 import embedding_bag
from torch.onnx.symbolic_opset11 import embedding_renorm
from torch.onnx.symbolic_opset11 import flatten
from torch.onnx.symbolic_opset11 import gather
from torch.onnx.symbolic_opset11 import hardtanh
from torch.onnx.symbolic_opset11 import hstack
from torch.onnx.symbolic_opset11 import im2col
from torch.onnx.symbolic_opset11 import index
from torch.onnx.symbolic_opset11 import index_copy
from torch.onnx.symbolic_opset11 import index_fill
from torch.onnx.symbolic_opset11 import index_put
from torch.onnx.symbolic_opset11 import insert
from torch.onnx.symbolic_opset11 import linalg_det
from torch.onnx.symbolic_opset11 import linalg_vector_norm
from torch.onnx.symbolic_opset11 import logdet
from torch.onnx.symbolic_opset11 import masked_scatter
from torch.onnx.symbolic_opset11 import masked_select
from torch.onnx.symbolic_opset11 import mm
from torch.onnx.symbolic_opset11 import narrow
from torch.onnx.symbolic_opset11 import normal
from torch.onnx.symbolic_opset11 import pad
from torch.onnx.symbolic_opset11 import pixel_shuffle
from torch.onnx.symbolic_opset11 import pop
from torch.onnx.symbolic_opset11 import prim_constant_chunk
from torch.onnx.symbolic_opset11 import reflection_pad
from torch.onnx.symbolic_opset11 import relu6
from torch.onnx.symbolic_opset11 import remainder
from torch.onnx.symbolic_opset11 import replication_pad
from torch.onnx.symbolic_opset11 import round
from torch.onnx.symbolic_opset11 import scatter
from torch.onnx.symbolic_opset11 import select
from torch.onnx.symbolic_opset11 import size
from torch.onnx.symbolic_opset11 import sort
from torch.onnx.symbolic_opset11 import split
from torch.onnx.symbolic_opset11 import split_with_sizes
from torch.onnx.symbolic_opset11 import squeeze
from torch.onnx.symbolic_opset11 import stack
from torch.onnx.symbolic_opset11 import topk
from torch.onnx.symbolic_opset11 import unbind
from torch.onnx.symbolic_opset11 import unique_dim
from torch.onnx.symbolic_opset11 import unsqueeze
from torch.onnx.symbolic_opset11 import vstack
from torch.onnx.symbolic_opset12 import argmax
from torch.onnx.symbolic_opset12 import argmin
from torch.onnx.symbolic_opset12 import binary_cross_entropy_with_logits
from torch.onnx.symbolic_opset12 import celu
from torch.onnx.symbolic_opset12 import cross_entropy_loss
from torch.onnx.symbolic_opset12 import dropout
from torch.onnx.symbolic_opset12 import einsum
from torch.onnx.symbolic_opset12 import ge
from torch.onnx.symbolic_opset12 import le
from torch.onnx.symbolic_opset12 import native_dropout
from torch.onnx.symbolic_opset12 import nll_loss
from torch.onnx.symbolic_opset12 import nll_loss2d
from torch.onnx.symbolic_opset12 import nll_loss_nd
from torch.onnx.symbolic_opset12 import outer
from torch.onnx.symbolic_opset12 import pow
from torch.onnx.symbolic_opset12 import tensordot
from torch.onnx.symbolic_opset12 import unfold
from torch.onnx.symbolic_opset13 import diagonal
from torch.onnx.symbolic_opset13 import fake_quantize_per_channel_affine
from torch.onnx.symbolic_opset13 import fake_quantize_per_tensor_affine
from torch.onnx.symbolic_opset13 import frobenius_norm
from torch.onnx.symbolic_opset13 import log_softmax
from torch.onnx.symbolic_opset13 import nonzero_numpy
from torch.onnx.symbolic_opset13 import quantized_conv1d
from torch.onnx.symbolic_opset13 import quantized_conv1d_relu
from torch.onnx.symbolic_opset13 import quantized_conv2d
from torch.onnx.symbolic_opset13 import quantized_conv2d_relu
from torch.onnx.symbolic_opset13 import quantized_conv3d
from torch.onnx.symbolic_opset13 import quantized_conv3d_relu
from torch.onnx.symbolic_opset13 import quantized_conv_transpose1d
from torch.onnx.symbolic_opset13 import quantized_conv_transpose2d
from torch.onnx.symbolic_opset13 import quantized_conv_transpose3d
from torch.onnx.symbolic_opset13 import quantized_linear
from torch.onnx.symbolic_opset13 import quantized_linear_relu
from torch.onnx.symbolic_opset13 import repeat_interleave
from torch.onnx.symbolic_opset13 import softmax
from torch.onnx.symbolic_opset13 import split
from torch.onnx.symbolic_opset13 import split_with_sizes
from torch.onnx.symbolic_opset13 import tensor_split
from torch.onnx.symbolic_opset13 import tile
from torch.onnx.symbolic_opset13 import unbind
from torch.onnx.symbolic_opset13 import unflatten
from torch.onnx.symbolic_opset13 import unsafe_chunk
from torch.onnx.symbolic_opset13 import unsafe_split
from torch.onnx.symbolic_opset13 import unsafe_split_with_sizes
from torch.onnx.symbolic_opset13 import where
from torch.onnx.symbolic_opset14 import GLOBALS
from torch.onnx.symbolic_opset14 import batch_norm
from torch.onnx.symbolic_opset14 import hardswish
from torch.onnx.symbolic_opset14 import quantized_hardswish
from torch.onnx.symbolic_opset14 import reshape
from torch.onnx.symbolic_opset14 import scaled_dot_product_attention
from torch.onnx.symbolic_opset14 import tril
from torch.onnx.symbolic_opset14 import triu
from torch.onnx.symbolic_opset15 import aten__is_
from torch.onnx.symbolic_opset15 import aten__isnot_
from torch.onnx.symbolic_opset15 import bernoulli
from torch.onnx.symbolic_opset15 import prim_unchecked_cast
from torch.onnx.symbolic_opset16 import GRID_SAMPLE_INTERPOLATION_MODES
from torch.onnx.symbolic_opset16 import GRID_SAMPLE_PADDING_MODES
from torch.onnx.symbolic_opset16 import grid_sampler
from torch.onnx.symbolic_opset16 import scatter_add
from torch.onnx.symbolic_opset16 import scatter_reduce
from torch.onnx.symbolic_opset17 import layer_norm
from torch.onnx.symbolic_opset17 import quantized_layer_norm
from torch.onnx.symbolic_opset17 import stft
from torch.onnx.symbolic_opset18 import amax
from torch.onnx.symbolic_opset18 import amin
from torch.onnx.symbolic_opset18 import aminmax
from torch.onnx.symbolic_opset18 import col2im
from torch.onnx.symbolic_opset18 import embedding_bag
from torch.onnx.symbolic_opset18 import linalg_vector_norm
from torch.onnx.symbolic_opset18 import max
from torch.onnx.symbolic_opset18 import maximum
from torch.onnx.symbolic_opset18 import min
from torch.onnx.symbolic_opset18 import minimum
from torch.onnx.symbolic_opset20 import convert_grid_sample_mode
from torch.onnx.symbolic_opset20 import gelu
from torch.onnx.symbolic_opset7 import block_listed_op
from torch.onnx.symbolic_opset7 import block_listed_operators
from torch.onnx.symbolic_opset7 import max
from torch.onnx.symbolic_opset7 import min
from torch.onnx.symbolic_opset8 import addmm
from torch.onnx.symbolic_opset8 import block_listed_op
from torch.onnx.symbolic_opset8 import block_listed_operators
from torch.onnx.symbolic_opset8 import bmm
from torch.onnx.symbolic_opset8 import empty
from torch.onnx.symbolic_opset8 import empty_like
from torch.onnx.symbolic_opset8 import flatten
from torch.onnx.symbolic_opset8 import full
from torch.onnx.symbolic_opset8 import full_like
from torch.onnx.symbolic_opset8 import gt
from torch.onnx.symbolic_opset8 import lt
from torch.onnx.symbolic_opset8 import matmul
from torch.onnx.symbolic_opset8 import mm
from torch.onnx.symbolic_opset8 import ones
from torch.onnx.symbolic_opset8 import ones_like
from torch.onnx.symbolic_opset8 import prelu
from torch.onnx.symbolic_opset8 import repeat
from torch.onnx.symbolic_opset8 import zeros
from torch.onnx.symbolic_opset8 import zeros_like
from torch.onnx.symbolic_opset9 import GLOBALS
from torch.onnx.symbolic_opset9 import abs
from torch.onnx.symbolic_opset9 import acos
from torch.onnx.symbolic_opset9 import adaptive_avg_pool1d
from torch.onnx.symbolic_opset9 import add
from torch.onnx.symbolic_opset9 import addcmul
from torch.onnx.symbolic_opset9 import addmm
from torch.onnx.symbolic_opset9 import alias
from torch.onnx.symbolic_opset9 import amax
from torch.onnx.symbolic_opset9 import amin
from torch.onnx.symbolic_opset9 import aminmax
from torch.onnx.symbolic_opset9 import arange
from torch.onnx.symbolic_opset9 import argmax
from torch.onnx.symbolic_opset9 import argmin
from torch.onnx.symbolic_opset9 import as_strided
from torch.onnx.symbolic_opset9 import as_tensor
from torch.onnx.symbolic_opset9 import asin
from torch.onnx.symbolic_opset9 import atan
from torch.onnx.symbolic_opset9 import atan2
from torch.onnx.symbolic_opset9 import baddbmm
from torch.onnx.symbolic_opset9 import batch_norm
from torch.onnx.symbolic_opset9 import bernoulli
from torch.onnx.symbolic_opset9 import bitwise_not
from torch.onnx.symbolic_opset9 import bitwise_or
from torch.onnx.symbolic_opset9 import bmm
from torch.onnx.symbolic_opset9 import broadcast_tensors
from torch.onnx.symbolic_opset9 import broadcast_to
from torch.onnx.symbolic_opset9 import bucketize
from torch.onnx.symbolic_opset9 import cat
from torch.onnx.symbolic_opset9 import cdist
from torch.onnx.symbolic_opset9 import ceil
from torch.onnx.symbolic_opset9 import clamp
from torch.onnx.symbolic_opset9 import clamp_max
from torch.onnx.symbolic_opset9 import clamp_min
from torch.onnx.symbolic_opset9 import clone
from torch.onnx.symbolic_opset9 import constant_pad_nd
from torch.onnx.symbolic_opset9 import contiguous
from torch.onnx.symbolic_opset9 import conv1d
from torch.onnx.symbolic_opset9 import conv2d
from torch.onnx.symbolic_opset9 import conv3d
from torch.onnx.symbolic_opset9 import conv_tbc
from torch.onnx.symbolic_opset9 import conv_transpose1d
from torch.onnx.symbolic_opset9 import conv_transpose2d
from torch.onnx.symbolic_opset9 import conv_transpose3d
from torch.onnx.symbolic_opset9 import convert_element_type
from torch.onnx.symbolic_opset9 import convolution
from torch.onnx.symbolic_opset9 import cos
from torch.onnx.symbolic_opset9 import cosine_similarity
from torch.onnx.symbolic_opset9 import cross
from torch.onnx.symbolic_opset9 import cumsum
from torch.onnx.symbolic_opset9 import detach
from torch.onnx.symbolic_opset9 import dim
from torch.onnx.symbolic_opset9 import div
from torch.onnx.symbolic_opset9 import dot
from torch.onnx.symbolic_opset9 import dropout
from torch.onnx.symbolic_opset9 import elu
from torch.onnx.symbolic_opset9 import embedding
from torch.onnx.symbolic_opset9 import embedding_bag
from torch.onnx.symbolic_opset9 import empty
from torch.onnx.symbolic_opset9 import empty_like
from torch.onnx.symbolic_opset9 import eq
from torch.onnx.symbolic_opset9 import erf
from torch.onnx.symbolic_opset9 import exp
from torch.onnx.symbolic_opset9 import expand
from torch.onnx.symbolic_opset9 import expand_as
from torch.onnx.symbolic_opset9 import eye
from torch.onnx.symbolic_opset9 import fill
from torch.onnx.symbolic_opset9 import flatten
from torch.onnx.symbolic_opset9 import floor
from torch.onnx.symbolic_opset9 import floor_divide
from torch.onnx.symbolic_opset9 import floordiv
from torch.onnx.symbolic_opset9 import frobenius_norm
from torch.onnx.symbolic_opset9 import full
from torch.onnx.symbolic_opset9 import full_like
from torch.onnx.symbolic_opset9 import gather
from torch.onnx.symbolic_opset9 import ge
from torch.onnx.symbolic_opset9 import gelu
from torch.onnx.symbolic_opset9 import get_pool_ceil_padding
from torch.onnx.symbolic_opset9 import glu
from torch.onnx.symbolic_opset9 import group_norm
from torch.onnx.symbolic_opset9 import gru
from torch.onnx.symbolic_opset9 import gt
from torch.onnx.symbolic_opset9 import hann_window
from torch.onnx.symbolic_opset9 import hardshrink
from torch.onnx.symbolic_opset9 import hardsigmoid
from torch.onnx.symbolic_opset9 import hardswish
from torch.onnx.symbolic_opset9 import hardtanh
from torch.onnx.symbolic_opset9 import index
from torch.onnx.symbolic_opset9 import index_add
from torch.onnx.symbolic_opset9 import index_copy
from torch.onnx.symbolic_opset9 import index_fill
from torch.onnx.symbolic_opset9 import index_put
from torch.onnx.symbolic_opset9 import index_select
from torch.onnx.symbolic_opset9 import instance_norm
from torch.onnx.symbolic_opset9 import is_floating_point
from torch.onnx.symbolic_opset9 import is_pinned
from torch.onnx.symbolic_opset9 import isnan
from torch.onnx.symbolic_opset9 import item
from torch.onnx.symbolic_opset9 import kl_div
from torch.onnx.symbolic_opset9 import layer_norm
from torch.onnx.symbolic_opset9 import le
from torch.onnx.symbolic_opset9 import leaky_relu
from torch.onnx.symbolic_opset9 import lerp
from torch.onnx.symbolic_opset9 import lift
from torch.onnx.symbolic_opset9 import linalg_cross
from torch.onnx.symbolic_opset9 import linalg_matrix_norm
from torch.onnx.symbolic_opset9 import linalg_norm
from torch.onnx.symbolic_opset9 import linalg_vector_norm
from torch.onnx.symbolic_opset9 import linear
from torch.onnx.symbolic_opset9 import linspace
from torch.onnx.symbolic_opset9 import log
from torch.onnx.symbolic_opset9 import log10
from torch.onnx.symbolic_opset9 import log1p
from torch.onnx.symbolic_opset9 import log2
from torch.onnx.symbolic_opset9 import log_sigmoid
from torch.onnx.symbolic_opset9 import log_softmax
from torch.onnx.symbolic_opset9 import logical_and
from torch.onnx.symbolic_opset9 import logical_not
from torch.onnx.symbolic_opset9 import logical_or
from torch.onnx.symbolic_opset9 import logical_xor
from torch.onnx.symbolic_opset9 import logit
from torch.onnx.symbolic_opset9 import logsumexp
from torch.onnx.symbolic_opset9 import lstm
from torch.onnx.symbolic_opset9 import lstm_cell
from torch.onnx.symbolic_opset9 import lt
from torch.onnx.symbolic_opset9 import masked_fill
from torch.onnx.symbolic_opset9 import masked_fill_
from torch.onnx.symbolic_opset9 import matmul
from torch.onnx.symbolic_opset9 import max
from torch.onnx.symbolic_opset9 import maximum
from torch.onnx.symbolic_opset9 import meshgrid
from torch.onnx.symbolic_opset9 import min
from torch.onnx.symbolic_opset9 import minimum
from torch.onnx.symbolic_opset9 import mish
from torch.onnx.symbolic_opset9 import mm
from torch.onnx.symbolic_opset9 import movedim
from torch.onnx.symbolic_opset9 import mse_loss
from torch.onnx.symbolic_opset9 import mul
from torch.onnx.symbolic_opset9 import multinomial
from torch.onnx.symbolic_opset9 import mv
from torch.onnx.symbolic_opset9 import narrow
from torch.onnx.symbolic_opset9 import native_layer_norm
from torch.onnx.symbolic_opset9 import ne
from torch.onnx.symbolic_opset9 import neg
from torch.onnx.symbolic_opset9 import new_empty
from torch.onnx.symbolic_opset9 import new_full
from torch.onnx.symbolic_opset9 import new_ones
from torch.onnx.symbolic_opset9 import new_zeros
from torch.onnx.symbolic_opset9 import nonzero
from torch.onnx.symbolic_opset9 import nonzero_numpy
from torch.onnx.symbolic_opset9 import noop_complex_operators
from torch.onnx.symbolic_opset9 import norm
from torch.onnx.symbolic_opset9 import numel
from torch.onnx.symbolic_opset9 import numpy_T
from torch.onnx.symbolic_opset9 import one_hot
from torch.onnx.symbolic_opset9 import ones
from torch.onnx.symbolic_opset9 import ones_like
from torch.onnx.symbolic_opset9 import onnx_placeholder
from torch.onnx.symbolic_opset9 import pad
from torch.onnx.symbolic_opset9 import pairwise_distance
from torch.onnx.symbolic_opset9 import permute
from torch.onnx.symbolic_opset9 import pixel_shuffle
from torch.onnx.symbolic_opset9 import pixel_unshuffle
from torch.onnx.symbolic_opset9 import pow
from torch.onnx.symbolic_opset9 import prelu
from torch.onnx.symbolic_opset9 import prim_constant
from torch.onnx.symbolic_opset9 import prim_constant_chunk
from torch.onnx.symbolic_opset9 import prim_constant_split
from torch.onnx.symbolic_opset9 import prim_data
from torch.onnx.symbolic_opset9 import prim_device
from torch.onnx.symbolic_opset9 import prim_dtype
from torch.onnx.symbolic_opset9 import prim_if
from torch.onnx.symbolic_opset9 import prim_layout
from torch.onnx.symbolic_opset9 import prim_list_construct
from torch.onnx.symbolic_opset9 import prim_list_unpack
from torch.onnx.symbolic_opset9 import prim_loop
from torch.onnx.symbolic_opset9 import prim_max
from torch.onnx.symbolic_opset9 import prim_min
from torch.onnx.symbolic_opset9 import prim_shape
from torch.onnx.symbolic_opset9 import prim_tolist
from torch.onnx.symbolic_opset9 import prim_tuple_construct
from torch.onnx.symbolic_opset9 import prim_type
from torch.onnx.symbolic_opset9 import prim_unchecked_cast
from torch.onnx.symbolic_opset9 import prim_uninitialized
from torch.onnx.symbolic_opset9 import rand
from torch.onnx.symbolic_opset9 import rand_like
from torch.onnx.symbolic_opset9 import randint
from torch.onnx.symbolic_opset9 import randint_like
from torch.onnx.symbolic_opset9 import randn
from torch.onnx.symbolic_opset9 import randn_like
from torch.onnx.symbolic_opset9 import reciprocal
from torch.onnx.symbolic_opset9 import reflection_pad
from torch.onnx.symbolic_opset9 import relu
from torch.onnx.symbolic_opset9 import relu6
from torch.onnx.symbolic_opset9 import remainder
from torch.onnx.symbolic_opset9 import repeat
from torch.onnx.symbolic_opset9 import repeat_interleave
from torch.onnx.symbolic_opset9 import replication_pad
from torch.onnx.symbolic_opset9 import reshape
from torch.onnx.symbolic_opset9 import reshape_as
from torch.onnx.symbolic_opset9 import roll
from torch.onnx.symbolic_opset9 import rrelu
from torch.onnx.symbolic_opset9 import rsqrt
from torch.onnx.symbolic_opset9 import rsub
from torch.onnx.symbolic_opset9 import scalar_tensor
from torch.onnx.symbolic_opset9 import scatter
from torch.onnx.symbolic_opset9 import scatter_add
from torch.onnx.symbolic_opset9 import select
from torch.onnx.symbolic_opset9 import selu
from torch.onnx.symbolic_opset9 import sigmoid
from torch.onnx.symbolic_opset9 import sign
from torch.onnx.symbolic_opset9 import silu
from torch.onnx.symbolic_opset9 import sin
from torch.onnx.symbolic_opset9 import size
from torch.onnx.symbolic_opset9 import slice
from torch.onnx.symbolic_opset9 import softmax
from torch.onnx.symbolic_opset9 import softplus
from torch.onnx.symbolic_opset9 import softshrink
from torch.onnx.symbolic_opset9 import sort
from torch.onnx.symbolic_opset9 import split
from torch.onnx.symbolic_opset9 import split_with_sizes
from torch.onnx.symbolic_opset9 import sqrt
from torch.onnx.symbolic_opset9 import square
from torch.onnx.symbolic_opset9 import squeeze
from torch.onnx.symbolic_opset9 import stack
from torch.onnx.symbolic_opset9 import std
from torch.onnx.symbolic_opset9 import std_mean
from torch.onnx.symbolic_opset9 import sub
from torch.onnx.symbolic_opset9 import t
from torch.onnx.symbolic_opset9 import take
from torch.onnx.symbolic_opset9 import tan
from torch.onnx.symbolic_opset9 import tanh
from torch.onnx.symbolic_opset9 import tanhshrink
from torch.onnx.symbolic_opset9 import tensor
from torch.onnx.symbolic_opset9 import threshold
from torch.onnx.symbolic_opset9 import to
from torch.onnx.symbolic_opset9 import topk
from torch.onnx.symbolic_opset9 import transpose
from torch.onnx.symbolic_opset9 import true_divide
from torch.onnx.symbolic_opset9 import type_as
from torch.onnx.symbolic_opset9 import unbind
from torch.onnx.symbolic_opset9 import unfold
from torch.onnx.symbolic_opset9 import unsafe_chunk
from torch.onnx.symbolic_opset9 import unsafe_split
from torch.onnx.symbolic_opset9 import unsafe_split_with_sizes
from torch.onnx.symbolic_opset9 import unsqueeze
from torch.onnx.symbolic_opset9 import unsupported_complex_operators
from torch.onnx.symbolic_opset9 import unused
from torch.onnx.symbolic_opset9 import var
from torch.onnx.symbolic_opset9 import var_mean
from torch.onnx.symbolic_opset9 import view
from torch.onnx.symbolic_opset9 import view_as
from torch.onnx.symbolic_opset9 import where
from torch.onnx.symbolic_opset9 import wrap_logical_op_with_cast_to
from torch.onnx.symbolic_opset9 import wrap_logical_op_with_negation
from torch.onnx.symbolic_opset9 import zero
from torch.onnx.symbolic_opset9 import zeros
from torch.onnx.symbolic_opset9 import zeros_like
from torch.onnx.utils import GLOBALS
from torch.onnx.utils import disable_apex_o2_state_dict_hook
from torch.onnx.utils import export
from torch.onnx.utils import exporter_context
from torch.onnx.utils import model_signature
from torch.onnx.utils import register_custom_op_symbolic
from torch.onnx.utils import select_model_mode_for_export
from torch.onnx.utils import setup_onnx_logging
from torch.onnx.utils import unconvertible_ops
from torch.onnx.utils import unpack_quantized_tensor
from torch.onnx.utils import unregister_custom_op_symbolic
from torch.onnx.utils import warn_on_static_input_change
from torch.onnx.verification import GLOBALS
from torch.onnx.verification import GraphInfo
from torch.onnx.verification import GraphInfoPrettyPrinter
from torch.onnx.verification import OnnxBackend
from torch.onnx.verification import OnnxTestCaseRepro
from torch.onnx.verification import VerificationInfo
from torch.onnx.verification import VerificationOptions
from torch.onnx.verification import check_export_model_diff
from torch.onnx.verification import find_mismatch
from torch.onnx.verification import verify
from torch.onnx.verification import verify_aten_graph
from torch.onnx.verification import verify_onnx_program
from torch.optim import Adafactor
from torch.optim.adadelta import Adadelta
from torch.optim.adadelta import adadelta
from torch.optim.adagrad import Adagrad
from torch.optim.adagrad import adagrad
from torch.optim.adam import Adam
from torch.optim.adam import adam
from torch.optim.adamax import Adamax
from torch.optim.adamax import adamax
from torch.optim.adamw import AdamW
from torch.optim.adamw import adamw
from torch.optim.asgd import ASGD
from torch.optim.asgd import asgd
from torch.optim.lbfgs import LBFGS
from torch.optim.lr_scheduler import ChainedScheduler
from torch.optim.lr_scheduler import ConstantLR
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from torch.optim.lr_scheduler import CyclicLR
from torch.optim.lr_scheduler import ExponentialLR
from torch.optim.lr_scheduler import LRScheduler
from torch.optim.lr_scheduler import LambdaLR
from torch.optim.lr_scheduler import LinearLR
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.lr_scheduler import MultiplicativeLR
from torch.optim.lr_scheduler import OneCycleLR
from torch.optim.lr_scheduler import PolynomialLR
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.optim.lr_scheduler import SequentialLR
from torch.optim.lr_scheduler import StepLR
from torch.optim.nadam import NAdam
from torch.optim.nadam import nadam
from torch.optim.optimizer import Optimizer
from torch.optim.optimizer import R
from torch.optim.optimizer import T
from torch.optim.optimizer import register_optimizer_step_post_hook
from torch.optim.optimizer import register_optimizer_step_pre_hook
from torch.optim.optimizer import required
from torch.optim.radam import RAdam
from torch.optim.radam import radam
from torch.optim.rmsprop import RMSprop
from torch.optim.rmsprop import rmsprop
from torch.optim.rprop import Rprop
from torch.optim.rprop import rprop
from torch.optim.sgd import SGD
from torch.optim.sgd import sgd
from torch.optim.sparse_adam import SparseAdam
from torch.optim.swa_utils import AveragedModel
from torch.optim.swa_utils import SWALR
from torch.optim.swa_utils import get_ema_avg_fn
from torch.optim.swa_utils import get_ema_multi_avg_fn
from torch.optim.swa_utils import get_swa_avg_fn
from torch.optim.swa_utils import get_swa_multi_avg_fn
from torch.optim.swa_utils import update_bn
from torch.overrides import BaseTorchFunctionMode
from torch.overrides import TorchFunctionMode
from torch.overrides import enable_reentrant_dispatch
from torch.overrides import get_default_nowrap_functions
from torch.overrides import get_ignored_functions
from torch.overrides import get_overridable_functions
from torch.overrides import get_testing_overrides
from torch.overrides import handle_torch_function
from torch.overrides import is_tensor_like
from torch.overrides import is_tensor_method_or_property
from torch.overrides import resolve_name
from torch.overrides import wrap_torch_function
from torch.package import sys_importer
from torch.package.analyze.find_first_use_of_broken_modules import find_first_use_of_broken_modules
from torch.package.analyze.is_from_package import is_from_package
from torch.package.analyze.trace_dependencies import trace_dependencies
from torch.package.file_structure_representation import Directory
from torch.package.find_file_dependencies import find_files_source_depends_on
from torch.package.glob_group import GlobGroup
from torch.package.importer import Importer
from torch.package.importer import ObjMismatchError
from torch.package.importer import ObjNotFoundError
from torch.package.importer import OrderedImporter
from torch.package.importer import demangle
from torch.package.importer import get_mangle_prefix
from torch.package.importer import is_mangled
from torch.package.importer import sys_importer
from torch.package.package_exporter import DiGraph
from torch.package.package_exporter import EmptyMatchError
from torch.package.package_exporter import PackageExporter
from torch.package.package_exporter import PackagingError
from torch.package.package_exporter import PackagingErrorReason
from torch.package.package_exporter import create_pickler
from torch.package.package_exporter import is_stdlib_module
from torch.package.package_exporter import sys_importer
from torch.package.package_importer import DirectoryReader
from torch.package.package_importer import EXTERN_IMPORT_COMPAT_NAME_MAPPING
from torch.package.package_importer import IMPLICIT_IMPORT_ALLOWLIST
from torch.package.package_importer import PackageImporter
from torch.package.package_importer import PackageMangler
from torch.package.package_importer import PackageUnpickler
from torch.profiler import RecordScope
from torch.profiler import is_fbcode
from torch.profiler.itt import is_available
from torch.profiler.itt import mark
from torch.profiler.itt import range
from torch.profiler.itt import range_pop
from torch.profiler.itt import range_push
from torch.profiler.profiler import ExecutionTraceObserver
from torch.profiler.profiler import MemoryProfile
from torch.profiler.profiler import MemoryProfileTimeline
from torch.profiler.profiler import ProfilerAction
from torch.profiler.profiler import profile
from torch.profiler.profiler import schedule
from torch.profiler.profiler import supported_activities
from torch.profiler.profiler import tensorboard_trace_handler
from torch.quantization import DEFAULT_DYNAMIC_QUANT_MODULE_MAPPINGS
from torch.quantization import DEFAULT_FLOAT_TO_QUANTIZED_OPERATOR_MAPPINGS
from torch.quantization import DEFAULT_MODULE_TO_ACT_POST_PROCESS
from torch.quantization import DEFAULT_QAT_MODULE_MAPPINGS
from torch.quantization import DEFAULT_REFERENCE_STATIC_QUANT_MODULE_MAPPINGS
from torch.quantization import DEFAULT_STATIC_QUANT_MODULE_MAPPINGS
from torch.quantization import default_activation_only_qconfig
from torch.quantization import default_debug_qconfig
from torch.quantization import default_dynamic_qconfig
from torch.quantization import default_dynamic_quant_observer
from torch.quantization import default_eval_fn
from torch.quantization import default_fake_quant
from torch.quantization import default_fixed_qparams_range_0to1_fake_quant
from torch.quantization import default_fixed_qparams_range_neg1to1_fake_quant
from torch.quantization import default_float_qparams_observer
from torch.quantization import default_fused_act_fake_quant
from torch.quantization import default_fused_per_channel_wt_fake_quant
from torch.quantization import default_fused_wt_fake_quant
from torch.quantization import default_histogram_fake_quant
from torch.quantization import default_histogram_observer
from torch.quantization import default_observer
from torch.quantization import default_per_channel_qconfig
from torch.quantization import default_per_channel_weight_fake_quant
from torch.quantization import default_per_channel_weight_observer
from torch.quantization import default_qat_qconfig
from torch.quantization import default_qat_qconfig_v2
from torch.quantization import default_qconfig
from torch.quantization import default_weight_fake_quant
from torch.quantization import default_weight_observer
from torch.quantization import default_weight_only_qconfig
from torch.quantization import float16_dynamic_qconfig
from torch.quantization import float16_static_qconfig
from torch.quantization import float_qparams_weight_only_qconfig
from torch.quantization import per_channel_dynamic_qconfig
from torch.quantization.fake_quantize import default_fake_quant
from torch.quantization.fake_quantize import default_fixed_qparams_range_0to1_fake_quant
from torch.quantization.fake_quantize import default_fixed_qparams_range_neg1to1_fake_quant
from torch.quantization.fake_quantize import default_fused_act_fake_quant
from torch.quantization.fake_quantize import default_fused_per_channel_wt_fake_quant
from torch.quantization.fake_quantize import default_fused_wt_fake_quant
from torch.quantization.fake_quantize import default_histogram_fake_quant
from torch.quantization.fake_quantize import default_per_channel_weight_fake_quant
from torch.quantization.fake_quantize import default_weight_fake_quant
from torch.quantization.fx.quantization_patterns import BatchNormQuantizeHandler
from torch.quantization.fx.quantization_patterns import BinaryOpQuantizeHandler
from torch.quantization.fx.quantization_patterns import CatQuantizeHandler
from torch.quantization.fx.quantization_patterns import ConvReluQuantizeHandler
from torch.quantization.fx.quantization_patterns import CopyNodeQuantizeHandler
from torch.quantization.fx.quantization_patterns import CustomModuleQuantizeHandler
from torch.quantization.fx.quantization_patterns import DefaultNodeQuantizeHandler
from torch.quantization.fx.quantization_patterns import EmbeddingQuantizeHandler
from torch.quantization.fx.quantization_patterns import FixedQParamsOpQuantizeHandler
from torch.quantization.fx.quantization_patterns import GeneralTensorShapeOpQuantizeHandler
from torch.quantization.fx.quantization_patterns import LinearReLUQuantizeHandler
from torch.quantization.fx.quantization_patterns import QuantizeHandler
from torch.quantization.fx.quantization_patterns import RNNDynamicQuantizeHandler
from torch.quantization.fx.quantization_patterns import StandaloneModuleQuantizeHandler
from torch.quantization.observer import default_dynamic_quant_observer
from torch.quantization.observer import default_float_qparams_observer
from torch.quantization.observer import default_histogram_observer
from torch.quantization.observer import default_observer
from torch.quantization.observer import default_per_channel_weight_observer
from torch.quantization.observer import default_weight_observer
from torch.quantization.qconfig import default_activation_only_qconfig
from torch.quantization.qconfig import default_debug_qconfig
from torch.quantization.qconfig import default_dynamic_qconfig
from torch.quantization.qconfig import default_per_channel_qconfig
from torch.quantization.qconfig import default_qat_qconfig
from torch.quantization.qconfig import default_qat_qconfig_v2
from torch.quantization.qconfig import default_qconfig
from torch.quantization.qconfig import default_weight_only_qconfig
from torch.quantization.qconfig import float16_dynamic_qconfig
from torch.quantization.qconfig import float16_static_qconfig
from torch.quantization.qconfig import float_qparams_weight_only_qconfig
from torch.quantization.qconfig import per_channel_dynamic_qconfig
from torch.quantization.quantization_mappings import DEFAULT_DYNAMIC_QUANT_MODULE_MAPPINGS
from torch.quantization.quantization_mappings import DEFAULT_FLOAT_TO_QUANTIZED_OPERATOR_MAPPINGS
from torch.quantization.quantization_mappings import DEFAULT_MODULE_TO_ACT_POST_PROCESS
from torch.quantization.quantization_mappings import DEFAULT_QAT_MODULE_MAPPINGS
from torch.quantization.quantization_mappings import DEFAULT_REFERENCE_STATIC_QUANT_MODULE_MAPPINGS
from torch.quantization.quantization_mappings import DEFAULT_STATIC_QUANT_MODULE_MAPPINGS
from torch.quasirandom import SobolEngine
from torch.random import default_generator
from torch.random import fork_rng
from torch.random import get_rng_state
from torch.random import initial_seed
from torch.random import manual_seed
from torch.random import seed
from torch.random import set_rng_state
from torch.return_types import SequenceKey
from torch.return_types import all_return_types
from torch.return_types import aminmax
from torch.return_types import aminmax_out
from torch.return_types import cummax
from torch.return_types import cummax_out
from torch.return_types import cummin
from torch.return_types import cummin_out
from torch.return_types import frexp
from torch.return_types import frexp_out
from torch.return_types import geqrf
from torch.return_types import geqrf_out
from torch.return_types import histogram
from torch.return_types import histogram_out
from torch.return_types import histogramdd
from torch.return_types import kthvalue
from torch.return_types import kthvalue_out
from torch.return_types import linalg_cholesky_ex
from torch.return_types import linalg_cholesky_ex_out
from torch.return_types import linalg_eig
from torch.return_types import linalg_eig_out
from torch.return_types import linalg_eigh
from torch.return_types import linalg_eigh_out
from torch.return_types import linalg_inv_ex
from torch.return_types import linalg_inv_ex_out
from torch.return_types import linalg_ldl_factor
from torch.return_types import linalg_ldl_factor_ex
from torch.return_types import linalg_ldl_factor_ex_out
from torch.return_types import linalg_ldl_factor_out
from torch.return_types import linalg_lstsq
from torch.return_types import linalg_lstsq_out
from torch.return_types import linalg_lu
from torch.return_types import linalg_lu_factor
from torch.return_types import linalg_lu_factor_ex
from torch.return_types import linalg_lu_factor_ex_out
from torch.return_types import linalg_lu_factor_out
from torch.return_types import linalg_lu_out
from torch.return_types import linalg_qr
from torch.return_types import linalg_qr_out
from torch.return_types import linalg_slogdet
from torch.return_types import linalg_slogdet_out
from torch.return_types import linalg_solve_ex
from torch.return_types import linalg_solve_ex_out
from torch.return_types import linalg_svd
from torch.return_types import linalg_svd_out
from torch.return_types import lu_unpack
from torch.return_types import lu_unpack_out
from torch.return_types import max
from torch.return_types import max_out
from torch.return_types import median
from torch.return_types import median_out
from torch.return_types import min
from torch.return_types import min_out
from torch.return_types import mode
from torch.return_types import mode_out
from torch.return_types import name
from torch.return_types import nanmedian
from torch.return_types import nanmedian_out
from torch.return_types import pytree_register_structseq
from torch.return_types import qr
from torch.return_types import qr_out
from torch.return_types import register_pytree_node
from torch.return_types import slogdet
from torch.return_types import slogdet_out
from torch.return_types import sort
from torch.return_types import sort_out
from torch.return_types import svd
from torch.return_types import svd_out
from torch.return_types import topk
from torch.return_types import topk_out
from torch.return_types import triangular_solve
from torch.return_types import triangular_solve_out
from torch.serialization import LoadEndianness
from torch.serialization import SourceChangeWarning
from torch.serialization import StorageType
from torch.serialization import T
from torch.serialization import add_safe_globals
from torch.serialization import check_module_version_greater_or_equal
from torch.serialization import clear_safe_globals
from torch.serialization import default_restore_location
from torch.serialization import get_crc32_options
from torch.serialization import get_default_load_endianness
from torch.serialization import get_default_mmap_options
from torch.serialization import get_safe_globals
from torch.serialization import get_unsafe_globals_in_checkpoint
from torch.serialization import load
from torch.serialization import location_tag
from torch.serialization import mkdtemp
from torch.serialization import normalize_storage_type
from torch.serialization import register_package
from torch.serialization import safe_globals
from torch.serialization import save
from torch.serialization import set_crc32_options
from torch.serialization import set_default_load_endianness
from torch.serialization import set_default_mmap_options
from torch.serialization import skip_data
from torch.serialization import storage_to_tensor_type
from torch.serialization import validate_cuda_device
from torch.serialization import validate_hpu_device
from torch.signal.windows.windows import bartlett
from torch.signal.windows.windows import blackman
from torch.signal.windows.windows import cosine
from torch.signal.windows.windows import exponential
from torch.signal.windows.windows import factory_common_args
from torch.signal.windows.windows import gaussian
from torch.signal.windows.windows import general_cosine
from torch.signal.windows.windows import general_hamming
from torch.signal.windows.windows import hamming
from torch.signal.windows.windows import hann
from torch.signal.windows.windows import kaiser
from torch.signal.windows.windows import merge_dicts
from torch.signal.windows.windows import nuttall
from torch.signal.windows.windows import parse_kwargs
from torch.signal.windows.windows import window_common_args
from torch.sparse import BFloat16Tensor
from torch.sparse import ByteTensor
from torch.sparse import CharTensor
from torch.sparse import DoubleTensor
from torch.sparse import FloatTensor
from torch.sparse import HalfTensor
from torch.sparse import IntTensor
from torch.sparse import LongTensor
from torch.sparse import ShortTensor
from torch.sparse import as_sparse_gradcheck
from torch.sparse import check_sparse_tensor_invariants
from torch.sparse import sampled_addmm
from torch.sparse import sum
from torch.sparse.semi_structured import SparseSemiStructuredTensor
from torch.sparse.semi_structured import SparseSemiStructuredTensorCUSPARSELT
from torch.sparse.semi_structured import SparseSemiStructuredTensorCUTLASS
from torch.sparse.semi_structured import fallback_dispatcher
from torch.sparse.semi_structured import semi_sparse_addmm
from torch.sparse.semi_structured import semi_sparse_detach
from torch.sparse.semi_structured import semi_sparse_indices
from torch.sparse.semi_structured import semi_sparse_linear
from torch.sparse.semi_structured import semi_sparse_mm
from torch.sparse.semi_structured import semi_sparse_scaled_mm
from torch.sparse.semi_structured import semi_sparse_t
from torch.sparse.semi_structured import semi_sparse_values
from torch.sparse.semi_structured import semi_sparse_view
from torch.sparse.semi_structured import sparse_semi_structured_from_dense_cutlass
from torch.sparse.semi_structured import sparse_semi_structured_to_dense_cutlass
from torch.sparse.semi_structured import to_sparse_semi_structured
from torch.special import airy_ai
from torch.special import bessel_j0
from torch.special import bessel_j1
from torch.special import bessel_y0
from torch.special import bessel_y1
from torch.special import chebyshev_polynomial_t
from torch.special import chebyshev_polynomial_u
from torch.special import chebyshev_polynomial_v
from torch.special import chebyshev_polynomial_w
from torch.special import common_args
from torch.special import digamma
from torch.special import entr
from torch.special import erf
from torch.special import erfc
from torch.special import erfcx
from torch.special import erfinv
from torch.special import exp2
from torch.special import expit
from torch.special import expm1
from torch.special import gammainc
from torch.special import gammaincc
from torch.special import gammaln
from torch.special import hermite_polynomial_h
from torch.special import hermite_polynomial_he
from torch.special import i0
from torch.special import i0e
from torch.special import i1
from torch.special import i1e
from torch.special import laguerre_polynomial_l
from torch.special import legendre_polynomial_p
from torch.special import log1p
from torch.special import log_ndtr
from torch.special import log_softmax
from torch.special import logit
from torch.special import logsumexp
from torch.special import modified_bessel_i0
from torch.special import modified_bessel_i1
from torch.special import modified_bessel_k0
from torch.special import modified_bessel_k1
from torch.special import multi_dim_common
from torch.special import multigammaln
from torch.special import ndtr
from torch.special import ndtri
from torch.special import polygamma
from torch.special import psi
from torch.special import round
from torch.special import scaled_modified_bessel_k0
from torch.special import scaled_modified_bessel_k1
from torch.special import shifted_chebyshev_polynomial_t
from torch.special import shifted_chebyshev_polynomial_u
from torch.special import shifted_chebyshev_polynomial_v
from torch.special import shifted_chebyshev_polynomial_w
from torch.special import sinc
from torch.special import softmax
from torch.special import spherical_bessel_j0
from torch.special import xlog1py
from torch.special import xlogy
from torch.special import zeta
from torch.storage import T
from torch.storage import TypedStorage
from torch.storage import UntypedStorage
from torch.testing import assert_allclose
from torch.testing import assert_close
from torch.testing import make_tensor
from torch.torch_version import InvalidVersion
from torch.torch_version import TorchVersion
from torch.torch_version import Version
from torch.torch_version import cmp_method
from torch.torch_version import internal_version
from torch.types import Storage
from torch.types import py_sym_types
from torch.utils import cmake_prefix_path
from torch.utils import set_module
from torch.utils import swap_tensors
from torch.utils.backcompat import Warning
from torch.utils.backcompat import broadcast_warning
from torch.utils.backcompat import keepdim_warning
from torch.utils.backend_registration import generate_methods_for_privateuse1_backend
from torch.utils.backend_registration import rename_privateuse1_backend
from torch.utils.benchmark.examples.compare import FauxTorch
from torch.utils.benchmark.examples.compare import main
from torch.utils.benchmark.examples.fuzzer import main
from torch.utils.benchmark.examples.op_benchmark import assert_dicts_equal
from torch.utils.benchmark.examples.op_benchmark import main
from torch.utils.benchmark.examples.op_benchmark import run
from torch.utils.benchmark.examples.simple_timeit import main
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import BENCHMARKS
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import BENCHMARK_MAP
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import BENCHMARK_NAMES
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import Benchmark
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import DEVICE_NAMES
from torch.utils.benchmark.examples.spectral_ops_fuzz_test import run_benchmark
from torch.utils.benchmark.op_fuzzers.binary import BinaryOpFuzzer
from torch.utils.benchmark.op_fuzzers.sparse_binary import BinaryOpSparseFuzzer
from torch.utils.benchmark.op_fuzzers.sparse_unary import UnaryOpSparseFuzzer
from torch.utils.benchmark.op_fuzzers.spectral import REGULAR_SIZES
from torch.utils.benchmark.op_fuzzers.spectral import SpectralOpFuzzer
from torch.utils.benchmark.op_fuzzers.spectral import i
from torch.utils.benchmark.op_fuzzers.spectral import ij
from torch.utils.benchmark.op_fuzzers.spectral import ijk
from torch.utils.benchmark.op_fuzzers.spectral import j
from torch.utils.benchmark.op_fuzzers.spectral import k
from torch.utils.benchmark.op_fuzzers.spectral import power_range
from torch.utils.benchmark.op_fuzzers.unary import UnaryOpFuzzer
from torch.utils.benchmark.utils.common import Measurement
from torch.utils.benchmark.utils.common import TaskSpec
from torch.utils.benchmark.utils.common import ordered_unique
from torch.utils.benchmark.utils.common import select_unit
from torch.utils.benchmark.utils.common import set_torch_threads
from torch.utils.benchmark.utils.common import trim_sigfig
from torch.utils.benchmark.utils.common import unit_to_english
from torch.utils.benchmark.utils.compare import Colorize
from torch.utils.benchmark.utils.compare import Compare
from torch.utils.benchmark.utils.compare import Table
from torch.utils.benchmark.utils.compare import optional_min
from torch.utils.benchmark.utils.compile import CompileCounterWithBackend
from torch.utils.benchmark.utils.compile import tabulate
from torch.utils.benchmark.utils.cpp_jit import COMPAT_CALLGRIND_BINDINGS
from torch.utils.benchmark.utils.cpp_jit import CXX_FLAGS
from torch.utils.benchmark.utils.cpp_jit import CallgrindModuleType
from torch.utils.benchmark.utils.cpp_jit import EXTRA_INCLUDE_PATHS
from torch.utils.benchmark.utils.cpp_jit import compile_callgrind_template
from torch.utils.benchmark.utils.cpp_jit import compile_timeit_template
from torch.utils.benchmark.utils.cpp_jit import get_compat_bindings
from torch.utils.benchmark.utils.fuzzer import FuzzedParameter
from torch.utils.benchmark.utils.fuzzer import FuzzedTensor
from torch.utils.benchmark.utils.fuzzer import Fuzzer
from torch.utils.benchmark.utils.fuzzer import ParameterAlias
from torch.utils.benchmark.utils.fuzzer import dtype_size
from torch.utils.benchmark.utils.fuzzer import prod
from torch.utils.benchmark.utils.sparse_fuzzer import FuzzedSparseTensor
from torch.utils.benchmark.utils.timer import CPPTimer
from torch.utils.benchmark.utils.timer import Language
from torch.utils.benchmark.utils.timer import TimeitModuleType
from torch.utils.benchmark.utils.timer import Timer
from torch.utils.benchmark.utils.timer import TimerClass
from torch.utils.benchmark.utils.timer import timer
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import CALLGRIND_SINGLETON
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import CallgrindStats
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import CopyIfCallgrind
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import FunctionCount
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import FunctionCounts
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import GlobalsBridge
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import Serialization
from torch.utils.benchmark.utils.valgrind_wrapper.timer_interface import wrapper_singleton
from torch.utils.bundled_inputs import InflatableArg
from torch.utils.bundled_inputs import T
from torch.utils.bundled_inputs import augment_many_model_functions_with_bundled_inputs
from torch.utils.bundled_inputs import augment_model_with_bundled_inputs
from torch.utils.bundled_inputs import bundle_inputs
from torch.utils.bundled_inputs import bundle_large_tensor
from torch.utils.bundled_inputs import bundle_randn
from torch.utils.bundled_inputs import wrap_cpp_module
from torch.utils.checkpoint import CheckpointError
from torch.utils.checkpoint import CheckpointFunction
from torch.utils.checkpoint import CheckpointPolicy
from torch.utils.checkpoint import DefaultDeviceType
from torch.utils.checkpoint import LoggingTensorMode
from torch.utils.checkpoint import SAC_IGNORED_OPS
from torch.utils.checkpoint import SelectiveCheckpointContext
from torch.utils.checkpoint import capture_logs
from torch.utils.checkpoint import check_backward_validity
from torch.utils.checkpoint import checkpoint
from torch.utils.checkpoint import checkpoint_sequential
from torch.utils.checkpoint import create_selective_checkpoint_contexts
from torch.utils.checkpoint import detach_variable
from torch.utils.checkpoint import get_device_states
from torch.utils.checkpoint import noop_context_fn
from torch.utils.checkpoint import set_checkpoint_debug_enabled
from torch.utils.checkpoint import set_checkpoint_early_stop
from torch.utils.checkpoint import set_device_states
from torch.utils.checkpoint import tree_map
from torch.utils.collect_env import COMMON_PATTERNS
from torch.utils.collect_env import CONDA_PATTERNS
from torch.utils.collect_env import NVIDIA_PATTERNS
from torch.utils.collect_env import ONEAPI_PATTERNS
from torch.utils.collect_env import PIP_PATTERNS
from torch.utils.collect_env import SystemEnv
from torch.utils.collect_env import check_release_file
from torch.utils.collect_env import env_info_fmt
from torch.utils.collect_env import get_cachingallocator_config
from torch.utils.collect_env import get_clang_version
from torch.utils.collect_env import get_cmake_version
from torch.utils.collect_env import get_conda_packages
from torch.utils.collect_env import get_cpu_info
from torch.utils.collect_env import get_cuda_module_loading_config
from torch.utils.collect_env import get_cudnn_version
from torch.utils.collect_env import get_env_info
from torch.utils.collect_env import get_gcc_version
from torch.utils.collect_env import get_gpu_info
from torch.utils.collect_env import get_intel_gpu_detected
from torch.utils.collect_env import get_intel_gpu_driver_version
from torch.utils.collect_env import get_intel_gpu_onboard
from torch.utils.collect_env import get_libc_version
from torch.utils.collect_env import get_linux_pkg_version
from torch.utils.collect_env import get_lsb_version
from torch.utils.collect_env import get_mac_version
from torch.utils.collect_env import get_nvidia_driver_version
from torch.utils.collect_env import get_nvidia_smi
from torch.utils.collect_env import get_os
from torch.utils.collect_env import get_pip_packages
from torch.utils.collect_env import get_platform
from torch.utils.collect_env import get_pretty_env_info
from torch.utils.collect_env import get_python_platform
from torch.utils.collect_env import get_running_cuda_version
from torch.utils.collect_env import get_windows_version
from torch.utils.collect_env import is_xnnpack_available
from torch.utils.collect_env import main
from torch.utils.collect_env import pretty_str
from torch.utils.collect_env import run
from torch.utils.collect_env import run_and_parse_first_match
from torch.utils.collect_env import run_and_read_all
from torch.utils.collect_env import run_and_return_first_line
from torch.utils.cpp_backtrace import get_cpp_backtrace
from torch.utils.cpp_extension import BuildExtension
from torch.utils.cpp_extension import COMMON_HIPCC_FLAGS
from torch.utils.cpp_extension import COMMON_HIP_FLAGS
from torch.utils.cpp_extension import COMMON_MSVC_FLAGS
from torch.utils.cpp_extension import COMMON_NVCC_FLAGS
from torch.utils.cpp_extension import CUDAExtension
from torch.utils.cpp_extension import CUDA_CLANG_VERSIONS
from torch.utils.cpp_extension import CUDA_GCC_VERSIONS
from torch.utils.cpp_extension import CUDA_HOME
from torch.utils.cpp_extension import CUDNN_HOME
from torch.utils.cpp_extension import CppExtension
from torch.utils.cpp_extension import ExtensionVersioner
from torch.utils.cpp_extension import HIP_HOME
from torch.utils.cpp_extension import JIT_EXTENSION_VERSIONER
from torch.utils.cpp_extension import MINIMUM_CLANG_VERSION
from torch.utils.cpp_extension import MINIMUM_GCC_VERSION
from torch.utils.cpp_extension import MINIMUM_MSVC_VERSION
from torch.utils.cpp_extension import MSVC_IGNORE_CUDAFE_WARNINGS
from torch.utils.cpp_extension import PLAT_TO_VCVARS
from torch.utils.cpp_extension import ROCM_HOME
from torch.utils.cpp_extension import ROCM_VERSION
from torch.utils.cpp_extension import SUBPROCESS_DECODE_ARGS
from torch.utils.cpp_extension import SYCL_HOME
from torch.utils.cpp_extension import SyclExtension
from torch.utils.cpp_extension import check_compiler_is_gcc
from torch.utils.cpp_extension import check_compiler_ok_for_platform
from torch.utils.cpp_extension import get_compiler_abi_compatibility_and_version
from torch.utils.cpp_extension import get_cxx_compiler
from torch.utils.cpp_extension import get_default_build_root
from torch.utils.cpp_extension import include_paths
from torch.utils.cpp_extension import is_ninja_available
from torch.utils.cpp_extension import library_paths
from torch.utils.cpp_extension import load
from torch.utils.cpp_extension import load_inline
from torch.utils.cpp_extension import min_supported_cpython
from torch.utils.cpp_extension import remove_extension_h_precompiler_headers
from torch.utils.cpp_extension import verify_ninja_availability
from torch.utils.data import argument_validation
from torch.utils.data import default_collate
from torch.utils.data import default_convert
from torch.utils.data import functional_datapipe
from torch.utils.data import get_worker_info
from torch.utils.data import guaranteed_datapipes_determinism
from torch.utils.data import non_deterministic
from torch.utils.data import runtime_validation
from torch.utils.data import runtime_validation_disabled
from torch.utils.data.backward_compatibility import worker_init_fn
from torch.utils.data.dataloader import DataLoader
from torch.utils.data.dataloader import ExceptionWrapper
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import PandasWrapper
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import concat
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import create_dataframe
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import get_columns
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import get_df_wrapper
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import get_item
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import get_len
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import is_column
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import is_dataframe
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import iterate
from torch.utils.data.datapipes.dataframe.dataframe_wrapper import set_df_wrapper
from torch.utils.data.datapipes.dataframe.dataframes import Capture
from torch.utils.data.datapipes.dataframe.dataframes import CaptureA
from torch.utils.data.datapipes.dataframe.dataframes import CaptureAdd
from torch.utils.data.datapipes.dataframe.dataframes import CaptureCall
from torch.utils.data.datapipes.dataframe.dataframes import CaptureControl
from torch.utils.data.datapipes.dataframe.dataframes import CaptureDataFrame
from torch.utils.data.datapipes.dataframe.dataframes import CaptureDataFrameWithDataPipeOps
from torch.utils.data.datapipes.dataframe.dataframes import CaptureF
from torch.utils.data.datapipes.dataframe.dataframes import CaptureGetAttr
from torch.utils.data.datapipes.dataframe.dataframes import CaptureGetItem
from torch.utils.data.datapipes.dataframe.dataframes import CaptureInitial
from torch.utils.data.datapipes.dataframe.dataframes import CaptureLikeMock
from torch.utils.data.datapipes.dataframe.dataframes import CaptureMul
from torch.utils.data.datapipes.dataframe.dataframes import CaptureSetItem
from torch.utils.data.datapipes.dataframe.dataframes import CaptureSub
from torch.utils.data.datapipes.dataframe.dataframes import CaptureVariable
from torch.utils.data.datapipes.dataframe.dataframes import CaptureVariableAssign
from torch.utils.data.datapipes.dataframe.dataframes import DATAPIPES_OPS
from torch.utils.data.datapipes.dataframe.dataframes import DataFrameTracedOps
from torch.utils.data.datapipes.dataframe.dataframes import DataFrameTracer
from torch.utils.data.datapipes.dataframe.dataframes import UNIMPLEMENTED_ATTR
from torch.utils.data.datapipes.dataframe.dataframes import disable_capture
from torch.utils.data.datapipes.dataframe.dataframes import get_val
from torch.utils.data.datapipes.dataframe.datapipes import ConcatDataFramesPipe
from torch.utils.data.datapipes.dataframe.datapipes import DataFramesAsTuplesPipe
from torch.utils.data.datapipes.dataframe.datapipes import ExampleAggregateAsDataFrames
from torch.utils.data.datapipes.dataframe.datapipes import FilterDataFramesPipe
from torch.utils.data.datapipes.dataframe.datapipes import PerRowDataFramesPipe
from torch.utils.data.datapipes.dataframe.datapipes import ShuffleDataFramesPipe
from torch.utils.data.datapipes.dataframe.structures import DataChunkDF
from torch.utils.data.datapipes.datapipe import DFIterDataPipe
from torch.utils.data.datapipes.datapipe import DataChunk
from torch.utils.data.datapipes.datapipe import IterDataPipe
from torch.utils.data.datapipes.datapipe import MapDataPipe
from torch.utils.data.datapipes.datapipe import UNTRACABLE_DATAFRAME_PIPES
from torch.utils.data.datapipes.datapipe import dill
from torch.utils.data.datapipes.datapipe import import_dill
from torch.utils.data.datapipes.iter.callable import CollatorIterDataPipe
from torch.utils.data.datapipes.iter.callable import MapperIterDataPipe
from torch.utils.data.datapipes.iter.combinatorics import SamplerIterDataPipe
from torch.utils.data.datapipes.iter.combinatorics import ShufflerIterDataPipe
from torch.utils.data.datapipes.iter.combining import ConcaterIterDataPipe
from torch.utils.data.datapipes.iter.combining import DemultiplexerIterDataPipe
from torch.utils.data.datapipes.iter.combining import ForkerIterDataPipe
from torch.utils.data.datapipes.iter.combining import MultiplexerIterDataPipe
from torch.utils.data.datapipes.iter.combining import ZipperIterDataPipe
from torch.utils.data.datapipes.iter.filelister import FileListerIterDataPipe
from torch.utils.data.datapipes.iter.fileopener import FileOpenerIterDataPipe
from torch.utils.data.datapipes.iter.grouping import BatcherIterDataPipe
from torch.utils.data.datapipes.iter.grouping import GrouperIterDataPipe
from torch.utils.data.datapipes.iter.grouping import UnBatcherIterDataPipe
from torch.utils.data.datapipes.iter.routeddecoder import RoutedDecoderIterDataPipe
from torch.utils.data.datapipes.iter.selecting import FilterIterDataPipe
from torch.utils.data.datapipes.iter.sharding import SHARDING_PRIORITIES
from torch.utils.data.datapipes.iter.sharding import ShardingFilterIterDataPipe
from torch.utils.data.datapipes.iter.streamreader import StreamReaderIterDataPipe
from torch.utils.data.datapipes.iter.utils import IterableWrapperIterDataPipe
from torch.utils.data.datapipes.map.callable import MapperMapDataPipe
from torch.utils.data.datapipes.map.callable import default_fn
from torch.utils.data.datapipes.map.combinatorics import ShufflerIterDataPipe
from torch.utils.data.datapipes.map.combining import ConcaterMapDataPipe
from torch.utils.data.datapipes.map.combining import ZipperMapDataPipe
from torch.utils.data.datapipes.map.grouping import BatcherMapDataPipe
from torch.utils.data.datapipes.map.utils import SequenceWrapperMapDataPipe
from torch.utils.data.datapipes.utils.common import StreamWrapper
from torch.utils.data.datapipes.utils.common import get_file_binaries_from_pathnames
from torch.utils.data.datapipes.utils.common import get_file_pathnames_from_root
from torch.utils.data.datapipes.utils.common import match_masks
from torch.utils.data.datapipes.utils.common import validate_input_col
from torch.utils.data.datapipes.utils.common import validate_pathname_binary_tuple
from torch.utils.data.datapipes.utils.decoder import Decoder
from torch.utils.data.datapipes.utils.decoder import ImageHandler
from torch.utils.data.datapipes.utils.decoder import MatHandler
from torch.utils.data.datapipes.utils.decoder import audiohandler
from torch.utils.data.datapipes.utils.decoder import basichandlers
from torch.utils.data.datapipes.utils.decoder import extension_extract_fn
from torch.utils.data.datapipes.utils.decoder import handle_extension
from torch.utils.data.datapipes.utils.decoder import imagehandler
from torch.utils.data.datapipes.utils.decoder import imagespecs
from torch.utils.data.datapipes.utils.decoder import mathandler
from torch.utils.data.datapipes.utils.decoder import videohandler
from torch.utils.data.dataset import ChainDataset
from torch.utils.data.dataset import ConcatDataset
from torch.utils.data.dataset import Dataset
from torch.utils.data.dataset import IterableDataset
from torch.utils.data.dataset import StackDataset
from torch.utils.data.dataset import Subset
from torch.utils.data.dataset import TensorDataset
from torch.utils.data.dataset import default_generator
from torch.utils.data.dataset import random_split
from torch.utils.data.distributed import DistributedSampler
from torch.utils.data.graph import dill_available
from torch.utils.data.graph import traverse
from torch.utils.data.graph import traverse_dps
from torch.utils.data.graph_settings import apply_random_seed
from torch.utils.data.graph_settings import apply_sharding
from torch.utils.data.graph_settings import apply_shuffle_seed
from torch.utils.data.graph_settings import apply_shuffle_settings
from torch.utils.data.graph_settings import get_all_graph_pipes
from torch.utils.data.sampler import BatchSampler
from torch.utils.data.sampler import RandomSampler
from torch.utils.data.sampler import Sampler
from torch.utils.data.sampler import SequentialSampler
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data.sampler import WeightedRandomSampler
from torch.utils.dlpack import DLDeviceType
from torch.utils.dlpack import from_dlpack
from torch.utils.file_baton import FileBaton
from torch.utils.flop_counter import FlopCounterMode
from torch.utils.flop_counter import addmm_flop
from torch.utils.flop_counter import baddbmm_flop
from torch.utils.flop_counter import bmm_flop
from torch.utils.flop_counter import conv_backward_flop
from torch.utils.flop_counter import conv_flop
from torch.utils.flop_counter import conv_flop_count
from torch.utils.flop_counter import convert_num_with_suffix
from torch.utils.flop_counter import convert_to_percent_str
from torch.utils.flop_counter import flop_registry
from torch.utils.flop_counter import get_shape
from torch.utils.flop_counter import get_suffix_str
from torch.utils.flop_counter import mm_flop
from torch.utils.flop_counter import normalize_tuple
from torch.utils.flop_counter import register_flop_formula
from torch.utils.flop_counter import sdpa_backward_flop
from torch.utils.flop_counter import sdpa_backward_flop_count
from torch.utils.flop_counter import sdpa_flop
from torch.utils.flop_counter import sdpa_flop_count
from torch.utils.flop_counter import shape_wrapper
from torch.utils.flop_counter import suffixes
from torch.utils.flop_counter import tree_flatten
from torch.utils.flop_counter import tree_unflatten
from torch.utils.hipify.constants import CONV_VERSION
from torch.utils.hipify.cuda_to_hip_mappings import C10_MAPPINGS
from torch.utils.hipify.cuda_to_hip_mappings import CAFFE2_SPECIFIC_MAPPINGS
from torch.utils.hipify.cuda_to_hip_mappings import CONV_VERSION
from torch.utils.hipify.cuda_to_hip_mappings import CUDA_IDENTIFIER_MAP
from torch.utils.hipify.cuda_to_hip_mappings import CUDA_INCLUDE_MAP
from torch.utils.hipify.cuda_to_hip_mappings import CUDA_SPECIAL_MAP
from torch.utils.hipify.cuda_to_hip_mappings import CUDA_TO_HIP_MAPPINGS
from torch.utils.hipify.cuda_to_hip_mappings import CUDA_TYPE_NAME_MAP
from torch.utils.hipify.cuda_to_hip_mappings import MATH_TRANSPILATIONS
from torch.utils.hipify.cuda_to_hip_mappings import PYTORCH_SPECIFIC_MAPPINGS
from torch.utils.hipify.hipify_python import CAFFE2_MAP
from torch.utils.hipify.hipify_python import CAFFE2_TRIE
from torch.utils.hipify.hipify_python import CUDA_TO_HIP_MAPPINGS
from torch.utils.hipify.hipify_python import CurrentState
from torch.utils.hipify.hipify_python import GeneratedFileCleaner
from torch.utils.hipify.hipify_python import HIPIFY_FINAL_RESULT
from torch.utils.hipify.hipify_python import HipifyResult
from torch.utils.hipify.hipify_python import InputError
from torch.utils.hipify.hipify_python import MATH_TRANSPILATIONS
from torch.utils.hipify.hipify_python import PYTORCH_MAP
from torch.utils.hipify.hipify_python import PYTORCH_SPECIAL_MAP
from torch.utils.hipify.hipify_python import PYTORCH_TEMPLATE_MAP
from torch.utils.hipify.hipify_python import PYTORCH_TRIE
from torch.utils.hipify.hipify_python import Trie
from torch.utils.hipify.hipify_python import TrieNode
from torch.utils.hipify.hipify_python import add_dim3
from torch.utils.hipify.hipify_python import bcolors
from torch.utils.hipify.hipify_python import compute_stats
from torch.utils.hipify.hipify_python import dst
from torch.utils.hipify.hipify_python import extract_arguments
from torch.utils.hipify.hipify_python import file_add_header
from torch.utils.hipify.hipify_python import file_specific_replacement
from torch.utils.hipify.hipify_python import find_bracket_group
from torch.utils.hipify.hipify_python import find_closure_group
from torch.utils.hipify.hipify_python import find_parentheses_group
from torch.utils.hipify.hipify_python import fix_static_global_kernels
from torch.utils.hipify.hipify_python import get_hip_file_path
from torch.utils.hipify.hipify_python import hip_header_magic
from torch.utils.hipify.hipify_python import hipify
from torch.utils.hipify.hipify_python import is_caffe2_gpu_file
from torch.utils.hipify.hipify_python import is_cusparse_file
from torch.utils.hipify.hipify_python import is_out_of_place
from torch.utils.hipify.hipify_python import is_pytorch_file
from torch.utils.hipify.hipify_python import is_special_file
from torch.utils.hipify.hipify_python import mapping
from torch.utils.hipify.hipify_python import match_extensions
from torch.utils.hipify.hipify_python import matched_files_iter
from torch.utils.hipify.hipify_python import meta_data
from torch.utils.hipify.hipify_python import openf
from torch.utils.hipify.hipify_python import preprocess_file_and_save_result
from torch.utils.hipify.hipify_python import preprocessor
from torch.utils.hipify.hipify_python import processKernelLaunches
from torch.utils.hipify.hipify_python import replace_extern_shared
from torch.utils.hipify.hipify_python import replace_math_functions
from torch.utils.hipify.hipify_python import src
from torch.utils.hipify.hipify_python import str2bool
from torch.utils.hipify.hipify_python import value
from torch.utils.hooks import BackwardHook
from torch.utils.hooks import RemovableHandle
from torch.utils.hooks import unserializable_hook
from torch.utils.hooks import warn_if_has_hooks
from torch.utils.jit.log_extract import extract_ir
from torch.utils.jit.log_extract import load_graph_and_inputs
from torch.utils.jit.log_extract import make_tensor_from_type
from torch.utils.jit.log_extract import no_fuser
from torch.utils.jit.log_extract import run_baseline_no_fusion
from torch.utils.jit.log_extract import run_nnc
from torch.utils.jit.log_extract import run_nvfuser
from torch.utils.jit.log_extract import run_test
from torch.utils.jit.log_extract import time_cpu
from torch.utils.jit.log_extract import time_cuda
from torch.utils.mkldnn import MkldnnBatchNorm
from torch.utils.mkldnn import MkldnnConv1d
from torch.utils.mkldnn import MkldnnConv2d
from torch.utils.mkldnn import MkldnnConv3d
from torch.utils.mkldnn import MkldnnLinear
from torch.utils.mkldnn import MkldnnPrelu
from torch.utils.mkldnn import to_mkldnn
from torch.utils.mobile_optimizer import LintCode
from torch.utils.mobile_optimizer import generate_mobile_module_lints
from torch.utils.mobile_optimizer import optimize_for_mobile
from torch.utils.model_dump import burn_in_info
from torch.utils.model_dump import get_info_and_burn_skeleton
from torch.utils.model_dump import get_inline_skeleton
from torch.utils.model_dump import get_model_info
from torch.utils.model_dump import get_storage_info
from torch.utils.model_dump import hierarchical_pickle
from torch.utils.model_dump import main
from torch.utils.module_tracker import ModuleTracker
from torch.utils.serialization.config import load
from torch.utils.serialization.config import save
from torch.utils.show_pickle import DumpUnpickler
from torch.utils.show_pickle import FakeClass
from torch.utils.show_pickle import FakeObject
from torch.utils.show_pickle import main
from torch.utils.throughput_benchmark import ExecutionStats
from torch.utils.throughput_benchmark import ThroughputBenchmark
from torch.utils.throughput_benchmark import format_time
from torch.utils.weak import TensorWeakRef
from torch.utils.weak import WeakIdKeyDictionary
from torch.utils.weak import WeakIdRef
from torch.version import cuda
from torch.version import debug
from torch.version import git_version
from torch.version import hip
from torch.version import xpu
from torch.xpu import StreamContext
from torch.xpu import current_device
from torch.xpu import current_stream
from torch.xpu import default_generators
from torch.xpu import device
from torch.xpu import device_count
from torch.xpu import device_of
from torch.xpu import get_arch_list
from torch.xpu import get_device_capability
from torch.xpu import get_device_name
from torch.xpu import get_device_properties
from torch.xpu import get_gencode_flags
from torch.xpu import get_stream_from_external
from torch.xpu import init
from torch.xpu import is_available
from torch.xpu import is_bf16_supported
from torch.xpu import is_initialized
from torch.xpu import set_device
from torch.xpu import set_stream
from torch.xpu import stream
from torch.xpu import synchronize
from torch.xpu.memory import empty_cache
from torch.xpu.memory import max_memory_allocated
from torch.xpu.memory import max_memory_reserved
from torch.xpu.memory import mem_get_info
from torch.xpu.memory import memory_allocated
from torch.xpu.memory import memory_reserved
from torch.xpu.memory import memory_stats
from torch.xpu.memory import memory_stats_as_nested_dict
from torch.xpu.memory import reset_accumulated_memory_stats
from torch.xpu.memory import reset_peak_memory_stats
from torch.xpu.random import get_rng_state
from torch.xpu.random import get_rng_state_all
from torch.xpu.random import initial_seed
from torch.xpu.random import manual_seed
from torch.xpu.random import manual_seed_all
from torch.xpu.random import seed
from torch.xpu.random import seed_all
from torch.xpu.random import set_rng_state
from torch.xpu.random import set_rng_state_all
from torch.xpu.streams import Event
from torch.xpu.streams import Stream